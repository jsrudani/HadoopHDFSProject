// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_protos.proto

package org.apache.hadoop.yarn.proto;

public final class YarnProtos {
  private YarnProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code hadoop.yarn.ContainerStateProto}
   */
  public enum ContainerStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>C_NEW = 1;</code>
     */
    C_NEW(0, 1),
    /**
     * <code>C_RUNNING = 2;</code>
     */
    C_RUNNING(1, 2),
    /**
     * <code>C_COMPLETE = 3;</code>
     */
    C_COMPLETE(2, 3),
    ;

    /**
     * <code>C_NEW = 1;</code>
     */
    public static final int C_NEW_VALUE = 1;
    /**
     * <code>C_RUNNING = 2;</code>
     */
    public static final int C_RUNNING_VALUE = 2;
    /**
     * <code>C_COMPLETE = 3;</code>
     */
    public static final int C_COMPLETE_VALUE = 3;


    public final int getNumber() { return value; }

    public static ContainerStateProto valueOf(int value) {
      switch (value) {
        case 1: return C_NEW;
        case 2: return C_RUNNING;
        case 3: return C_COMPLETE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>() {
            public ContainerStateProto findValueByNumber(int number) {
              return ContainerStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final ContainerStateProto[] VALUES = values();

    public static ContainerStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.YarnApplicationStateProto}
   */
  public enum YarnApplicationStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NEW = 1;</code>
     */
    NEW(0, 1),
    /**
     * <code>NEW_SAVING = 2;</code>
     */
    NEW_SAVING(1, 2),
    /**
     * <code>SUBMITTED = 3;</code>
     */
    SUBMITTED(2, 3),
    /**
     * <code>ACCEPTED = 4;</code>
     */
    ACCEPTED(3, 4),
    /**
     * <code>RUNNING = 5;</code>
     */
    RUNNING(4, 5),
    /**
     * <code>FINISHED = 6;</code>
     */
    FINISHED(5, 6),
    /**
     * <code>FAILED = 7;</code>
     */
    FAILED(6, 7),
    /**
     * <code>KILLED = 8;</code>
     */
    KILLED(7, 8),
    ;

    /**
     * <code>NEW = 1;</code>
     */
    public static final int NEW_VALUE = 1;
    /**
     * <code>NEW_SAVING = 2;</code>
     */
    public static final int NEW_SAVING_VALUE = 2;
    /**
     * <code>SUBMITTED = 3;</code>
     */
    public static final int SUBMITTED_VALUE = 3;
    /**
     * <code>ACCEPTED = 4;</code>
     */
    public static final int ACCEPTED_VALUE = 4;
    /**
     * <code>RUNNING = 5;</code>
     */
    public static final int RUNNING_VALUE = 5;
    /**
     * <code>FINISHED = 6;</code>
     */
    public static final int FINISHED_VALUE = 6;
    /**
     * <code>FAILED = 7;</code>
     */
    public static final int FAILED_VALUE = 7;
    /**
     * <code>KILLED = 8;</code>
     */
    public static final int KILLED_VALUE = 8;


    public final int getNumber() { return value; }

    public static YarnApplicationStateProto valueOf(int value) {
      switch (value) {
        case 1: return NEW;
        case 2: return NEW_SAVING;
        case 3: return SUBMITTED;
        case 4: return ACCEPTED;
        case 5: return RUNNING;
        case 6: return FINISHED;
        case 7: return FAILED;
        case 8: return KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>() {
            public YarnApplicationStateProto findValueByNumber(int number) {
              return YarnApplicationStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final YarnApplicationStateProto[] VALUES = values();

    public static YarnApplicationStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private YarnApplicationStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.YarnApplicationStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.FinalApplicationStatusProto}
   */
  public enum FinalApplicationStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APP_UNDEFINED = 0;</code>
     */
    APP_UNDEFINED(0, 0),
    /**
     * <code>APP_SUCCEEDED = 1;</code>
     */
    APP_SUCCEEDED(1, 1),
    /**
     * <code>APP_FAILED = 2;</code>
     */
    APP_FAILED(2, 2),
    /**
     * <code>APP_KILLED = 3;</code>
     */
    APP_KILLED(3, 3),
    ;

    /**
     * <code>APP_UNDEFINED = 0;</code>
     */
    public static final int APP_UNDEFINED_VALUE = 0;
    /**
     * <code>APP_SUCCEEDED = 1;</code>
     */
    public static final int APP_SUCCEEDED_VALUE = 1;
    /**
     * <code>APP_FAILED = 2;</code>
     */
    public static final int APP_FAILED_VALUE = 2;
    /**
     * <code>APP_KILLED = 3;</code>
     */
    public static final int APP_KILLED_VALUE = 3;


    public final int getNumber() { return value; }

    public static FinalApplicationStatusProto valueOf(int value) {
      switch (value) {
        case 0: return APP_UNDEFINED;
        case 1: return APP_SUCCEEDED;
        case 2: return APP_FAILED;
        case 3: return APP_KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>() {
            public FinalApplicationStatusProto findValueByNumber(int number) {
              return FinalApplicationStatusProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final FinalApplicationStatusProto[] VALUES = values();

    public static FinalApplicationStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private FinalApplicationStatusProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.FinalApplicationStatusProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LocalResourceVisibilityProto}
   */
  public enum LocalResourceVisibilityProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>PUBLIC = 1;</code>
     */
    PUBLIC(0, 1),
    /**
     * <code>PRIVATE = 2;</code>
     */
    PRIVATE(1, 2),
    /**
     * <code>APPLICATION = 3;</code>
     */
    APPLICATION(2, 3),
    ;

    /**
     * <code>PUBLIC = 1;</code>
     */
    public static final int PUBLIC_VALUE = 1;
    /**
     * <code>PRIVATE = 2;</code>
     */
    public static final int PRIVATE_VALUE = 2;
    /**
     * <code>APPLICATION = 3;</code>
     */
    public static final int APPLICATION_VALUE = 3;


    public final int getNumber() { return value; }

    public static LocalResourceVisibilityProto valueOf(int value) {
      switch (value) {
        case 1: return PUBLIC;
        case 2: return PRIVATE;
        case 3: return APPLICATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>() {
            public LocalResourceVisibilityProto findValueByNumber(int number) {
              return LocalResourceVisibilityProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final LocalResourceVisibilityProto[] VALUES = values();

    public static LocalResourceVisibilityProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private LocalResourceVisibilityProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LocalResourceVisibilityProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LocalResourceTypeProto}
   */
  public enum LocalResourceTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ARCHIVE = 1;</code>
     */
    ARCHIVE(0, 1),
    /**
     * <code>FILE = 2;</code>
     */
    FILE(1, 2),
    /**
     * <code>PATTERN = 3;</code>
     */
    PATTERN(2, 3),
    ;

    /**
     * <code>ARCHIVE = 1;</code>
     */
    public static final int ARCHIVE_VALUE = 1;
    /**
     * <code>FILE = 2;</code>
     */
    public static final int FILE_VALUE = 2;
    /**
     * <code>PATTERN = 3;</code>
     */
    public static final int PATTERN_VALUE = 3;


    public final int getNumber() { return value; }

    public static LocalResourceTypeProto valueOf(int value) {
      switch (value) {
        case 1: return ARCHIVE;
        case 2: return FILE;
        case 3: return PATTERN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>() {
            public LocalResourceTypeProto findValueByNumber(int number) {
              return LocalResourceTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final LocalResourceTypeProto[] VALUES = values();

    public static LocalResourceTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private LocalResourceTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LocalResourceTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.NodeStateProto}
   */
  public enum NodeStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NS_NEW = 1;</code>
     */
    NS_NEW(0, 1),
    /**
     * <code>NS_RUNNING = 2;</code>
     */
    NS_RUNNING(1, 2),
    /**
     * <code>NS_UNHEALTHY = 3;</code>
     */
    NS_UNHEALTHY(2, 3),
    /**
     * <code>NS_DECOMMISSIONED = 4;</code>
     */
    NS_DECOMMISSIONED(3, 4),
    /**
     * <code>NS_LOST = 5;</code>
     */
    NS_LOST(4, 5),
    /**
     * <code>NS_REBOOTED = 6;</code>
     */
    NS_REBOOTED(5, 6),
    ;

    /**
     * <code>NS_NEW = 1;</code>
     */
    public static final int NS_NEW_VALUE = 1;
    /**
     * <code>NS_RUNNING = 2;</code>
     */
    public static final int NS_RUNNING_VALUE = 2;
    /**
     * <code>NS_UNHEALTHY = 3;</code>
     */
    public static final int NS_UNHEALTHY_VALUE = 3;
    /**
     * <code>NS_DECOMMISSIONED = 4;</code>
     */
    public static final int NS_DECOMMISSIONED_VALUE = 4;
    /**
     * <code>NS_LOST = 5;</code>
     */
    public static final int NS_LOST_VALUE = 5;
    /**
     * <code>NS_REBOOTED = 6;</code>
     */
    public static final int NS_REBOOTED_VALUE = 6;


    public final int getNumber() { return value; }

    public static NodeStateProto valueOf(int value) {
      switch (value) {
        case 1: return NS_NEW;
        case 2: return NS_RUNNING;
        case 3: return NS_UNHEALTHY;
        case 4: return NS_DECOMMISSIONED;
        case 5: return NS_LOST;
        case 6: return NS_REBOOTED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>() {
            public NodeStateProto findValueByNumber(int number) {
              return NodeStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final NodeStateProto[] VALUES = values();

    public static NodeStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private NodeStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.NodeStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.AMCommandProto}
   */
  public enum AMCommandProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>AM_RESYNC = 1;</code>
     */
    AM_RESYNC(0, 1),
    /**
     * <code>AM_SHUTDOWN = 2;</code>
     */
    AM_SHUTDOWN(1, 2),
    ;

    /**
     * <code>AM_RESYNC = 1;</code>
     */
    public static final int AM_RESYNC_VALUE = 1;
    /**
     * <code>AM_SHUTDOWN = 2;</code>
     */
    public static final int AM_SHUTDOWN_VALUE = 2;


    public final int getNumber() { return value; }

    public static AMCommandProto valueOf(int value) {
      switch (value) {
        case 1: return AM_RESYNC;
        case 2: return AM_SHUTDOWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>() {
            public AMCommandProto findValueByNumber(int number) {
              return AMCommandProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final AMCommandProto[] VALUES = values();

    public static AMCommandProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private AMCommandProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.AMCommandProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ApplicationAccessTypeProto}
   */
  public enum ApplicationAccessTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APPACCESS_VIEW_APP = 1;</code>
     */
    APPACCESS_VIEW_APP(0, 1),
    /**
     * <code>APPACCESS_MODIFY_APP = 2;</code>
     */
    APPACCESS_MODIFY_APP(1, 2),
    ;

    /**
     * <code>APPACCESS_VIEW_APP = 1;</code>
     */
    public static final int APPACCESS_VIEW_APP_VALUE = 1;
    /**
     * <code>APPACCESS_MODIFY_APP = 2;</code>
     */
    public static final int APPACCESS_MODIFY_APP_VALUE = 2;


    public final int getNumber() { return value; }

    public static ApplicationAccessTypeProto valueOf(int value) {
      switch (value) {
        case 1: return APPACCESS_VIEW_APP;
        case 2: return APPACCESS_MODIFY_APP;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>() {
            public ApplicationAccessTypeProto findValueByNumber(int number) {
              return ApplicationAccessTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final ApplicationAccessTypeProto[] VALUES = values();

    public static ApplicationAccessTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ApplicationAccessTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ApplicationAccessTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.QueueStateProto}
   */
  public enum QueueStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>Q_STOPPED = 1;</code>
     */
    Q_STOPPED(0, 1),
    /**
     * <code>Q_RUNNING = 2;</code>
     */
    Q_RUNNING(1, 2),
    ;

    /**
     * <code>Q_STOPPED = 1;</code>
     */
    public static final int Q_STOPPED_VALUE = 1;
    /**
     * <code>Q_RUNNING = 2;</code>
     */
    public static final int Q_RUNNING_VALUE = 2;


    public final int getNumber() { return value; }

    public static QueueStateProto valueOf(int value) {
      switch (value) {
        case 1: return Q_STOPPED;
        case 2: return Q_RUNNING;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>() {
            public QueueStateProto findValueByNumber(int number) {
              return QueueStateProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final QueueStateProto[] VALUES = values();

    public static QueueStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private QueueStateProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.QueueStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.QueueACLProto}
   */
  public enum QueueACLProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>QACL_SUBMIT_APPLICATIONS = 1;</code>
     */
    QACL_SUBMIT_APPLICATIONS(0, 1),
    /**
     * <code>QACL_ADMINISTER_QUEUE = 2;</code>
     */
    QACL_ADMINISTER_QUEUE(1, 2),
    ;

    /**
     * <code>QACL_SUBMIT_APPLICATIONS = 1;</code>
     */
    public static final int QACL_SUBMIT_APPLICATIONS_VALUE = 1;
    /**
     * <code>QACL_ADMINISTER_QUEUE = 2;</code>
     */
    public static final int QACL_ADMINISTER_QUEUE_VALUE = 2;


    public final int getNumber() { return value; }

    public static QueueACLProto valueOf(int value) {
      switch (value) {
        case 1: return QACL_SUBMIT_APPLICATIONS;
        case 2: return QACL_ADMINISTER_QUEUE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>() {
            public QueueACLProto findValueByNumber(int number) {
              return QueueACLProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final QueueACLProto[] VALUES = values();

    public static QueueACLProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private QueueACLProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.QueueACLProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ContainerExitStatusProto}
   */
  public enum ContainerExitStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SUCCESS = 0;</code>
     */
    SUCCESS(0, 0),
    /**
     * <code>INVALID = -1000;</code>
     */
    INVALID(1, -1000),
    /**
     * <code>ABORTED = -100;</code>
     */
    ABORTED(2, -100),
    /**
     * <code>DISKS_FAILED = -101;</code>
     */
    DISKS_FAILED(3, -101),
    ;

    /**
     * <code>SUCCESS = 0;</code>
     */
    public static final int SUCCESS_VALUE = 0;
    /**
     * <code>INVALID = -1000;</code>
     */
    public static final int INVALID_VALUE = -1000;
    /**
     * <code>ABORTED = -100;</code>
     */
    public static final int ABORTED_VALUE = -100;
    /**
     * <code>DISKS_FAILED = -101;</code>
     */
    public static final int DISKS_FAILED_VALUE = -101;


    public final int getNumber() { return value; }

    public static ContainerExitStatusProto valueOf(int value) {
      switch (value) {
        case 0: return SUCCESS;
        case -1000: return INVALID;
        case -100: return ABORTED;
        case -101: return DISKS_FAILED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>() {
            public ContainerExitStatusProto findValueByNumber(int number) {
              return ContainerExitStatusProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final ContainerExitStatusProto[] VALUES = values();

    public static ContainerExitStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ContainerExitStatusProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerExitStatusProto)
  }

  public interface SerializedExceptionProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string message = 1;
    /**
     * <code>optional string message = 1;</code>
     */
    boolean hasMessage();
    /**
     * <code>optional string message = 1;</code>
     */
    java.lang.String getMessage();
    /**
     * <code>optional string message = 1;</code>
     */
    com.google.protobuf.ByteString
        getMessageBytes();

    // optional string trace = 2;
    /**
     * <code>optional string trace = 2;</code>
     */
    boolean hasTrace();
    /**
     * <code>optional string trace = 2;</code>
     */
    java.lang.String getTrace();
    /**
     * <code>optional string trace = 2;</code>
     */
    com.google.protobuf.ByteString
        getTraceBytes();

    // optional string class_name = 3;
    /**
     * <code>optional string class_name = 3;</code>
     */
    boolean hasClassName();
    /**
     * <code>optional string class_name = 3;</code>
     */
    java.lang.String getClassName();
    /**
     * <code>optional string class_name = 3;</code>
     */
    com.google.protobuf.ByteString
        getClassNameBytes();

    // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    boolean hasCause();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SerializedExceptionProto}
   */
  public static final class SerializedExceptionProto extends
      com.google.protobuf.GeneratedMessage
      implements SerializedExceptionProtoOrBuilder {
    // Use SerializedExceptionProto.newBuilder() to construct.
    private SerializedExceptionProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SerializedExceptionProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SerializedExceptionProto defaultInstance;
    public static SerializedExceptionProto getDefaultInstance() {
      return defaultInstance;
    }

    public SerializedExceptionProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SerializedExceptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              message_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              trace_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              className_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = cause_.toBuilder();
              }
              cause_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(cause_);
                cause_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SerializedExceptionProto> PARSER =
        new com.google.protobuf.AbstractParser<SerializedExceptionProto>() {
      public SerializedExceptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SerializedExceptionProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SerializedExceptionProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string message = 1;
    public static final int MESSAGE_FIELD_NUMBER = 1;
    private java.lang.Object message_;
    /**
     * <code>optional string message = 1;</code>
     */
    public boolean hasMessage() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string message = 1;</code>
     */
    public java.lang.String getMessage() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          message_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string message = 1;</code>
     */
    public com.google.protobuf.ByteString
        getMessageBytes() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        message_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string trace = 2;
    public static final int TRACE_FIELD_NUMBER = 2;
    private java.lang.Object trace_;
    /**
     * <code>optional string trace = 2;</code>
     */
    public boolean hasTrace() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string trace = 2;</code>
     */
    public java.lang.String getTrace() {
      java.lang.Object ref = trace_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trace_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string trace = 2;</code>
     */
    public com.google.protobuf.ByteString
        getTraceBytes() {
      java.lang.Object ref = trace_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trace_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string class_name = 3;
    public static final int CLASS_NAME_FIELD_NUMBER = 3;
    private java.lang.Object className_;
    /**
     * <code>optional string class_name = 3;</code>
     */
    public boolean hasClassName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string class_name = 3;</code>
     */
    public java.lang.String getClassName() {
      java.lang.Object ref = className_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          className_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string class_name = 3;</code>
     */
    public com.google.protobuf.ByteString
        getClassNameBytes() {
      java.lang.Object ref = className_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        className_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
    public static final int CAUSE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto cause_;
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public boolean hasCause() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause() {
      return cause_;
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder() {
      return cause_;
    }

    private void initFields() {
      message_ = "";
      trace_ = "";
      className_ = "";
      cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getMessageBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getTraceBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getClassNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, cause_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getMessageBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getTraceBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getClassNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, cause_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) obj;

      boolean result = true;
      result = result && (hasMessage() == other.hasMessage());
      if (hasMessage()) {
        result = result && getMessage()
            .equals(other.getMessage());
      }
      result = result && (hasTrace() == other.hasTrace());
      if (hasTrace()) {
        result = result && getTrace()
            .equals(other.getTrace());
      }
      result = result && (hasClassName() == other.hasClassName());
      if (hasClassName()) {
        result = result && getClassName()
            .equals(other.getClassName());
      }
      result = result && (hasCause() == other.hasCause());
      if (hasCause()) {
        result = result && getCause()
            .equals(other.getCause());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMessage()) {
        hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + getMessage().hashCode();
      }
      if (hasTrace()) {
        hash = (37 * hash) + TRACE_FIELD_NUMBER;
        hash = (53 * hash) + getTrace().hashCode();
      }
      if (hasClassName()) {
        hash = (37 * hash) + CLASS_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getClassName().hashCode();
      }
      if (hasCause()) {
        hash = (37 * hash) + CAUSE_FIELD_NUMBER;
        hash = (53 * hash) + getCause().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SerializedExceptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getCauseFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        message_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        trace_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        className_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (causeBuilder_ == null) {
          cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
        } else {
          causeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.message_ = message_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.trace_ = trace_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.className_ = className_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (causeBuilder_ == null) {
          result.cause_ = cause_;
        } else {
          result.cause_ = causeBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) return this;
        if (other.hasMessage()) {
          bitField0_ |= 0x00000001;
          message_ = other.message_;
          onChanged();
        }
        if (other.hasTrace()) {
          bitField0_ |= 0x00000002;
          trace_ = other.trace_;
          onChanged();
        }
        if (other.hasClassName()) {
          bitField0_ |= 0x00000004;
          className_ = other.className_;
          onChanged();
        }
        if (other.hasCause()) {
          mergeCause(other.getCause());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string message = 1;
      private java.lang.Object message_ = "";
      /**
       * <code>optional string message = 1;</code>
       */
      public boolean hasMessage() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public java.lang.String getMessage() {
        java.lang.Object ref = message_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          message_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public com.google.protobuf.ByteString
          getMessageBytes() {
        java.lang.Object ref = message_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          message_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder setMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        message_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder clearMessage() {
        bitField0_ = (bitField0_ & ~0x00000001);
        message_ = getDefaultInstance().getMessage();
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder setMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        message_ = value;
        onChanged();
        return this;
      }

      // optional string trace = 2;
      private java.lang.Object trace_ = "";
      /**
       * <code>optional string trace = 2;</code>
       */
      public boolean hasTrace() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public java.lang.String getTrace() {
        java.lang.Object ref = trace_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          trace_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public com.google.protobuf.ByteString
          getTraceBytes() {
        java.lang.Object ref = trace_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trace_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder setTrace(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trace_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder clearTrace() {
        bitField0_ = (bitField0_ & ~0x00000002);
        trace_ = getDefaultInstance().getTrace();
        onChanged();
        return this;
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder setTraceBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trace_ = value;
        onChanged();
        return this;
      }

      // optional string class_name = 3;
      private java.lang.Object className_ = "";
      /**
       * <code>optional string class_name = 3;</code>
       */
      public boolean hasClassName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public java.lang.String getClassName() {
        java.lang.Object ref = className_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          className_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public com.google.protobuf.ByteString
          getClassNameBytes() {
        java.lang.Object ref = className_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          className_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder setClassName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        className_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder clearClassName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        className_ = getDefaultInstance().getClassName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder setClassNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        className_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.SerializedExceptionProto cause = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> causeBuilder_;
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public boolean hasCause() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause() {
        if (causeBuilder_ == null) {
          return cause_;
        } else {
          return causeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder setCause(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (causeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          cause_ = value;
          onChanged();
        } else {
          causeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder setCause(
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder builderForValue) {
        if (causeBuilder_ == null) {
          cause_ = builderForValue.build();
          onChanged();
        } else {
          causeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder mergeCause(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (causeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              cause_ != org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) {
            cause_ =
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder(cause_).mergeFrom(value).buildPartial();
          } else {
            cause_ = value;
          }
          onChanged();
        } else {
          causeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder clearCause() {
        if (causeBuilder_ == null) {
          cause_ = org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
          onChanged();
        } else {
          causeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder getCauseBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getCauseFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder() {
        if (causeBuilder_ != null) {
          return causeBuilder_.getMessageOrBuilder();
        } else {
          return cause_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> 
          getCauseFieldBuilder() {
        if (causeBuilder_ == null) {
          causeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder>(
                  cause_,
                  getParentForChildren(),
                  isClean());
          cause_ = null;
        }
        return causeBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SerializedExceptionProto)
    }

    static {
      defaultInstance = new SerializedExceptionProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SerializedExceptionProto)
  }

  public interface ApplicationIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 id = 1;
    /**
     * <code>optional int32 id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional int32 id = 1;</code>
     */
    int getId();

    // optional int64 cluster_timestamp = 2;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    boolean hasClusterTimestamp();
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    long getClusterTimestamp();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationIdProto}
   */
  public static final class ApplicationIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationIdProtoOrBuilder {
    // Use ApplicationIdProto.newBuilder() to construct.
    private ApplicationIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationIdProto defaultInstance;
    public static ApplicationIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              id_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              clusterTimestamp_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationIdProto>() {
      public ApplicationIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private int id_;
    /**
     * <code>optional int32 id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 id = 1;</code>
     */
    public int getId() {
      return id_;
    }

    // optional int64 cluster_timestamp = 2;
    public static final int CLUSTER_TIMESTAMP_FIELD_NUMBER = 2;
    private long clusterTimestamp_;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public boolean hasClusterTimestamp() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public long getClusterTimestamp() {
      return clusterTimestamp_;
    }

    private void initFields() {
      id_ = 0;
      clusterTimestamp_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, clusterTimestamp_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, clusterTimestamp_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result && (hasClusterTimestamp() == other.hasClusterTimestamp());
      if (hasClusterTimestamp()) {
        result = result && (getClusterTimestamp()
            == other.getClusterTimestamp());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId();
      }
      if (hasClusterTimestamp()) {
        hash = (37 * hash) + CLUSTER_TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getClusterTimestamp());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        id_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        clusterTimestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.id_ = id_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.clusterTimestamp_ = clusterTimestamp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          setId(other.getId());
        }
        if (other.hasClusterTimestamp()) {
          setClusterTimestamp(other.getClusterTimestamp());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 id = 1;
      private int id_ ;
      /**
       * <code>optional int32 id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public int getId() {
        return id_;
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public Builder setId(int value) {
        bitField0_ |= 0x00000001;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        id_ = 0;
        onChanged();
        return this;
      }

      // optional int64 cluster_timestamp = 2;
      private long clusterTimestamp_ ;
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public boolean hasClusterTimestamp() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public long getClusterTimestamp() {
        return clusterTimestamp_;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder setClusterTimestamp(long value) {
        bitField0_ |= 0x00000002;
        clusterTimestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder clearClusterTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000002);
        clusterTimestamp_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationIdProto)
    }

    static {
      defaultInstance = new ApplicationIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationIdProto)
  }

  public interface ApplicationAttemptIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional int32 attemptId = 2;
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    boolean hasAttemptId();
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    int getAttemptId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationAttemptIdProto}
   */
  public static final class ApplicationAttemptIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationAttemptIdProtoOrBuilder {
    // Use ApplicationAttemptIdProto.newBuilder() to construct.
    private ApplicationAttemptIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationAttemptIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationAttemptIdProto defaultInstance;
    public static ApplicationAttemptIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationAttemptIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationAttemptIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              attemptId_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationAttemptIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationAttemptIdProto>() {
      public ApplicationAttemptIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationAttemptIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationAttemptIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional int32 attemptId = 2;
    public static final int ATTEMPTID_FIELD_NUMBER = 2;
    private int attemptId_;
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    public boolean hasAttemptId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    public int getAttemptId() {
      return attemptId_;
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      attemptId_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, attemptId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, attemptId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasAttemptId() == other.hasAttemptId());
      if (hasAttemptId()) {
        result = result && (getAttemptId()
            == other.getAttemptId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasAttemptId()) {
        hash = (37 * hash) + ATTEMPTID_FIELD_NUMBER;
        hash = (53 * hash) + getAttemptId();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationAttemptIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        attemptId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.attemptId_ = attemptId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasAttemptId()) {
          setAttemptId(other.getAttemptId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional int32 attemptId = 2;
      private int attemptId_ ;
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public boolean hasAttemptId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public int getAttemptId() {
        return attemptId_;
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public Builder setAttemptId(int value) {
        bitField0_ |= 0x00000002;
        attemptId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public Builder clearAttemptId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        attemptId_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationAttemptIdProto)
    }

    static {
      defaultInstance = new ApplicationAttemptIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationAttemptIdProto)
  }

  public interface ContainerIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    boolean hasAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder();

    // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    boolean hasAppAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder();

    // optional int32 id = 3;
    /**
     * <code>optional int32 id = 3;</code>
     */
    boolean hasId();
    /**
     * <code>optional int32 id = 3;</code>
     */
    int getId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerIdProto}
   */
  public static final class ContainerIdProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerIdProtoOrBuilder {
    // Use ContainerIdProto.newBuilder() to construct.
    private ContainerIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerIdProto defaultInstance;
    public static ContainerIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = appId_.toBuilder();
              }
              appId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appId_);
                appId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = appAttemptId_.toBuilder();
              }
              appAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appAttemptId_);
                appAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              id_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerIdProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerIdProto>() {
      public ContainerIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
    public static final int APP_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public boolean hasAppId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
      return appId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
      return appId_;
    }

    // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
    public static final int APP_ATTEMPT_ID_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto appAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public boolean hasAppAttemptId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId() {
      return appAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder() {
      return appAttemptId_;
    }

    // optional int32 id = 3;
    public static final int ID_FIELD_NUMBER = 3;
    private int id_;
    /**
     * <code>optional int32 id = 3;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 id = 3;</code>
     */
    public int getId() {
      return id_;
    }

    private void initFields() {
      appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      id_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, appAttemptId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, id_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, appAttemptId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, id_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) obj;

      boolean result = true;
      result = result && (hasAppId() == other.hasAppId());
      if (hasAppId()) {
        result = result && getAppId()
            .equals(other.getAppId());
      }
      result = result && (hasAppAttemptId() == other.hasAppAttemptId());
      if (hasAppAttemptId()) {
        result = result && getAppAttemptId()
            .equals(other.getAppAttemptId());
      }
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAppId()) {
        hash = (37 * hash) + APP_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAppId().hashCode();
      }
      if (hasAppAttemptId()) {
        hash = (37 * hash) + APP_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAppAttemptId().hashCode();
      }
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAppIdFieldBuilder();
          getAppAttemptIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          appAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        id_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (appIdBuilder_ == null) {
          result.appId_ = appId_;
        } else {
          result.appId_ = appIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (appAttemptIdBuilder_ == null) {
          result.appAttemptId_ = appAttemptId_;
        } else {
          result.appAttemptId_ = appAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.id_ = id_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) return this;
        if (other.hasAppId()) {
          mergeAppId(other.getAppId());
        }
        if (other.hasAppAttemptId()) {
          mergeAppAttemptId(other.getAppAttemptId());
        }
        if (other.hasId()) {
          setId(other.getId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto app_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> appIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public boolean hasAppId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
        if (appIdBuilder_ == null) {
          return appId_;
        } else {
          return appIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder setAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appId_ = value;
          onChanged();
        } else {
          appIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder setAppId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (appIdBuilder_ == null) {
          appId_ = builderForValue.build();
          onChanged();
        } else {
          appIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder mergeAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              appId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            appId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(appId_).mergeFrom(value).buildPartial();
          } else {
            appId_ = value;
          }
          onChanged();
        } else {
          appIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder clearAppId() {
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getAppIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAppIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
        if (appIdBuilder_ != null) {
          return appIdBuilder_.getMessageOrBuilder();
        } else {
          return appId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getAppIdFieldBuilder() {
        if (appIdBuilder_ == null) {
          appIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  appId_,
                  getParentForChildren(),
                  isClean());
          appId_ = null;
        }
        return appIdBuilder_;
      }

      // optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> appAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public boolean hasAppAttemptId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId() {
        if (appAttemptIdBuilder_ == null) {
          return appAttemptId_;
        } else {
          return appAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder setAppAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (appAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appAttemptId_ = value;
          onChanged();
        } else {
          appAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder setAppAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          appAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder mergeAppAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (appAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              appAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            appAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(appAttemptId_).mergeFrom(value).buildPartial();
          } else {
            appAttemptId_ = value;
          }
          onChanged();
        } else {
          appAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder clearAppAttemptId() {
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          appAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getAppAttemptIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getAppAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder() {
        if (appAttemptIdBuilder_ != null) {
          return appAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return appAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getAppAttemptIdFieldBuilder() {
        if (appAttemptIdBuilder_ == null) {
          appAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  appAttemptId_,
                  getParentForChildren(),
                  isClean());
          appAttemptId_ = null;
        }
        return appAttemptIdBuilder_;
      }

      // optional int32 id = 3;
      private int id_ ;
      /**
       * <code>optional int32 id = 3;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 id = 3;</code>
       */
      public int getId() {
        return id_;
      }
      /**
       * <code>optional int32 id = 3;</code>
       */
      public Builder setId(int value) {
        bitField0_ |= 0x00000004;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 id = 3;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        id_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerIdProto)
    }

    static {
      defaultInstance = new ContainerIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerIdProto)
  }

  public interface ResourceProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 memory = 1;
    /**
     * <code>optional int32 memory = 1;</code>
     */
    boolean hasMemory();
    /**
     * <code>optional int32 memory = 1;</code>
     */
    int getMemory();

    // optional int32 virtual_cores = 2;
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    boolean hasVirtualCores();
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    int getVirtualCores();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceProto}
   */
  public static final class ResourceProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceProtoOrBuilder {
    // Use ResourceProto.newBuilder() to construct.
    private ResourceProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceProto defaultInstance;
    public static ResourceProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              memory_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              virtualCores_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceProto>() {
      public ResourceProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 memory = 1;
    public static final int MEMORY_FIELD_NUMBER = 1;
    private int memory_;
    /**
     * <code>optional int32 memory = 1;</code>
     */
    public boolean hasMemory() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 memory = 1;</code>
     */
    public int getMemory() {
      return memory_;
    }

    // optional int32 virtual_cores = 2;
    public static final int VIRTUAL_CORES_FIELD_NUMBER = 2;
    private int virtualCores_;
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    public boolean hasVirtualCores() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    public int getVirtualCores() {
      return virtualCores_;
    }

    private void initFields() {
      memory_ = 0;
      virtualCores_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, memory_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, virtualCores_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, memory_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, virtualCores_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) obj;

      boolean result = true;
      result = result && (hasMemory() == other.hasMemory());
      if (hasMemory()) {
        result = result && (getMemory()
            == other.getMemory());
      }
      result = result && (hasVirtualCores() == other.hasVirtualCores());
      if (hasVirtualCores()) {
        result = result && (getVirtualCores()
            == other.getVirtualCores());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMemory()) {
        hash = (37 * hash) + MEMORY_FIELD_NUMBER;
        hash = (53 * hash) + getMemory();
      }
      if (hasVirtualCores()) {
        hash = (37 * hash) + VIRTUAL_CORES_FIELD_NUMBER;
        hash = (53 * hash) + getVirtualCores();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        memory_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        virtualCores_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.memory_ = memory_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.virtualCores_ = virtualCores_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) return this;
        if (other.hasMemory()) {
          setMemory(other.getMemory());
        }
        if (other.hasVirtualCores()) {
          setVirtualCores(other.getVirtualCores());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 memory = 1;
      private int memory_ ;
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public boolean hasMemory() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public int getMemory() {
        return memory_;
      }
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public Builder setMemory(int value) {
        bitField0_ |= 0x00000001;
        memory_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public Builder clearMemory() {
        bitField0_ = (bitField0_ & ~0x00000001);
        memory_ = 0;
        onChanged();
        return this;
      }

      // optional int32 virtual_cores = 2;
      private int virtualCores_ ;
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public boolean hasVirtualCores() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public int getVirtualCores() {
        return virtualCores_;
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public Builder setVirtualCores(int value) {
        bitField0_ |= 0x00000002;
        virtualCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public Builder clearVirtualCores() {
        bitField0_ = (bitField0_ & ~0x00000002);
        virtualCores_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceProto)
    }

    static {
      defaultInstance = new ResourceProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceProto)
  }

  public interface ResourceOptionProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ResourceProto resource = 1;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional int32 over_commit_timeout = 2;
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    boolean hasOverCommitTimeout();
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    int getOverCommitTimeout();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceOptionProto}
   */
  public static final class ResourceOptionProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceOptionProtoOrBuilder {
    // Use ResourceOptionProto.newBuilder() to construct.
    private ResourceOptionProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceOptionProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceOptionProto defaultInstance;
    public static ResourceOptionProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceOptionProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceOptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              overCommitTimeout_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceOptionProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceOptionProto>() {
      public ResourceOptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceOptionProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceOptionProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ResourceProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional int32 over_commit_timeout = 2;
    public static final int OVER_COMMIT_TIMEOUT_FIELD_NUMBER = 2;
    private int overCommitTimeout_;
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    public boolean hasOverCommitTimeout() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    public int getOverCommitTimeout() {
      return overCommitTimeout_;
    }

    private void initFields() {
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      overCommitTimeout_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, overCommitTimeout_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, overCommitTimeout_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasOverCommitTimeout() == other.hasOverCommitTimeout());
      if (hasOverCommitTimeout()) {
        result = result && (getOverCommitTimeout()
            == other.getOverCommitTimeout());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasOverCommitTimeout()) {
        hash = (37 * hash) + OVER_COMMIT_TIMEOUT_FIELD_NUMBER;
        hash = (53 * hash) + getOverCommitTimeout();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceOptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        overCommitTimeout_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.overCommitTimeout_ = overCommitTimeout_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasOverCommitTimeout()) {
          setOverCommitTimeout(other.getOverCommitTimeout());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ResourceProto resource = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional int32 over_commit_timeout = 2;
      private int overCommitTimeout_ ;
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public boolean hasOverCommitTimeout() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public int getOverCommitTimeout() {
        return overCommitTimeout_;
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public Builder setOverCommitTimeout(int value) {
        bitField0_ |= 0x00000002;
        overCommitTimeout_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public Builder clearOverCommitTimeout() {
        bitField0_ = (bitField0_ & ~0x00000002);
        overCommitTimeout_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceOptionProto)
    }

    static {
      defaultInstance = new ResourceOptionProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceOptionProto)
  }

  public interface NodeResourceMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    boolean hasResourceOption();
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption();
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeResourceMapProto}
   */
  public static final class NodeResourceMapProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeResourceMapProtoOrBuilder {
    // Use NodeResourceMapProto.newBuilder() to construct.
    private NodeResourceMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeResourceMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeResourceMapProto defaultInstance;
    public static NodeResourceMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeResourceMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeResourceMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = resourceOption_.toBuilder();
              }
              resourceOption_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resourceOption_);
                resourceOption_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeResourceMapProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeResourceMapProto>() {
      public NodeResourceMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeResourceMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeResourceMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    public static final int NODE_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
    public static final int RESOURCE_OPTION_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto resourceOption_;
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public boolean hasResourceOption() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption() {
      return resourceOption_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder() {
      return resourceOption_;
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, resourceOption_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, resourceOption_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasResourceOption() == other.hasResourceOption());
      if (hasResourceOption()) {
        result = result && getResourceOption()
            .equals(other.getResourceOption());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasResourceOption()) {
        hash = (37 * hash) + RESOURCE_OPTION_FIELD_NUMBER;
        hash = (53 * hash) + getResourceOption().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeResourceMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getResourceOptionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
        } else {
          resourceOptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (resourceOptionBuilder_ == null) {
          result.resourceOption_ = resourceOption_;
        } else {
          result.resourceOption_ = resourceOptionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasResourceOption()) {
          mergeResourceOption(other.getResourceOption());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto node_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceOptionProto resource_option = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder> resourceOptionBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public boolean hasResourceOption() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption() {
        if (resourceOptionBuilder_ == null) {
          return resourceOption_;
        } else {
          return resourceOptionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder setResourceOption(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto value) {
        if (resourceOptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resourceOption_ = value;
          onChanged();
        } else {
          resourceOptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder setResourceOption(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder builderForValue) {
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = builderForValue.build();
          onChanged();
        } else {
          resourceOptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder mergeResourceOption(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto value) {
        if (resourceOptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              resourceOption_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance()) {
            resourceOption_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.newBuilder(resourceOption_).mergeFrom(value).buildPartial();
          } else {
            resourceOption_ = value;
          }
          onChanged();
        } else {
          resourceOptionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder clearResourceOption() {
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
          onChanged();
        } else {
          resourceOptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder getResourceOptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResourceOptionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder() {
        if (resourceOptionBuilder_ != null) {
          return resourceOptionBuilder_.getMessageOrBuilder();
        } else {
          return resourceOption_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder> 
          getResourceOptionFieldBuilder() {
        if (resourceOptionBuilder_ == null) {
          resourceOptionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder>(
                  resourceOption_,
                  getParentForChildren(),
                  isClean());
          resourceOption_ = null;
        }
        return resourceOptionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeResourceMapProto)
    }

    static {
      defaultInstance = new NodeResourceMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeResourceMapProto)
  }

  public interface PriorityProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 priority = 1;
    /**
     * <code>optional int32 priority = 1;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional int32 priority = 1;</code>
     */
    int getPriority();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PriorityProto}
   */
  public static final class PriorityProto extends
      com.google.protobuf.GeneratedMessage
      implements PriorityProtoOrBuilder {
    // Use PriorityProto.newBuilder() to construct.
    private PriorityProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PriorityProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PriorityProto defaultInstance;
    public static PriorityProto getDefaultInstance() {
      return defaultInstance;
    }

    public PriorityProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PriorityProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              priority_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PriorityProto> PARSER =
        new com.google.protobuf.AbstractParser<PriorityProto>() {
      public PriorityProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PriorityProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PriorityProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 priority = 1;
    public static final int PRIORITY_FIELD_NUMBER = 1;
    private int priority_;
    /**
     * <code>optional int32 priority = 1;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 priority = 1;</code>
     */
    public int getPriority() {
      return priority_;
    }

    private void initFields() {
      priority_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, priority_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, priority_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) obj;

      boolean result = true;
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && (getPriority()
            == other.getPriority());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PriorityProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        priority_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.priority_ = priority_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) return this;
        if (other.hasPriority()) {
          setPriority(other.getPriority());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 priority = 1;
      private int priority_ ;
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public int getPriority() {
        return priority_;
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public Builder setPriority(int value) {
        bitField0_ |= 0x00000001;
        priority_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public Builder clearPriority() {
        bitField0_ = (bitField0_ & ~0x00000001);
        priority_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PriorityProto)
    }

    static {
      defaultInstance = new PriorityProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PriorityProto)
  }

  public interface ContainerProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder();

    // optional .hadoop.yarn.NodeIdProto nodeId = 2;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional string node_http_address = 3;
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    boolean hasNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    java.lang.String getNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    com.google.protobuf.ByteString
        getNodeHttpAddressBytes();

    // optional .hadoop.yarn.ResourceProto resource = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional .hadoop.yarn.PriorityProto priority = 5;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional .hadoop.common.TokenProto container_token = 6;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerProto}
   */
  public static final class ContainerProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerProtoOrBuilder {
    // Use ContainerProto.newBuilder() to construct.
    private ContainerProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerProto defaultInstance;
    public static ContainerProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = id_.toBuilder();
              }
              id_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(id_);
                id_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              nodeHttpAddress_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 50: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) == 0x00000020)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerProto>() {
      public ContainerProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
      return id_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
      return id_;
    }

    // optional .hadoop.yarn.NodeIdProto nodeId = 2;
    public static final int NODEID_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional string node_http_address = 3;
    public static final int NODE_HTTP_ADDRESS_FIELD_NUMBER = 3;
    private java.lang.Object nodeHttpAddress_;
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public boolean hasNodeHttpAddress() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public java.lang.String getNodeHttpAddress() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeHttpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public com.google.protobuf.ByteString
        getNodeHttpAddressBytes() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeHttpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ResourceProto resource = 4;
    public static final int RESOURCE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional .hadoop.yarn.PriorityProto priority = 5;
    public static final int PRIORITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional .hadoop.common.TokenProto container_token = 6;
    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 6;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_;
    }

    private void initFields() {
      id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      nodeHttpAddress_ = "";
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, nodeId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getNodeHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, resource_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, priority_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(6, containerToken_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, nodeId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getNodeHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, resource_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, priority_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, containerToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && getId()
            .equals(other.getId());
      }
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasNodeHttpAddress() == other.hasNodeHttpAddress());
      if (hasNodeHttpAddress()) {
        result = result && getNodeHttpAddress()
            .equals(other.getNodeHttpAddress());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasNodeHttpAddress()) {
        hash = (37 * hash) + NODE_HTTP_ADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeHttpAddress().hashCode();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getIdFieldBuilder();
          getNodeIdFieldBuilder();
          getResourceFieldBuilder();
          getPriorityFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        nodeHttpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (idBuilder_ == null) {
          result.id_ = id_;
        } else {
          result.id_ = idBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.nodeHttpAddress_ = nodeHttpAddress_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasNodeHttpAddress()) {
          bitField0_ |= 0x00000004;
          nodeHttpAddress_ = other.nodeHttpAddress_;
          onChanged();
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> idBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
        if (idBuilder_ == null) {
          return id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
          onChanged();
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
          onChanged();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder mergeId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              id_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            id_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(id_).mergeFrom(value).buildPartial();
          } else {
            id_ = value;
          }
          onChanged();
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder clearId() {
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  id_,
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }

      // optional .hadoop.yarn.NodeIdProto nodeId = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional string node_http_address = 3;
      private java.lang.Object nodeHttpAddress_ = "";
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public boolean hasNodeHttpAddress() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public java.lang.String getNodeHttpAddress() {
        java.lang.Object ref = nodeHttpAddress_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeHttpAddress_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public com.google.protobuf.ByteString
          getNodeHttpAddressBytes() {
        java.lang.Object ref = nodeHttpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeHttpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder setNodeHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder clearNodeHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000004);
        nodeHttpAddress_ = getDefaultInstance().getNodeHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder setNodeHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional .hadoop.yarn.PriorityProto priority = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional .hadoop.common.TokenProto container_token = 6;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder setContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder setContainerToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder mergeContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              containerToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  containerToken_,
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerProto)
    }

    static {
      defaultInstance = new ContainerProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerProto)
  }

  public interface URLProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string scheme = 1;
    /**
     * <code>optional string scheme = 1;</code>
     */
    boolean hasScheme();
    /**
     * <code>optional string scheme = 1;</code>
     */
    java.lang.String getScheme();
    /**
     * <code>optional string scheme = 1;</code>
     */
    com.google.protobuf.ByteString
        getSchemeBytes();

    // optional string host = 2;
    /**
     * <code>optional string host = 2;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 2;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 2;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 port = 3;
    /**
     * <code>optional int32 port = 3;</code>
     */
    boolean hasPort();
    /**
     * <code>optional int32 port = 3;</code>
     */
    int getPort();

    // optional string file = 4;
    /**
     * <code>optional string file = 4;</code>
     */
    boolean hasFile();
    /**
     * <code>optional string file = 4;</code>
     */
    java.lang.String getFile();
    /**
     * <code>optional string file = 4;</code>
     */
    com.google.protobuf.ByteString
        getFileBytes();

    // optional string userInfo = 5;
    /**
     * <code>optional string userInfo = 5;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>optional string userInfo = 5;</code>
     */
    java.lang.String getUserInfo();
    /**
     * <code>optional string userInfo = 5;</code>
     */
    com.google.protobuf.ByteString
        getUserInfoBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.URLProto}
   */
  public static final class URLProto extends
      com.google.protobuf.GeneratedMessage
      implements URLProtoOrBuilder {
    // Use URLProto.newBuilder() to construct.
    private URLProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private URLProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final URLProto defaultInstance;
    public static URLProto getDefaultInstance() {
      return defaultInstance;
    }

    public URLProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private URLProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              scheme_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              host_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              port_ = input.readInt32();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              file_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              userInfo_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.class, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder.class);
    }

    public static com.google.protobuf.Parser<URLProto> PARSER =
        new com.google.protobuf.AbstractParser<URLProto>() {
      public URLProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new URLProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<URLProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string scheme = 1;
    public static final int SCHEME_FIELD_NUMBER = 1;
    private java.lang.Object scheme_;
    /**
     * <code>optional string scheme = 1;</code>
     */
    public boolean hasScheme() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string scheme = 1;</code>
     */
    public java.lang.String getScheme() {
      java.lang.Object ref = scheme_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          scheme_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string scheme = 1;</code>
     */
    public com.google.protobuf.ByteString
        getSchemeBytes() {
      java.lang.Object ref = scheme_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        scheme_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string host = 2;
    public static final int HOST_FIELD_NUMBER = 2;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 2;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 port = 3;
    public static final int PORT_FIELD_NUMBER = 3;
    private int port_;
    /**
     * <code>optional int32 port = 3;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 port = 3;</code>
     */
    public int getPort() {
      return port_;
    }

    // optional string file = 4;
    public static final int FILE_FIELD_NUMBER = 4;
    private java.lang.Object file_;
    /**
     * <code>optional string file = 4;</code>
     */
    public boolean hasFile() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string file = 4;</code>
     */
    public java.lang.String getFile() {
      java.lang.Object ref = file_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          file_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string file = 4;</code>
     */
    public com.google.protobuf.ByteString
        getFileBytes() {
      java.lang.Object ref = file_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        file_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string userInfo = 5;
    public static final int USERINFO_FIELD_NUMBER = 5;
    private java.lang.Object userInfo_;
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public java.lang.String getUserInfo() {
      java.lang.Object ref = userInfo_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          userInfo_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public com.google.protobuf.ByteString
        getUserInfoBytes() {
      java.lang.Object ref = userInfo_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        userInfo_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      scheme_ = "";
      host_ = "";
      port_ = 0;
      file_ = "";
      userInfo_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getSchemeBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, port_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getFileBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getUserInfoBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getSchemeBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, port_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getFileBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getUserInfoBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.URLProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.URLProto other = (org.apache.hadoop.yarn.proto.YarnProtos.URLProto) obj;

      boolean result = true;
      result = result && (hasScheme() == other.hasScheme());
      if (hasScheme()) {
        result = result && getScheme()
            .equals(other.getScheme());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result && (hasFile() == other.hasFile());
      if (hasFile()) {
        result = result && getFile()
            .equals(other.getFile());
      }
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasScheme()) {
        hash = (37 * hash) + SCHEME_FIELD_NUMBER;
        hash = (53 * hash) + getScheme().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      if (hasFile()) {
        hash = (37 * hash) + FILE_FIELD_NUMBER;
        hash = (53 * hash) + getFile().hashCode();
      }
      if (hasUserInfo()) {
        hash = (37 * hash) + USERINFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.URLProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.URLProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.URLProto.class, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.URLProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        scheme_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        file_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        userInfo_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto result = new org.apache.hadoop.yarn.proto.YarnProtos.URLProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.scheme_ = scheme_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.port_ = port_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.file_ = file_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.userInfo_ = userInfo_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.URLProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.URLProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.URLProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance()) return this;
        if (other.hasScheme()) {
          bitField0_ |= 0x00000001;
          scheme_ = other.scheme_;
          onChanged();
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000002;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        if (other.hasFile()) {
          bitField0_ |= 0x00000008;
          file_ = other.file_;
          onChanged();
        }
        if (other.hasUserInfo()) {
          bitField0_ |= 0x00000010;
          userInfo_ = other.userInfo_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.URLProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string scheme = 1;
      private java.lang.Object scheme_ = "";
      /**
       * <code>optional string scheme = 1;</code>
       */
      public boolean hasScheme() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public java.lang.String getScheme() {
        java.lang.Object ref = scheme_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          scheme_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public com.google.protobuf.ByteString
          getSchemeBytes() {
        java.lang.Object ref = scheme_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          scheme_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder setScheme(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        scheme_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder clearScheme() {
        bitField0_ = (bitField0_ & ~0x00000001);
        scheme_ = getDefaultInstance().getScheme();
        onChanged();
        return this;
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder setSchemeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        scheme_ = value;
        onChanged();
        return this;
      }

      // optional string host = 2;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 2;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 port = 3;
      private int port_ ;
      /**
       * <code>optional int32 port = 3;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000004;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000004);
        port_ = 0;
        onChanged();
        return this;
      }

      // optional string file = 4;
      private java.lang.Object file_ = "";
      /**
       * <code>optional string file = 4;</code>
       */
      public boolean hasFile() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public java.lang.String getFile() {
        java.lang.Object ref = file_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          file_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public com.google.protobuf.ByteString
          getFileBytes() {
        java.lang.Object ref = file_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          file_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder setFile(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        file_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder clearFile() {
        bitField0_ = (bitField0_ & ~0x00000008);
        file_ = getDefaultInstance().getFile();
        onChanged();
        return this;
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder setFileBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        file_ = value;
        onChanged();
        return this;
      }

      // optional string userInfo = 5;
      private java.lang.Object userInfo_ = "";
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public java.lang.String getUserInfo() {
        java.lang.Object ref = userInfo_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          userInfo_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public com.google.protobuf.ByteString
          getUserInfoBytes() {
        java.lang.Object ref = userInfo_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          userInfo_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder setUserInfo(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        userInfo_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000010);
        userInfo_ = getDefaultInstance().getUserInfo();
        onChanged();
        return this;
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder setUserInfoBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        userInfo_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.URLProto)
    }

    static {
      defaultInstance = new URLProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.URLProto)
  }

  public interface LocalResourceProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.URLProto resource = 1;
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource();
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder();

    // optional int64 size = 2;
    /**
     * <code>optional int64 size = 2;</code>
     */
    boolean hasSize();
    /**
     * <code>optional int64 size = 2;</code>
     */
    long getSize();

    // optional int64 timestamp = 3;
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    boolean hasTimestamp();
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    long getTimestamp();

    // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    boolean hasType();
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType();

    // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    boolean hasVisibility();
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility();

    // optional string pattern = 6;
    /**
     * <code>optional string pattern = 6;</code>
     */
    boolean hasPattern();
    /**
     * <code>optional string pattern = 6;</code>
     */
    java.lang.String getPattern();
    /**
     * <code>optional string pattern = 6;</code>
     */
    com.google.protobuf.ByteString
        getPatternBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.LocalResourceProto}
   */
  public static final class LocalResourceProto extends
      com.google.protobuf.GeneratedMessage
      implements LocalResourceProtoOrBuilder {
    // Use LocalResourceProto.newBuilder() to construct.
    private LocalResourceProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private LocalResourceProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final LocalResourceProto defaultInstance;
    public static LocalResourceProto getDefaultInstance() {
      return defaultInstance;
    }

    public LocalResourceProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private LocalResourceProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.URLProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              size_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              timestamp_ = input.readInt64();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                type_ = value;
              }
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto value = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                visibility_ = value;
              }
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              pattern_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder.class);
    }

    public static com.google.protobuf.Parser<LocalResourceProto> PARSER =
        new com.google.protobuf.AbstractParser<LocalResourceProto>() {
      public LocalResourceProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new LocalResourceProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<LocalResourceProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.URLProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.URLProto resource_;
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional int64 size = 2;
    public static final int SIZE_FIELD_NUMBER = 2;
    private long size_;
    /**
     * <code>optional int64 size = 2;</code>
     */
    public boolean hasSize() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 size = 2;</code>
     */
    public long getSize() {
      return size_;
    }

    // optional int64 timestamp = 3;
    public static final int TIMESTAMP_FIELD_NUMBER = 3;
    private long timestamp_;
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    public long getTimestamp() {
      return timestamp_;
    }

    // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
    public static final int TYPE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto type_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType() {
      return type_;
    }

    // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
    public static final int VISIBILITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto visibility_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    public boolean hasVisibility() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility() {
      return visibility_;
    }

    // optional string pattern = 6;
    public static final int PATTERN_FIELD_NUMBER = 6;
    private java.lang.Object pattern_;
    /**
     * <code>optional string pattern = 6;</code>
     */
    public boolean hasPattern() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string pattern = 6;</code>
     */
    public java.lang.String getPattern() {
      java.lang.Object ref = pattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          pattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string pattern = 6;</code>
     */
    public com.google.protobuf.ByteString
        getPatternBytes() {
      java.lang.Object ref = pattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        pattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      size_ = 0L;
      timestamp_ = 0L;
      type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
      visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
      pattern_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, size_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, type_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, visibility_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, getPatternBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, size_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, type_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, visibility_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, getPatternBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto other = (org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasSize() == other.hasSize());
      if (hasSize()) {
        result = result && (getSize()
            == other.getSize());
      }
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasVisibility() == other.hasVisibility());
      if (hasVisibility()) {
        result = result &&
            (getVisibility() == other.getVisibility());
      }
      result = result && (hasPattern() == other.hasPattern());
      if (hasPattern()) {
        result = result && getPattern()
            .equals(other.getPattern());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasSize()) {
        hash = (37 * hash) + SIZE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getSize());
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimestamp());
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getVisibility());
      }
      if (hasPattern()) {
        hash = (37 * hash) + PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getPattern().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LocalResourceProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        size_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
        bitField0_ = (bitField0_ & ~0x00000008);
        visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
        bitField0_ = (bitField0_ & ~0x00000010);
        pattern_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto result = new org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.size_ = size_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.timestamp_ = timestamp_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.visibility_ = visibility_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.pattern_ = pattern_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasSize()) {
          setSize(other.getSize());
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (other.hasPattern()) {
          bitField0_ |= 0x00000020;
          pattern_ = other.pattern_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.URLProto resource = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.URLProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.URLProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.URLProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional int64 size = 2;
      private long size_ ;
      /**
       * <code>optional int64 size = 2;</code>
       */
      public boolean hasSize() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public long getSize() {
        return size_;
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public Builder setSize(long value) {
        bitField0_ |= 0x00000002;
        size_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public Builder clearSize() {
        bitField0_ = (bitField0_ & ~0x00000002);
        size_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 timestamp = 3;
      private long timestamp_ ;
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000004;
        timestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000004);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LocalResourceTypeProto type = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType() {
        return type_;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public Builder setType(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        type_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public boolean hasVisibility() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility() {
        return visibility_;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public Builder setVisibility(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        visibility_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000010);
        visibility_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC;
        onChanged();
        return this;
      }

      // optional string pattern = 6;
      private java.lang.Object pattern_ = "";
      /**
       * <code>optional string pattern = 6;</code>
       */
      public boolean hasPattern() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public java.lang.String getPattern() {
        java.lang.Object ref = pattern_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          pattern_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public com.google.protobuf.ByteString
          getPatternBytes() {
        java.lang.Object ref = pattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          pattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder setPattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        pattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder clearPattern() {
        bitField0_ = (bitField0_ & ~0x00000020);
        pattern_ = getDefaultInstance().getPattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder setPatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        pattern_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LocalResourceProto)
    }

    static {
      defaultInstance = new LocalResourceProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LocalResourceProto)
  }

  public interface ApplicationResourceUsageReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 num_used_containers = 1;
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    boolean hasNumUsedContainers();
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    int getNumUsedContainers();

    // optional int32 num_reserved_containers = 2;
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    boolean hasNumReservedContainers();
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    int getNumReservedContainers();

    // optional .hadoop.yarn.ResourceProto used_resources = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    boolean hasUsedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder();

    // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    boolean hasReservedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder();

    // optional .hadoop.yarn.ResourceProto needed_resources = 5;
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    boolean hasNeededResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationResourceUsageReportProto}
   */
  public static final class ApplicationResourceUsageReportProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationResourceUsageReportProtoOrBuilder {
    // Use ApplicationResourceUsageReportProto.newBuilder() to construct.
    private ApplicationResourceUsageReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationResourceUsageReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationResourceUsageReportProto defaultInstance;
    public static ApplicationResourceUsageReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationResourceUsageReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationResourceUsageReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numUsedContainers_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numReservedContainers_ = input.readInt32();
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = usedResources_.toBuilder();
              }
              usedResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(usedResources_);
                usedResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = reservedResources_.toBuilder();
              }
              reservedResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservedResources_);
                reservedResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = neededResources_.toBuilder();
              }
              neededResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(neededResources_);
                neededResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationResourceUsageReportProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationResourceUsageReportProto>() {
      public ApplicationResourceUsageReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationResourceUsageReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationResourceUsageReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 num_used_containers = 1;
    public static final int NUM_USED_CONTAINERS_FIELD_NUMBER = 1;
    private int numUsedContainers_;
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    public boolean hasNumUsedContainers() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    public int getNumUsedContainers() {
      return numUsedContainers_;
    }

    // optional int32 num_reserved_containers = 2;
    public static final int NUM_RESERVED_CONTAINERS_FIELD_NUMBER = 2;
    private int numReservedContainers_;
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    public boolean hasNumReservedContainers() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    public int getNumReservedContainers() {
      return numReservedContainers_;
    }

    // optional .hadoop.yarn.ResourceProto used_resources = 3;
    public static final int USED_RESOURCES_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto usedResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public boolean hasUsedResources() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources() {
      return usedResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder() {
      return usedResources_;
    }

    // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
    public static final int RESERVED_RESOURCES_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto reservedResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public boolean hasReservedResources() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources() {
      return reservedResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder() {
      return reservedResources_;
    }

    // optional .hadoop.yarn.ResourceProto needed_resources = 5;
    public static final int NEEDED_RESOURCES_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto neededResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public boolean hasNeededResources() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources() {
      return neededResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder() {
      return neededResources_;
    }

    private void initFields() {
      numUsedContainers_ = 0;
      numReservedContainers_ = 0;
      usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, numUsedContainers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numReservedContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, usedResources_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, reservedResources_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, neededResources_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, numUsedContainers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numReservedContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, usedResources_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, reservedResources_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, neededResources_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) obj;

      boolean result = true;
      result = result && (hasNumUsedContainers() == other.hasNumUsedContainers());
      if (hasNumUsedContainers()) {
        result = result && (getNumUsedContainers()
            == other.getNumUsedContainers());
      }
      result = result && (hasNumReservedContainers() == other.hasNumReservedContainers());
      if (hasNumReservedContainers()) {
        result = result && (getNumReservedContainers()
            == other.getNumReservedContainers());
      }
      result = result && (hasUsedResources() == other.hasUsedResources());
      if (hasUsedResources()) {
        result = result && getUsedResources()
            .equals(other.getUsedResources());
      }
      result = result && (hasReservedResources() == other.hasReservedResources());
      if (hasReservedResources()) {
        result = result && getReservedResources()
            .equals(other.getReservedResources());
      }
      result = result && (hasNeededResources() == other.hasNeededResources());
      if (hasNeededResources()) {
        result = result && getNeededResources()
            .equals(other.getNeededResources());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumUsedContainers()) {
        hash = (37 * hash) + NUM_USED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumUsedContainers();
      }
      if (hasNumReservedContainers()) {
        hash = (37 * hash) + NUM_RESERVED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumReservedContainers();
      }
      if (hasUsedResources()) {
        hash = (37 * hash) + USED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getUsedResources().hashCode();
      }
      if (hasReservedResources()) {
        hash = (37 * hash) + RESERVED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getReservedResources().hashCode();
      }
      if (hasNeededResources()) {
        hash = (37 * hash) + NEEDED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getNeededResources().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationResourceUsageReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUsedResourcesFieldBuilder();
          getReservedResourcesFieldBuilder();
          getNeededResourcesFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        numUsedContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        numReservedContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (usedResourcesBuilder_ == null) {
          usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          usedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          reservedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (neededResourcesBuilder_ == null) {
          neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          neededResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numUsedContainers_ = numUsedContainers_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numReservedContainers_ = numReservedContainers_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (usedResourcesBuilder_ == null) {
          result.usedResources_ = usedResources_;
        } else {
          result.usedResources_ = usedResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (reservedResourcesBuilder_ == null) {
          result.reservedResources_ = reservedResources_;
        } else {
          result.reservedResources_ = reservedResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (neededResourcesBuilder_ == null) {
          result.neededResources_ = neededResources_;
        } else {
          result.neededResources_ = neededResourcesBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance()) return this;
        if (other.hasNumUsedContainers()) {
          setNumUsedContainers(other.getNumUsedContainers());
        }
        if (other.hasNumReservedContainers()) {
          setNumReservedContainers(other.getNumReservedContainers());
        }
        if (other.hasUsedResources()) {
          mergeUsedResources(other.getUsedResources());
        }
        if (other.hasReservedResources()) {
          mergeReservedResources(other.getReservedResources());
        }
        if (other.hasNeededResources()) {
          mergeNeededResources(other.getNeededResources());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 num_used_containers = 1;
      private int numUsedContainers_ ;
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public boolean hasNumUsedContainers() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public int getNumUsedContainers() {
        return numUsedContainers_;
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public Builder setNumUsedContainers(int value) {
        bitField0_ |= 0x00000001;
        numUsedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public Builder clearNumUsedContainers() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numUsedContainers_ = 0;
        onChanged();
        return this;
      }

      // optional int32 num_reserved_containers = 2;
      private int numReservedContainers_ ;
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public boolean hasNumReservedContainers() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public int getNumReservedContainers() {
        return numReservedContainers_;
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public Builder setNumReservedContainers(int value) {
        bitField0_ |= 0x00000002;
        numReservedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public Builder clearNumReservedContainers() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numReservedContainers_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto used_resources = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> usedResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public boolean hasUsedResources() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources() {
        if (usedResourcesBuilder_ == null) {
          return usedResources_;
        } else {
          return usedResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder setUsedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          usedResources_ = value;
          onChanged();
        } else {
          usedResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder setUsedResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (usedResourcesBuilder_ == null) {
          usedResources_ = builderForValue.build();
          onChanged();
        } else {
          usedResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder mergeUsedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              usedResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            usedResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(usedResources_).mergeFrom(value).buildPartial();
          } else {
            usedResources_ = value;
          }
          onChanged();
        } else {
          usedResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder clearUsedResources() {
        if (usedResourcesBuilder_ == null) {
          usedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          usedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getUsedResourcesBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getUsedResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder() {
        if (usedResourcesBuilder_ != null) {
          return usedResourcesBuilder_.getMessageOrBuilder();
        } else {
          return usedResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getUsedResourcesFieldBuilder() {
        if (usedResourcesBuilder_ == null) {
          usedResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  usedResources_,
                  getParentForChildren(),
                  isClean());
          usedResources_ = null;
        }
        return usedResourcesBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto reserved_resources = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> reservedResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public boolean hasReservedResources() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources() {
        if (reservedResourcesBuilder_ == null) {
          return reservedResources_;
        } else {
          return reservedResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder setReservedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (reservedResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservedResources_ = value;
          onChanged();
        } else {
          reservedResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder setReservedResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = builderForValue.build();
          onChanged();
        } else {
          reservedResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder mergeReservedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (reservedResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              reservedResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            reservedResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(reservedResources_).mergeFrom(value).buildPartial();
          } else {
            reservedResources_ = value;
          }
          onChanged();
        } else {
          reservedResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder clearReservedResources() {
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          reservedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getReservedResourcesBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getReservedResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder() {
        if (reservedResourcesBuilder_ != null) {
          return reservedResourcesBuilder_.getMessageOrBuilder();
        } else {
          return reservedResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getReservedResourcesFieldBuilder() {
        if (reservedResourcesBuilder_ == null) {
          reservedResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  reservedResources_,
                  getParentForChildren(),
                  isClean());
          reservedResources_ = null;
        }
        return reservedResourcesBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto needed_resources = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> neededResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public boolean hasNeededResources() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources() {
        if (neededResourcesBuilder_ == null) {
          return neededResources_;
        } else {
          return neededResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder setNeededResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (neededResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          neededResources_ = value;
          onChanged();
        } else {
          neededResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder setNeededResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (neededResourcesBuilder_ == null) {
          neededResources_ = builderForValue.build();
          onChanged();
        } else {
          neededResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder mergeNeededResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (neededResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              neededResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            neededResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(neededResources_).mergeFrom(value).buildPartial();
          } else {
            neededResources_ = value;
          }
          onChanged();
        } else {
          neededResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder clearNeededResources() {
        if (neededResourcesBuilder_ == null) {
          neededResources_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          neededResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getNeededResourcesBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getNeededResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder() {
        if (neededResourcesBuilder_ != null) {
          return neededResourcesBuilder_.getMessageOrBuilder();
        } else {
          return neededResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getNeededResourcesFieldBuilder() {
        if (neededResourcesBuilder_ == null) {
          neededResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  neededResources_,
                  getParentForChildren(),
                  isClean());
          neededResources_ = null;
        }
        return neededResourcesBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
    }

    static {
      defaultInstance = new ApplicationResourceUsageReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
  }

  public interface ApplicationReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional string user = 2;
    /**
     * <code>optional string user = 2;</code>
     */
    boolean hasUser();
    /**
     * <code>optional string user = 2;</code>
     */
    java.lang.String getUser();
    /**
     * <code>optional string user = 2;</code>
     */
    com.google.protobuf.ByteString
        getUserBytes();

    // optional string queue = 3;
    /**
     * <code>optional string queue = 3;</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 3;</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 3;</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    // optional string name = 4;
    /**
     * <code>optional string name = 4;</code>
     */
    boolean hasName();
    /**
     * <code>optional string name = 4;</code>
     */
    java.lang.String getName();
    /**
     * <code>optional string name = 4;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional string host = 5;
    /**
     * <code>optional string host = 5;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 5;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 5;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 rpc_port = 6;
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    boolean hasRpcPort();
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    int getRpcPort();

    // optional .hadoop.common.TokenProto client_to_am_token = 7;
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    boolean hasClientToAmToken();
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken();
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder();

    // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    boolean hasYarnApplicationState();
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState();

    // optional string trackingUrl = 9;
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();

    // optional string diagnostics = 10 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    // optional int64 startTime = 11;
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    long getStartTime();

    // optional int64 finishTime = 12;
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    boolean hasFinishTime();
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    long getFinishTime();

    // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    boolean hasFinalApplicationStatus();
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus();

    // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    boolean hasAppResourceUsage();
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage();
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder();

    // optional string originalTrackingUrl = 15;
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    boolean hasOriginalTrackingUrl();
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    java.lang.String getOriginalTrackingUrl();
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes();

    // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    boolean hasCurrentApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder();

    // optional float progress = 17;
    /**
     * <code>optional float progress = 17;</code>
     */
    boolean hasProgress();
    /**
     * <code>optional float progress = 17;</code>
     */
    float getProgress();

    // optional string applicationType = 18;
    /**
     * <code>optional string applicationType = 18;</code>
     */
    boolean hasApplicationType();
    /**
     * <code>optional string applicationType = 18;</code>
     */
    java.lang.String getApplicationType();
    /**
     * <code>optional string applicationType = 18;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypeBytes();

    // optional .hadoop.common.TokenProto am_rm_token = 19;
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    boolean hasAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationReportProto}
   */
  public static final class ApplicationReportProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationReportProtoOrBuilder {
    // Use ApplicationReportProto.newBuilder() to construct.
    private ApplicationReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationReportProto defaultInstance;
    public static ApplicationReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              user_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              queue_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              name_ = input.readBytes();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              host_ = input.readBytes();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              rpcPort_ = input.readInt32();
              break;
            }
            case 58: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = clientToAmToken_.toBuilder();
              }
              clientToAmToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(clientToAmToken_);
                clientToAmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 64: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(8, rawValue);
              } else {
                bitField0_ |= 0x00000080;
                yarnApplicationState_ = value;
              }
              break;
            }
            case 74: {
              bitField0_ |= 0x00000100;
              trackingUrl_ = input.readBytes();
              break;
            }
            case 82: {
              bitField0_ |= 0x00000200;
              diagnostics_ = input.readBytes();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              startTime_ = input.readInt64();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              finishTime_ = input.readInt64();
              break;
            }
            case 104: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(13, rawValue);
              } else {
                bitField0_ |= 0x00001000;
                finalApplicationStatus_ = value;
              }
              break;
            }
            case 114: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00002000) == 0x00002000)) {
                subBuilder = appResourceUsage_.toBuilder();
              }
              appResourceUsage_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appResourceUsage_);
                appResourceUsage_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00002000;
              break;
            }
            case 122: {
              bitField0_ |= 0x00004000;
              originalTrackingUrl_ = input.readBytes();
              break;
            }
            case 130: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00008000) == 0x00008000)) {
                subBuilder = currentApplicationAttemptId_.toBuilder();
              }
              currentApplicationAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(currentApplicationAttemptId_);
                currentApplicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00008000;
              break;
            }
            case 141: {
              bitField0_ |= 0x00010000;
              progress_ = input.readFloat();
              break;
            }
            case 146: {
              bitField0_ |= 0x00020000;
              applicationType_ = input.readBytes();
              break;
            }
            case 154: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00040000) == 0x00040000)) {
                subBuilder = amRmToken_.toBuilder();
              }
              amRmToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amRmToken_);
                amRmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00040000;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationReportProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationReportProto>() {
      public ApplicationReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional string user = 2;
    public static final int USER_FIELD_NUMBER = 2;
    private java.lang.Object user_;
    /**
     * <code>optional string user = 2;</code>
     */
    public boolean hasUser() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string user = 2;</code>
     */
    public java.lang.String getUser() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          user_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string user = 2;</code>
     */
    public com.google.protobuf.ByteString
        getUserBytes() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        user_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string queue = 3;
    public static final int QUEUE_FIELD_NUMBER = 3;
    private java.lang.Object queue_;
    /**
     * <code>optional string queue = 3;</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 3;</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 3;</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string name = 4;
    public static final int NAME_FIELD_NUMBER = 4;
    private java.lang.Object name_;
    /**
     * <code>optional string name = 4;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string name = 4;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string name = 4;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string host = 5;
    public static final int HOST_FIELD_NUMBER = 5;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 5;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string host = 5;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 5;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 rpc_port = 6;
    public static final int RPC_PORT_FIELD_NUMBER = 6;
    private int rpcPort_;
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    public int getRpcPort() {
      return rpcPort_;
    }

    // optional .hadoop.common.TokenProto client_to_am_token = 7;
    public static final int CLIENT_TO_AM_TOKEN_FIELD_NUMBER = 7;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto clientToAmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public boolean hasClientToAmToken() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken() {
      return clientToAmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder() {
      return clientToAmToken_;
    }

    // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
    public static final int YARN_APPLICATION_STATE_FIELD_NUMBER = 8;
    private org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto yarnApplicationState_;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    public boolean hasYarnApplicationState() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState() {
      return yarnApplicationState_;
    }

    // optional string trackingUrl = 9;
    public static final int TRACKINGURL_FIELD_NUMBER = 9;
    private java.lang.Object trackingUrl_;
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string diagnostics = 10 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 10;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 startTime = 11;
    public static final int STARTTIME_FIELD_NUMBER = 11;
    private long startTime_;
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    // optional int64 finishTime = 12;
    public static final int FINISHTIME_FIELD_NUMBER = 12;
    private long finishTime_;
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    public boolean hasFinishTime() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    public long getFinishTime() {
      return finishTime_;
    }

    // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
    public static final int FINAL_APPLICATION_STATUS_FIELD_NUMBER = 13;
    private org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto finalApplicationStatus_;
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    public boolean hasFinalApplicationStatus() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
      return finalApplicationStatus_;
    }

    // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
    public static final int APP_RESOURCE_USAGE_FIELD_NUMBER = 14;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto appResourceUsage_;
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public boolean hasAppResourceUsage() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage() {
      return appResourceUsage_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder() {
      return appResourceUsage_;
    }

    // optional string originalTrackingUrl = 15;
    public static final int ORIGINALTRACKINGURL_FIELD_NUMBER = 15;
    private java.lang.Object originalTrackingUrl_;
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public boolean hasOriginalTrackingUrl() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public java.lang.String getOriginalTrackingUrl() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          originalTrackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        originalTrackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
    public static final int CURRENTAPPLICATIONATTEMPTID_FIELD_NUMBER = 16;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto currentApplicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public boolean hasCurrentApplicationAttemptId() {
      return ((bitField0_ & 0x00008000) == 0x00008000);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId() {
      return currentApplicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder() {
      return currentApplicationAttemptId_;
    }

    // optional float progress = 17;
    public static final int PROGRESS_FIELD_NUMBER = 17;
    private float progress_;
    /**
     * <code>optional float progress = 17;</code>
     */
    public boolean hasProgress() {
      return ((bitField0_ & 0x00010000) == 0x00010000);
    }
    /**
     * <code>optional float progress = 17;</code>
     */
    public float getProgress() {
      return progress_;
    }

    // optional string applicationType = 18;
    public static final int APPLICATIONTYPE_FIELD_NUMBER = 18;
    private java.lang.Object applicationType_;
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public boolean hasApplicationType() {
      return ((bitField0_ & 0x00020000) == 0x00020000);
    }
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public java.lang.String getApplicationType() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationType_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypeBytes() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.common.TokenProto am_rm_token = 19;
    public static final int AM_RM_TOKEN_FIELD_NUMBER = 19;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public boolean hasAmRmToken() {
      return ((bitField0_ & 0x00040000) == 0x00040000);
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
      return amRmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
      return amRmToken_;
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      user_ = "";
      queue_ = "";
      name_ = "";
      host_ = "";
      rpcPort_ = 0;
      clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
      trackingUrl_ = "";
      diagnostics_ = "N/A";
      startTime_ = 0L;
      finishTime_ = 0L;
      finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
      appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      originalTrackingUrl_ = "";
      currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      progress_ = 0F;
      applicationType_ = "";
      amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasClientToAmToken()) {
        if (!getClientToAmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasAmRmToken()) {
        if (!getAmRmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getUserBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getNameBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getHostBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, rpcPort_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(7, clientToAmToken_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeEnum(8, yarnApplicationState_.getNumber());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeBytes(9, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeBytes(10, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeInt64(11, startTime_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeInt64(12, finishTime_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeEnum(13, finalApplicationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeMessage(14, appResourceUsage_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        output.writeBytes(15, getOriginalTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        output.writeMessage(16, currentApplicationAttemptId_);
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        output.writeFloat(17, progress_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        output.writeBytes(18, getApplicationTypeBytes());
      }
      if (((bitField0_ & 0x00040000) == 0x00040000)) {
        output.writeMessage(19, amRmToken_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getUserBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getNameBytes());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getHostBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, rpcPort_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, clientToAmToken_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(8, yarnApplicationState_.getNumber());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(9, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(10, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(11, startTime_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(12, finishTime_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(13, finalApplicationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, appResourceUsage_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(15, getOriginalTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, currentApplicationAttemptId_);
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(17, progress_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(18, getApplicationTypeBytes());
      }
      if (((bitField0_ & 0x00040000) == 0x00040000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, amRmToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasUser() == other.hasUser());
      if (hasUser()) {
        result = result && getUser()
            .equals(other.getUser());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasClientToAmToken() == other.hasClientToAmToken());
      if (hasClientToAmToken()) {
        result = result && getClientToAmToken()
            .equals(other.getClientToAmToken());
      }
      result = result && (hasYarnApplicationState() == other.hasYarnApplicationState());
      if (hasYarnApplicationState()) {
        result = result &&
            (getYarnApplicationState() == other.getYarnApplicationState());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasFinishTime() == other.hasFinishTime());
      if (hasFinishTime()) {
        result = result && (getFinishTime()
            == other.getFinishTime());
      }
      result = result && (hasFinalApplicationStatus() == other.hasFinalApplicationStatus());
      if (hasFinalApplicationStatus()) {
        result = result &&
            (getFinalApplicationStatus() == other.getFinalApplicationStatus());
      }
      result = result && (hasAppResourceUsage() == other.hasAppResourceUsage());
      if (hasAppResourceUsage()) {
        result = result && getAppResourceUsage()
            .equals(other.getAppResourceUsage());
      }
      result = result && (hasOriginalTrackingUrl() == other.hasOriginalTrackingUrl());
      if (hasOriginalTrackingUrl()) {
        result = result && getOriginalTrackingUrl()
            .equals(other.getOriginalTrackingUrl());
      }
      result = result && (hasCurrentApplicationAttemptId() == other.hasCurrentApplicationAttemptId());
      if (hasCurrentApplicationAttemptId()) {
        result = result && getCurrentApplicationAttemptId()
            .equals(other.getCurrentApplicationAttemptId());
      }
      result = result && (hasProgress() == other.hasProgress());
      if (hasProgress()) {
        result = result && (Float.floatToIntBits(getProgress())    == Float.floatToIntBits(other.getProgress()));
      }
      result = result && (hasApplicationType() == other.hasApplicationType());
      if (hasApplicationType()) {
        result = result && getApplicationType()
            .equals(other.getApplicationType());
      }
      result = result && (hasAmRmToken() == other.hasAmRmToken());
      if (hasAmRmToken()) {
        result = result && getAmRmToken()
            .equals(other.getAmRmToken());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasUser()) {
        hash = (37 * hash) + USER_FIELD_NUMBER;
        hash = (53 * hash) + getUser().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasClientToAmToken()) {
        hash = (37 * hash) + CLIENT_TO_AM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getClientToAmToken().hashCode();
      }
      if (hasYarnApplicationState()) {
        hash = (37 * hash) + YARN_APPLICATION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getYarnApplicationState());
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKINGURL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasStartTime()) {
        hash = (37 * hash) + STARTTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStartTime());
      }
      if (hasFinishTime()) {
        hash = (37 * hash) + FINISHTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getFinishTime());
      }
      if (hasFinalApplicationStatus()) {
        hash = (37 * hash) + FINAL_APPLICATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getFinalApplicationStatus());
      }
      if (hasAppResourceUsage()) {
        hash = (37 * hash) + APP_RESOURCE_USAGE_FIELD_NUMBER;
        hash = (53 * hash) + getAppResourceUsage().hashCode();
      }
      if (hasOriginalTrackingUrl()) {
        hash = (37 * hash) + ORIGINALTRACKINGURL_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalTrackingUrl().hashCode();
      }
      if (hasCurrentApplicationAttemptId()) {
        hash = (37 * hash) + CURRENTAPPLICATIONATTEMPTID_FIELD_NUMBER;
        hash = (53 * hash) + getCurrentApplicationAttemptId().hashCode();
      }
      if (hasProgress()) {
        hash = (37 * hash) + PROGRESS_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getProgress());
      }
      if (hasApplicationType()) {
        hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationType().hashCode();
      }
      if (hasAmRmToken()) {
        hash = (37 * hash) + AM_RM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getAmRmToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getClientToAmTokenFieldBuilder();
          getAppResourceUsageFieldBuilder();
          getCurrentApplicationAttemptIdFieldBuilder();
          getAmRmTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        user_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        queue_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          clientToAmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
        bitField0_ = (bitField0_ & ~0x00000080);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000100);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000200);
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        finishTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000800);
        finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
        bitField0_ = (bitField0_ & ~0x00001000);
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
        } else {
          appResourceUsageBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        originalTrackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00004000);
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          currentApplicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00008000);
        progress_ = 0F;
        bitField0_ = (bitField0_ & ~0x00010000);
        applicationType_ = "";
        bitField0_ = (bitField0_ & ~0x00020000);
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.user_ = user_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        if (clientToAmTokenBuilder_ == null) {
          result.clientToAmToken_ = clientToAmToken_;
        } else {
          result.clientToAmToken_ = clientToAmTokenBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.yarnApplicationState_ = yarnApplicationState_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.finishTime_ = finishTime_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00001000;
        }
        result.finalApplicationStatus_ = finalApplicationStatus_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00002000;
        }
        if (appResourceUsageBuilder_ == null) {
          result.appResourceUsage_ = appResourceUsage_;
        } else {
          result.appResourceUsage_ = appResourceUsageBuilder_.build();
        }
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.originalTrackingUrl_ = originalTrackingUrl_;
        if (((from_bitField0_ & 0x00008000) == 0x00008000)) {
          to_bitField0_ |= 0x00008000;
        }
        if (currentApplicationAttemptIdBuilder_ == null) {
          result.currentApplicationAttemptId_ = currentApplicationAttemptId_;
        } else {
          result.currentApplicationAttemptId_ = currentApplicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00010000) == 0x00010000)) {
          to_bitField0_ |= 0x00010000;
        }
        result.progress_ = progress_;
        if (((from_bitField0_ & 0x00020000) == 0x00020000)) {
          to_bitField0_ |= 0x00020000;
        }
        result.applicationType_ = applicationType_;
        if (((from_bitField0_ & 0x00040000) == 0x00040000)) {
          to_bitField0_ |= 0x00040000;
        }
        if (amRmTokenBuilder_ == null) {
          result.amRmToken_ = amRmToken_;
        } else {
          result.amRmToken_ = amRmTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasUser()) {
          bitField0_ |= 0x00000002;
          user_ = other.user_;
          onChanged();
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000004;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasName()) {
          bitField0_ |= 0x00000008;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000010;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasClientToAmToken()) {
          mergeClientToAmToken(other.getClientToAmToken());
        }
        if (other.hasYarnApplicationState()) {
          setYarnApplicationState(other.getYarnApplicationState());
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000100;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000200;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasFinishTime()) {
          setFinishTime(other.getFinishTime());
        }
        if (other.hasFinalApplicationStatus()) {
          setFinalApplicationStatus(other.getFinalApplicationStatus());
        }
        if (other.hasAppResourceUsage()) {
          mergeAppResourceUsage(other.getAppResourceUsage());
        }
        if (other.hasOriginalTrackingUrl()) {
          bitField0_ |= 0x00004000;
          originalTrackingUrl_ = other.originalTrackingUrl_;
          onChanged();
        }
        if (other.hasCurrentApplicationAttemptId()) {
          mergeCurrentApplicationAttemptId(other.getCurrentApplicationAttemptId());
        }
        if (other.hasProgress()) {
          setProgress(other.getProgress());
        }
        if (other.hasApplicationType()) {
          bitField0_ |= 0x00020000;
          applicationType_ = other.applicationType_;
          onChanged();
        }
        if (other.hasAmRmToken()) {
          mergeAmRmToken(other.getAmRmToken());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasClientToAmToken()) {
          if (!getClientToAmToken().isInitialized()) {
            
            return false;
          }
        }
        if (hasAmRmToken()) {
          if (!getAmRmToken().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto applicationId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional string user = 2;
      private java.lang.Object user_ = "";
      /**
       * <code>optional string user = 2;</code>
       */
      public boolean hasUser() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public java.lang.String getUser() {
        java.lang.Object ref = user_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          user_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public com.google.protobuf.ByteString
          getUserBytes() {
        java.lang.Object ref = user_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          user_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder setUser(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        user_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder clearUser() {
        bitField0_ = (bitField0_ & ~0x00000002);
        user_ = getDefaultInstance().getUser();
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder setUserBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        user_ = value;
        onChanged();
        return this;
      }

      // optional string queue = 3;
      private java.lang.Object queue_ = "";
      /**
       * <code>optional string queue = 3;</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queue_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000004);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }

      // optional string name = 4;
      private java.lang.Object name_ = "";
      /**
       * <code>optional string name = 4;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000008);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        name_ = value;
        onChanged();
        return this;
      }

      // optional string host = 5;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 5;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000010);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 rpc_port = 6;
      private int rpcPort_ ;
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public int getRpcPort() {
        return rpcPort_;
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000020;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000020);
        rpcPort_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.common.TokenProto client_to_am_token = 7;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> clientToAmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public boolean hasClientToAmToken() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken() {
        if (clientToAmTokenBuilder_ == null) {
          return clientToAmToken_;
        } else {
          return clientToAmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder setClientToAmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (clientToAmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clientToAmToken_ = value;
          onChanged();
        } else {
          clientToAmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder setClientToAmToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = builderForValue.build();
          onChanged();
        } else {
          clientToAmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder mergeClientToAmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (clientToAmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              clientToAmToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            clientToAmToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(clientToAmToken_).mergeFrom(value).buildPartial();
          } else {
            clientToAmToken_ = value;
          }
          onChanged();
        } else {
          clientToAmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder clearClientToAmToken() {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          clientToAmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getClientToAmTokenBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getClientToAmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder() {
        if (clientToAmTokenBuilder_ != null) {
          return clientToAmTokenBuilder_.getMessageOrBuilder();
        } else {
          return clientToAmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getClientToAmTokenFieldBuilder() {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  clientToAmToken_,
                  getParentForChildren(),
                  isClean());
          clientToAmToken_ = null;
        }
        return clientToAmTokenBuilder_;
      }

      // optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;
      private org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public boolean hasYarnApplicationState() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState() {
        return yarnApplicationState_;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public Builder setYarnApplicationState(org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000080;
        yarnApplicationState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public Builder clearYarnApplicationState() {
        bitField0_ = (bitField0_ & ~0x00000080);
        yarnApplicationState_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW;
        onChanged();
        return this;
      }

      // optional string trackingUrl = 9;
      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          trackingUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000100);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        trackingUrl_ = value;
        onChanged();
        return this;
      }

      // optional string diagnostics = 10 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000200);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // optional int64 startTime = 11;
      private long startTime_ ;
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000400;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000400);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      // optional int64 finishTime = 12;
      private long finishTime_ ;
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public boolean hasFinishTime() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public long getFinishTime() {
        return finishTime_;
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public Builder setFinishTime(long value) {
        bitField0_ |= 0x00000800;
        finishTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public Builder clearFinishTime() {
        bitField0_ = (bitField0_ & ~0x00000800);
        finishTime_ = 0L;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;
      private org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public boolean hasFinalApplicationStatus() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
        return finalApplicationStatus_;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public Builder setFinalApplicationStatus(org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00001000;
        finalApplicationStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public Builder clearFinalApplicationStatus() {
        bitField0_ = (bitField0_ & ~0x00001000);
        finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder> appResourceUsageBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public boolean hasAppResourceUsage() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage() {
        if (appResourceUsageBuilder_ == null) {
          return appResourceUsage_;
        } else {
          return appResourceUsageBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder setAppResourceUsage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto value) {
        if (appResourceUsageBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appResourceUsage_ = value;
          onChanged();
        } else {
          appResourceUsageBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder setAppResourceUsage(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder builderForValue) {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = builderForValue.build();
          onChanged();
        } else {
          appResourceUsageBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder mergeAppResourceUsage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto value) {
        if (appResourceUsageBuilder_ == null) {
          if (((bitField0_ & 0x00002000) == 0x00002000) &&
              appResourceUsage_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance()) {
            appResourceUsage_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.newBuilder(appResourceUsage_).mergeFrom(value).buildPartial();
          } else {
            appResourceUsage_ = value;
          }
          onChanged();
        } else {
          appResourceUsageBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder clearAppResourceUsage() {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
          onChanged();
        } else {
          appResourceUsageBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder getAppResourceUsageBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getAppResourceUsageFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder() {
        if (appResourceUsageBuilder_ != null) {
          return appResourceUsageBuilder_.getMessageOrBuilder();
        } else {
          return appResourceUsage_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder> 
          getAppResourceUsageFieldBuilder() {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsageBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder>(
                  appResourceUsage_,
                  getParentForChildren(),
                  isClean());
          appResourceUsage_ = null;
        }
        return appResourceUsageBuilder_;
      }

      // optional string originalTrackingUrl = 15;
      private java.lang.Object originalTrackingUrl_ = "";
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public boolean hasOriginalTrackingUrl() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public java.lang.String getOriginalTrackingUrl() {
        java.lang.Object ref = originalTrackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          originalTrackingUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public com.google.protobuf.ByteString
          getOriginalTrackingUrlBytes() {
        java.lang.Object ref = originalTrackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          originalTrackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder setOriginalTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00004000;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder clearOriginalTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00004000);
        originalTrackingUrl_ = getDefaultInstance().getOriginalTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder setOriginalTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00004000;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> currentApplicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public boolean hasCurrentApplicationAttemptId() {
        return ((bitField0_ & 0x00008000) == 0x00008000);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          return currentApplicationAttemptId_;
        } else {
          return currentApplicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder setCurrentApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          currentApplicationAttemptId_ = value;
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder setCurrentApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder mergeCurrentApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00008000) == 0x00008000) &&
              currentApplicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            currentApplicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(currentApplicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            currentApplicationAttemptId_ = value;
          }
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder clearCurrentApplicationAttemptId() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00008000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getCurrentApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00008000;
        onChanged();
        return getCurrentApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder() {
        if (currentApplicationAttemptIdBuilder_ != null) {
          return currentApplicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return currentApplicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getCurrentApplicationAttemptIdFieldBuilder() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  currentApplicationAttemptId_,
                  getParentForChildren(),
                  isClean());
          currentApplicationAttemptId_ = null;
        }
        return currentApplicationAttemptIdBuilder_;
      }

      // optional float progress = 17;
      private float progress_ ;
      /**
       * <code>optional float progress = 17;</code>
       */
      public boolean hasProgress() {
        return ((bitField0_ & 0x00010000) == 0x00010000);
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public float getProgress() {
        return progress_;
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public Builder setProgress(float value) {
        bitField0_ |= 0x00010000;
        progress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public Builder clearProgress() {
        bitField0_ = (bitField0_ & ~0x00010000);
        progress_ = 0F;
        onChanged();
        return this;
      }

      // optional string applicationType = 18;
      private java.lang.Object applicationType_ = "";
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public boolean hasApplicationType() {
        return ((bitField0_ & 0x00020000) == 0x00020000);
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public java.lang.String getApplicationType() {
        java.lang.Object ref = applicationType_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationType_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypeBytes() {
        java.lang.Object ref = applicationType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder setApplicationType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00020000;
        applicationType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder clearApplicationType() {
        bitField0_ = (bitField0_ & ~0x00020000);
        applicationType_ = getDefaultInstance().getApplicationType();
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder setApplicationTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00020000;
        applicationType_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.common.TokenProto am_rm_token = 19;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> amRmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public boolean hasAmRmToken() {
        return ((bitField0_ & 0x00040000) == 0x00040000);
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          return amRmToken_;
        } else {
          return amRmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder setAmRmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amRmToken_ = value;
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder setAmRmToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = builderForValue.build();
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder mergeAmRmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00040000) == 0x00040000) &&
              amRmToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            amRmToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(amRmToken_).mergeFrom(value).buildPartial();
          } else {
            amRmToken_ = value;
          }
          onChanged();
        } else {
          amRmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder clearAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getAmRmTokenBuilder() {
        bitField0_ |= 0x00040000;
        onChanged();
        return getAmRmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
        if (amRmTokenBuilder_ != null) {
          return amRmTokenBuilder_.getMessageOrBuilder();
        } else {
          return amRmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getAmRmTokenFieldBuilder() {
        if (amRmTokenBuilder_ == null) {
          amRmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  amRmToken_,
                  getParentForChildren(),
                  isClean());
          amRmToken_ = null;
        }
        return amRmTokenBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationReportProto)
    }

    static {
      defaultInstance = new ApplicationReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationReportProto)
  }

  public interface NodeIdProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string host = 1;
    /**
     * <code>optional string host = 1;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 1;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 1;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    // optional int32 port = 2;
    /**
     * <code>optional int32 port = 2;</code>
     */
    boolean hasPort();
    /**
     * <code>optional int32 port = 2;</code>
     */
    int getPort();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeIdProto}
   */
  public static final class NodeIdProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeIdProtoOrBuilder {
    // Use NodeIdProto.newBuilder() to construct.
    private NodeIdProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeIdProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeIdProto defaultInstance;
    public static NodeIdProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeIdProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              host_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              port_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeIdProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeIdProto>() {
      public NodeIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeIdProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeIdProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string host = 1;
    public static final int HOST_FIELD_NUMBER = 1;
    private java.lang.Object host_;
    /**
     * <code>optional string host = 1;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 port = 2;
    public static final int PORT_FIELD_NUMBER = 2;
    private int port_;
    /**
     * <code>optional int32 port = 2;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 port = 2;</code>
     */
    public int getPort() {
      return port_;
    }

    private void initFields() {
      host_ = "";
      port_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getHostBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, port_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getHostBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, port_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) obj;

      boolean result = true;
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.port_ = port_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) return this;
        if (other.hasHost()) {
          bitField0_ |= 0x00000001;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string host = 1;
      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 1;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }

      // optional int32 port = 2;
      private int port_ ;
      /**
       * <code>optional int32 port = 2;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000002;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeIdProto)
    }

    static {
      defaultInstance = new NodeIdProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeIdProto)
  }

  public interface NodeReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto nodeId = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional string httpAddress = 2;
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    boolean hasHttpAddress();
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    java.lang.String getHttpAddress();
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    com.google.protobuf.ByteString
        getHttpAddressBytes();

    // optional string rackName = 3;
    /**
     * <code>optional string rackName = 3;</code>
     */
    boolean hasRackName();
    /**
     * <code>optional string rackName = 3;</code>
     */
    java.lang.String getRackName();
    /**
     * <code>optional string rackName = 3;</code>
     */
    com.google.protobuf.ByteString
        getRackNameBytes();

    // optional .hadoop.yarn.ResourceProto used = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    boolean hasUsed();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 5;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional int32 numContainers = 6;
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    int getNumContainers();

    // optional .hadoop.yarn.NodeStateProto node_state = 7;
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    boolean hasNodeState();
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState();

    // optional string health_report = 8;
    /**
     * <code>optional string health_report = 8;</code>
     */
    boolean hasHealthReport();
    /**
     * <code>optional string health_report = 8;</code>
     */
    java.lang.String getHealthReport();
    /**
     * <code>optional string health_report = 8;</code>
     */
    com.google.protobuf.ByteString
        getHealthReportBytes();

    // optional int64 last_health_report_time = 9;
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    boolean hasLastHealthReportTime();
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    long getLastHealthReportTime();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeReportProto}
   */
  public static final class NodeReportProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeReportProtoOrBuilder {
    // Use NodeReportProto.newBuilder() to construct.
    private NodeReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeReportProto defaultInstance;
    public static NodeReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              httpAddress_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              rackName_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = used_.toBuilder();
              }
              used_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(used_);
                used_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              numContainers_ = input.readInt32();
              break;
            }
            case 56: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(7, rawValue);
              } else {
                bitField0_ |= 0x00000040;
                nodeState_ = value;
              }
              break;
            }
            case 66: {
              bitField0_ |= 0x00000080;
              healthReport_ = input.readBytes();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              lastHealthReportTime_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeReportProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeReportProto>() {
      public NodeReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto nodeId = 1;
    public static final int NODEID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional string httpAddress = 2;
    public static final int HTTPADDRESS_FIELD_NUMBER = 2;
    private java.lang.Object httpAddress_;
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public boolean hasHttpAddress() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public java.lang.String getHttpAddress() {
      java.lang.Object ref = httpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          httpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHttpAddressBytes() {
      java.lang.Object ref = httpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        httpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string rackName = 3;
    public static final int RACKNAME_FIELD_NUMBER = 3;
    private java.lang.Object rackName_;
    /**
     * <code>optional string rackName = 3;</code>
     */
    public boolean hasRackName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string rackName = 3;</code>
     */
    public java.lang.String getRackName() {
      java.lang.Object ref = rackName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rackName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string rackName = 3;</code>
     */
    public com.google.protobuf.ByteString
        getRackNameBytes() {
      java.lang.Object ref = rackName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rackName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ResourceProto used = 4;
    public static final int USED_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto used_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public boolean hasUsed() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed() {
      return used_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder() {
      return used_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 5;
    public static final int CAPABILITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional int32 numContainers = 6;
    public static final int NUMCONTAINERS_FIELD_NUMBER = 6;
    private int numContainers_;
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    // optional .hadoop.yarn.NodeStateProto node_state = 7;
    public static final int NODE_STATE_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto nodeState_;
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    public boolean hasNodeState() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState() {
      return nodeState_;
    }

    // optional string health_report = 8;
    public static final int HEALTH_REPORT_FIELD_NUMBER = 8;
    private java.lang.Object healthReport_;
    /**
     * <code>optional string health_report = 8;</code>
     */
    public boolean hasHealthReport() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string health_report = 8;</code>
     */
    public java.lang.String getHealthReport() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          healthReport_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string health_report = 8;</code>
     */
    public com.google.protobuf.ByteString
        getHealthReportBytes() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        healthReport_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 last_health_report_time = 9;
    public static final int LAST_HEALTH_REPORT_TIME_FIELD_NUMBER = 9;
    private long lastHealthReportTime_;
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    public boolean hasLastHealthReportTime() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    public long getLastHealthReportTime() {
      return lastHealthReportTime_;
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      httpAddress_ = "";
      rackName_ = "";
      used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      numContainers_ = 0;
      nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
      healthReport_ = "";
      lastHealthReportTime_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getRackNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, used_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, capability_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, numContainers_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeEnum(7, nodeState_.getNumber());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeBytes(8, getHealthReportBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt64(9, lastHealthReportTime_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHttpAddressBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getRackNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, used_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, capability_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, numContainers_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, nodeState_.getNumber());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, getHealthReportBytes());
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(9, lastHealthReportTime_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasHttpAddress() == other.hasHttpAddress());
      if (hasHttpAddress()) {
        result = result && getHttpAddress()
            .equals(other.getHttpAddress());
      }
      result = result && (hasRackName() == other.hasRackName());
      if (hasRackName()) {
        result = result && getRackName()
            .equals(other.getRackName());
      }
      result = result && (hasUsed() == other.hasUsed());
      if (hasUsed()) {
        result = result && getUsed()
            .equals(other.getUsed());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasNodeState() == other.hasNodeState());
      if (hasNodeState()) {
        result = result &&
            (getNodeState() == other.getNodeState());
      }
      result = result && (hasHealthReport() == other.hasHealthReport());
      if (hasHealthReport()) {
        result = result && getHealthReport()
            .equals(other.getHealthReport());
      }
      result = result && (hasLastHealthReportTime() == other.hasLastHealthReportTime());
      if (hasLastHealthReportTime()) {
        result = result && (getLastHealthReportTime()
            == other.getLastHealthReportTime());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasHttpAddress()) {
        hash = (37 * hash) + HTTPADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getHttpAddress().hashCode();
      }
      if (hasRackName()) {
        hash = (37 * hash) + RACKNAME_FIELD_NUMBER;
        hash = (53 * hash) + getRackName().hashCode();
      }
      if (hasUsed()) {
        hash = (37 * hash) + USED_FIELD_NUMBER;
        hash = (53 * hash) + getUsed().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUMCONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasNodeState()) {
        hash = (37 * hash) + NODE_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getNodeState());
      }
      if (hasHealthReport()) {
        hash = (37 * hash) + HEALTH_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getHealthReport().hashCode();
      }
      if (hasLastHealthReportTime()) {
        hash = (37 * hash) + LAST_HEALTH_REPORT_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLastHealthReportTime());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getUsedFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        httpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rackName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (usedBuilder_ == null) {
          used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          usedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        numContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
        bitField0_ = (bitField0_ & ~0x00000040);
        healthReport_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        lastHealthReportTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.httpAddress_ = httpAddress_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rackName_ = rackName_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (usedBuilder_ == null) {
          result.used_ = used_;
        } else {
          result.used_ = usedBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.nodeState_ = nodeState_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.healthReport_ = healthReport_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.lastHealthReportTime_ = lastHealthReportTime_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasHttpAddress()) {
          bitField0_ |= 0x00000002;
          httpAddress_ = other.httpAddress_;
          onChanged();
        }
        if (other.hasRackName()) {
          bitField0_ |= 0x00000004;
          rackName_ = other.rackName_;
          onChanged();
        }
        if (other.hasUsed()) {
          mergeUsed(other.getUsed());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasNodeState()) {
          setNodeState(other.getNodeState());
        }
        if (other.hasHealthReport()) {
          bitField0_ |= 0x00000080;
          healthReport_ = other.healthReport_;
          onChanged();
        }
        if (other.hasLastHealthReportTime()) {
          setLastHealthReportTime(other.getLastHealthReportTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto nodeId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional string httpAddress = 2;
      private java.lang.Object httpAddress_ = "";
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public boolean hasHttpAddress() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public java.lang.String getHttpAddress() {
        java.lang.Object ref = httpAddress_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          httpAddress_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHttpAddressBytes() {
        java.lang.Object ref = httpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          httpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder setHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        httpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder clearHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000002);
        httpAddress_ = getDefaultInstance().getHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder setHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        httpAddress_ = value;
        onChanged();
        return this;
      }

      // optional string rackName = 3;
      private java.lang.Object rackName_ = "";
      /**
       * <code>optional string rackName = 3;</code>
       */
      public boolean hasRackName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public java.lang.String getRackName() {
        java.lang.Object ref = rackName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          rackName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public com.google.protobuf.ByteString
          getRackNameBytes() {
        java.lang.Object ref = rackName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rackName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder setRackName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rackName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder clearRackName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rackName_ = getDefaultInstance().getRackName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder setRackNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rackName_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto used = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> usedBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public boolean hasUsed() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed() {
        if (usedBuilder_ == null) {
          return used_;
        } else {
          return usedBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder setUsed(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          used_ = value;
          onChanged();
        } else {
          usedBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder setUsed(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (usedBuilder_ == null) {
          used_ = builderForValue.build();
          onChanged();
        } else {
          usedBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder mergeUsed(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              used_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            used_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(used_).mergeFrom(value).buildPartial();
          } else {
            used_ = value;
          }
          onChanged();
        } else {
          usedBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder clearUsed() {
        if (usedBuilder_ == null) {
          used_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          usedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getUsedBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUsedFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder() {
        if (usedBuilder_ != null) {
          return usedBuilder_.getMessageOrBuilder();
        } else {
          return used_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getUsedFieldBuilder() {
        if (usedBuilder_ == null) {
          usedBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  used_,
                  getParentForChildren(),
                  isClean());
          used_ = null;
        }
        return usedBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional int32 numContainers = 6;
      private int numContainers_ ;
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000020;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000020);
        numContainers_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.NodeStateProto node_state = 7;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public boolean hasNodeState() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState() {
        return nodeState_;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public Builder setNodeState(org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000040;
        nodeState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public Builder clearNodeState() {
        bitField0_ = (bitField0_ & ~0x00000040);
        nodeState_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW;
        onChanged();
        return this;
      }

      // optional string health_report = 8;
      private java.lang.Object healthReport_ = "";
      /**
       * <code>optional string health_report = 8;</code>
       */
      public boolean hasHealthReport() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public java.lang.String getHealthReport() {
        java.lang.Object ref = healthReport_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          healthReport_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public com.google.protobuf.ByteString
          getHealthReportBytes() {
        java.lang.Object ref = healthReport_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          healthReport_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder setHealthReport(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        healthReport_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder clearHealthReport() {
        bitField0_ = (bitField0_ & ~0x00000080);
        healthReport_ = getDefaultInstance().getHealthReport();
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder setHealthReportBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        healthReport_ = value;
        onChanged();
        return this;
      }

      // optional int64 last_health_report_time = 9;
      private long lastHealthReportTime_ ;
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public boolean hasLastHealthReportTime() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public long getLastHealthReportTime() {
        return lastHealthReportTime_;
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public Builder setLastHealthReportTime(long value) {
        bitField0_ |= 0x00000100;
        lastHealthReportTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public Builder clearLastHealthReportTime() {
        bitField0_ = (bitField0_ & ~0x00000100);
        lastHealthReportTime_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeReportProto)
    }

    static {
      defaultInstance = new NodeReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeReportProto)
  }

  public interface ResourceRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.PriorityProto priority = 1;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional string resource_name = 2;
    /**
     * <code>optional string resource_name = 2;</code>
     */
    boolean hasResourceName();
    /**
     * <code>optional string resource_name = 2;</code>
     */
    java.lang.String getResourceName();
    /**
     * <code>optional string resource_name = 2;</code>
     */
    com.google.protobuf.ByteString
        getResourceNameBytes();

    // optional .hadoop.yarn.ResourceProto capability = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional int32 num_containers = 4;
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    int getNumContainers();

    // optional bool relax_locality = 5 [default = true];
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    boolean hasRelaxLocality();
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    boolean getRelaxLocality();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceRequestProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From AM_RM_Protocol /////////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class ResourceRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceRequestProtoOrBuilder {
    // Use ResourceRequestProto.newBuilder() to construct.
    private ResourceRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceRequestProto defaultInstance;
    public static ResourceRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              resourceName_ = input.readBytes();
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numContainers_ = input.readInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              relaxLocality_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceRequestProto>() {
      public ResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.PriorityProto priority = 1;
    public static final int PRIORITY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional string resource_name = 2;
    public static final int RESOURCE_NAME_FIELD_NUMBER = 2;
    private java.lang.Object resourceName_;
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public boolean hasResourceName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public java.lang.String getResourceName() {
      java.lang.Object ref = resourceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public com.google.protobuf.ByteString
        getResourceNameBytes() {
      java.lang.Object ref = resourceName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.ResourceProto capability = 3;
    public static final int CAPABILITY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional int32 num_containers = 4;
    public static final int NUM_CONTAINERS_FIELD_NUMBER = 4;
    private int numContainers_;
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    // optional bool relax_locality = 5 [default = true];
    public static final int RELAX_LOCALITY_FIELD_NUMBER = 5;
    private boolean relaxLocality_;
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    public boolean hasRelaxLocality() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    public boolean getRelaxLocality() {
      return relaxLocality_;
    }

    private void initFields() {
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      resourceName_ = "";
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      numContainers_ = 0;
      relaxLocality_ = true;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, priority_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getResourceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, capability_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, numContainers_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, relaxLocality_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, priority_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getResourceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, capability_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, numContainers_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, relaxLocality_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasResourceName() == other.hasResourceName());
      if (hasResourceName()) {
        result = result && getResourceName()
            .equals(other.getResourceName());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasRelaxLocality() == other.hasRelaxLocality());
      if (hasRelaxLocality()) {
        result = result && (getRelaxLocality()
            == other.getRelaxLocality());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasResourceName()) {
        hash = (37 * hash) + RESOURCE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getResourceName().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUM_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasRelaxLocality()) {
        hash = (37 * hash) + RELAX_LOCALITY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getRelaxLocality());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceRequestProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From AM_RM_Protocol /////////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getPriorityFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        numContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        relaxLocality_ = true;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.resourceName_ = resourceName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.relaxLocality_ = relaxLocality_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasResourceName()) {
          bitField0_ |= 0x00000002;
          resourceName_ = other.resourceName_;
          onChanged();
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasRelaxLocality()) {
          setRelaxLocality(other.getRelaxLocality());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.PriorityProto priority = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional string resource_name = 2;
      private java.lang.Object resourceName_ = "";
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public boolean hasResourceName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public java.lang.String getResourceName() {
        java.lang.Object ref = resourceName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          resourceName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public com.google.protobuf.ByteString
          getResourceNameBytes() {
        java.lang.Object ref = resourceName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder setResourceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder clearResourceName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        resourceName_ = getDefaultInstance().getResourceName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder setResourceNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceName_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto capability = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional int32 num_containers = 4;
      private int numContainers_ ;
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000008;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numContainers_ = 0;
        onChanged();
        return this;
      }

      // optional bool relax_locality = 5 [default = true];
      private boolean relaxLocality_ = true;
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public boolean hasRelaxLocality() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public boolean getRelaxLocality() {
        return relaxLocality_;
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public Builder setRelaxLocality(boolean value) {
        bitField0_ |= 0x00000010;
        relaxLocality_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public Builder clearRelaxLocality() {
        bitField0_ = (bitField0_ & ~0x00000010);
        relaxLocality_ = true;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceRequestProto)
    }

    static {
      defaultInstance = new ResourceRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceRequestProto)
  }

  public interface PreemptionMessageProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    boolean hasStrictContract();
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract();
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder();

    // optional .hadoop.yarn.PreemptionContractProto contract = 2;
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    boolean hasContract();
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract();
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionMessageProto}
   */
  public static final class PreemptionMessageProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionMessageProtoOrBuilder {
    // Use PreemptionMessageProto.newBuilder() to construct.
    private PreemptionMessageProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionMessageProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionMessageProto defaultInstance;
    public static PreemptionMessageProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionMessageProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionMessageProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = strictContract_.toBuilder();
              }
              strictContract_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(strictContract_);
                strictContract_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = contract_.toBuilder();
              }
              contract_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(contract_);
                contract_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionMessageProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionMessageProto>() {
      public PreemptionMessageProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionMessageProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionMessageProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
    public static final int STRICTCONTRACT_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto strictContract_;
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public boolean hasStrictContract() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract() {
      return strictContract_;
    }
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder() {
      return strictContract_;
    }

    // optional .hadoop.yarn.PreemptionContractProto contract = 2;
    public static final int CONTRACT_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto contract_;
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public boolean hasContract() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract() {
      return contract_;
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder() {
      return contract_;
    }

    private void initFields() {
      strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, strictContract_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, contract_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, strictContract_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, contract_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) obj;

      boolean result = true;
      result = result && (hasStrictContract() == other.hasStrictContract());
      if (hasStrictContract()) {
        result = result && getStrictContract()
            .equals(other.getStrictContract());
      }
      result = result && (hasContract() == other.hasContract());
      if (hasContract()) {
        result = result && getContract()
            .equals(other.getContract());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasStrictContract()) {
        hash = (37 * hash) + STRICTCONTRACT_FIELD_NUMBER;
        hash = (53 * hash) + getStrictContract().hashCode();
      }
      if (hasContract()) {
        hash = (37 * hash) + CONTRACT_FIELD_NUMBER;
        hash = (53 * hash) + getContract().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionMessageProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getStrictContractFieldBuilder();
          getContractFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (strictContractBuilder_ == null) {
          strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
        } else {
          strictContractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (contractBuilder_ == null) {
          contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
        } else {
          contractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (strictContractBuilder_ == null) {
          result.strictContract_ = strictContract_;
        } else {
          result.strictContract_ = strictContractBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (contractBuilder_ == null) {
          result.contract_ = contract_;
        } else {
          result.contract_ = contractBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance()) return this;
        if (other.hasStrictContract()) {
          mergeStrictContract(other.getStrictContract());
        }
        if (other.hasContract()) {
          mergeContract(other.getContract());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder> strictContractBuilder_;
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public boolean hasStrictContract() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract() {
        if (strictContractBuilder_ == null) {
          return strictContract_;
        } else {
          return strictContractBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder setStrictContract(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto value) {
        if (strictContractBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          strictContract_ = value;
          onChanged();
        } else {
          strictContractBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder setStrictContract(
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder builderForValue) {
        if (strictContractBuilder_ == null) {
          strictContract_ = builderForValue.build();
          onChanged();
        } else {
          strictContractBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder mergeStrictContract(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto value) {
        if (strictContractBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              strictContract_ != org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance()) {
            strictContract_ =
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.newBuilder(strictContract_).mergeFrom(value).buildPartial();
          } else {
            strictContract_ = value;
          }
          onChanged();
        } else {
          strictContractBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder clearStrictContract() {
        if (strictContractBuilder_ == null) {
          strictContract_ = org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
          onChanged();
        } else {
          strictContractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder getStrictContractBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getStrictContractFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder() {
        if (strictContractBuilder_ != null) {
          return strictContractBuilder_.getMessageOrBuilder();
        } else {
          return strictContract_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder> 
          getStrictContractFieldBuilder() {
        if (strictContractBuilder_ == null) {
          strictContractBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder>(
                  strictContract_,
                  getParentForChildren(),
                  isClean());
          strictContract_ = null;
        }
        return strictContractBuilder_;
      }

      // optional .hadoop.yarn.PreemptionContractProto contract = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder> contractBuilder_;
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public boolean hasContract() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract() {
        if (contractBuilder_ == null) {
          return contract_;
        } else {
          return contractBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder setContract(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto value) {
        if (contractBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          contract_ = value;
          onChanged();
        } else {
          contractBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder setContract(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder builderForValue) {
        if (contractBuilder_ == null) {
          contract_ = builderForValue.build();
          onChanged();
        } else {
          contractBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder mergeContract(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto value) {
        if (contractBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              contract_ != org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance()) {
            contract_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.newBuilder(contract_).mergeFrom(value).buildPartial();
          } else {
            contract_ = value;
          }
          onChanged();
        } else {
          contractBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder clearContract() {
        if (contractBuilder_ == null) {
          contract_ = org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
          onChanged();
        } else {
          contractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder getContractBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getContractFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder() {
        if (contractBuilder_ != null) {
          return contractBuilder_.getMessageOrBuilder();
        } else {
          return contract_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder> 
          getContractFieldBuilder() {
        if (contractBuilder_ == null) {
          contractBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder>(
                  contract_,
                  getParentForChildren(),
                  isClean());
          contract_ = null;
        }
        return contractBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionMessageProto)
    }

    static {
      defaultInstance = new PreemptionMessageProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionMessageProto)
  }

  public interface StrictPreemptionContractProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> 
        getContainerList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    int getContainerCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StrictPreemptionContractProto}
   */
  public static final class StrictPreemptionContractProto extends
      com.google.protobuf.GeneratedMessage
      implements StrictPreemptionContractProtoOrBuilder {
    // Use StrictPreemptionContractProto.newBuilder() to construct.
    private StrictPreemptionContractProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StrictPreemptionContractProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StrictPreemptionContractProto defaultInstance;
    public static StrictPreemptionContractProto getDefaultInstance() {
      return defaultInstance;
    }

    public StrictPreemptionContractProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StrictPreemptionContractProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              container_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          container_ = java.util.Collections.unmodifiableList(container_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StrictPreemptionContractProto> PARSER =
        new com.google.protobuf.AbstractParser<StrictPreemptionContractProto>() {
      public StrictPreemptionContractProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StrictPreemptionContractProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StrictPreemptionContractProto> getParserForType() {
      return PARSER;
    }

    // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
    public static final int CONTAINER_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public int getContainerCount() {
      return container_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
      return container_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index) {
      return container_.get(index);
    }

    private void initFields() {
      container_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < container_.size(); i++) {
        output.writeMessage(1, container_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < container_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, container_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) obj;

      boolean result = true;
      result = result && getContainerList()
          .equals(other.getContainerList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getContainerCount() > 0) {
        hash = (37 * hash) + CONTAINER_FIELD_NUMBER;
        hash = (53 * hash) + getContainerList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StrictPreemptionContractProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          containerBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto(this);
        int from_bitField0_ = bitField0_;
        if (containerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            container_ = java.util.Collections.unmodifiableList(container_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.container_ = container_;
        } else {
          result.container_ = containerBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance()) return this;
        if (containerBuilder_ == null) {
          if (!other.container_.isEmpty()) {
            if (container_.isEmpty()) {
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureContainerIsMutable();
              container_.addAll(other.container_);
            }
            onChanged();
          }
        } else {
          if (!other.container_.isEmpty()) {
            if (containerBuilder_.isEmpty()) {
              containerBuilder_.dispose();
              containerBuilder_ = null;
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000001);
              containerBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainerFieldBuilder() : null;
            } else {
              containerBuilder_.addAllMessages(other.container_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.PreemptionContainerProto container = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_ =
        java.util.Collections.emptyList();
      private void ensureContainerIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>(container_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> containerBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
        if (containerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(container_);
        } else {
          return containerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public int getContainerCount() {
        if (containerBuilder_ == null) {
          return container_.size();
        } else {
          return containerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);
        } else {
          return containerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.set(index, value);
          onChanged();
        } else {
          containerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(value);
          onChanged();
        } else {
          containerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(index, value);
          onChanged();
        } else {
          containerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addAllContainer(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> values) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          super.addAll(values, container_);
          onChanged();
        } else {
          containerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder clearContainer() {
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          containerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder removeContainer(int index) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.remove(index);
          onChanged();
        } else {
          containerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder getContainerBuilder(
          int index) {
        return getContainerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
          int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);  } else {
          return containerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
           getContainerOrBuilderList() {
        if (containerBuilder_ != null) {
          return containerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(container_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder() {
        return getContainerFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder(
          int index) {
        return getContainerFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder> 
           getContainerBuilderList() {
        return getContainerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
          getContainerFieldBuilder() {
        if (containerBuilder_ == null) {
          containerBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder>(
                  container_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          container_ = null;
        }
        return containerBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StrictPreemptionContractProto)
    }

    static {
      defaultInstance = new StrictPreemptionContractProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StrictPreemptionContractProto)
  }

  public interface PreemptionContractProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> 
        getResourceList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    int getResourceCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
        getResourceOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
        int index);

    // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> 
        getContainerList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    int getContainerCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionContractProto}
   */
  public static final class PreemptionContractProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionContractProtoOrBuilder {
    // Use PreemptionContractProto.newBuilder() to construct.
    private PreemptionContractProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionContractProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionContractProto defaultInstance;
    public static PreemptionContractProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionContractProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionContractProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                resource_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              resource_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              container_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          resource_ = java.util.Collections.unmodifiableList(resource_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          container_ = java.util.Collections.unmodifiableList(container_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionContractProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionContractProto>() {
      public PreemptionContractProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionContractProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionContractProto> getParserForType() {
      return PARSER;
    }

    // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> resource_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> getResourceList() {
      return resource_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
        getResourceOrBuilderList() {
      return resource_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public int getResourceCount() {
      return resource_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index) {
      return resource_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
        int index) {
      return resource_.get(index);
    }

    // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
    public static final int CONTAINER_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public int getContainerCount() {
      return container_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
      return container_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index) {
      return container_.get(index);
    }

    private void initFields() {
      resource_ = java.util.Collections.emptyList();
      container_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < resource_.size(); i++) {
        output.writeMessage(1, resource_.get(i));
      }
      for (int i = 0; i < container_.size(); i++) {
        output.writeMessage(2, container_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < resource_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_.get(i));
      }
      for (int i = 0; i < container_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, container_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) obj;

      boolean result = true;
      result = result && getResourceList()
          .equals(other.getResourceList());
      result = result && getContainerList()
          .equals(other.getContainerList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResourceCount() > 0) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResourceList().hashCode();
      }
      if (getContainerCount() > 0) {
        hash = (37 * hash) + CONTAINER_FIELD_NUMBER;
        hash = (53 * hash) + getContainerList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionContractProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
          getContainerFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resourceBuilder_.clear();
        }
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          containerBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto(this);
        int from_bitField0_ = bitField0_;
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            resource_ = java.util.Collections.unmodifiableList(resource_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (containerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            container_ = java.util.Collections.unmodifiableList(container_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.container_ = container_;
        } else {
          result.container_ = containerBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance()) return this;
        if (resourceBuilder_ == null) {
          if (!other.resource_.isEmpty()) {
            if (resource_.isEmpty()) {
              resource_ = other.resource_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResourceIsMutable();
              resource_.addAll(other.resource_);
            }
            onChanged();
          }
        } else {
          if (!other.resource_.isEmpty()) {
            if (resourceBuilder_.isEmpty()) {
              resourceBuilder_.dispose();
              resourceBuilder_ = null;
              resource_ = other.resource_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resourceBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResourceFieldBuilder() : null;
            } else {
              resourceBuilder_.addAllMessages(other.resource_);
            }
          }
        }
        if (containerBuilder_ == null) {
          if (!other.container_.isEmpty()) {
            if (container_.isEmpty()) {
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureContainerIsMutable();
              container_.addAll(other.container_);
            }
            onChanged();
          }
        } else {
          if (!other.container_.isEmpty()) {
            if (containerBuilder_.isEmpty()) {
              containerBuilder_.dispose();
              containerBuilder_ = null;
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000002);
              containerBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainerFieldBuilder() : null;
            } else {
              containerBuilder_.addAllMessages(other.container_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> resource_ =
        java.util.Collections.emptyList();
      private void ensureResourceIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          resource_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto>(resource_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> resourceBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> getResourceList() {
        if (resourceBuilder_ == null) {
          return java.util.Collections.unmodifiableList(resource_);
        } else {
          return resourceBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public int getResourceCount() {
        if (resourceBuilder_ == null) {
          return resource_.size();
        } else {
          return resourceBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index) {
        if (resourceBuilder_ == null) {
          return resource_.get(index);
        } else {
          return resourceBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.set(index, value);
          onChanged();
        } else {
          resourceBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.set(index, builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.add(value);
          onChanged();
        } else {
          resourceBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.add(index, value);
          onChanged();
        } else {
          resourceBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.add(builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.add(index, builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addAllResource(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> values) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          super.addAll(values, resource_);
          onChanged();
        } else {
          resourceBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder removeResource(int index) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.remove(index);
          onChanged();
        } else {
          resourceBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder getResourceBuilder(
          int index) {
        return getResourceFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
          int index) {
        if (resourceBuilder_ == null) {
          return resource_.get(index);  } else {
          return resourceBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
           getResourceOrBuilderList() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(resource_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder addResourceBuilder() {
        return getResourceFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder addResourceBuilder(
          int index) {
        return getResourceFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder> 
           getResourceBuilderList() {
        return getResourceFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder>(
                  resource_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // repeated .hadoop.yarn.PreemptionContainerProto container = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_ =
        java.util.Collections.emptyList();
      private void ensureContainerIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>(container_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> containerBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
        if (containerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(container_);
        } else {
          return containerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public int getContainerCount() {
        if (containerBuilder_ == null) {
          return container_.size();
        } else {
          return containerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);
        } else {
          return containerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.set(index, value);
          onChanged();
        } else {
          containerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(value);
          onChanged();
        } else {
          containerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(index, value);
          onChanged();
        } else {
          containerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addAllContainer(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> values) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          super.addAll(values, container_);
          onChanged();
        } else {
          containerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder clearContainer() {
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          containerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder removeContainer(int index) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.remove(index);
          onChanged();
        } else {
          containerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder getContainerBuilder(
          int index) {
        return getContainerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
          int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);  } else {
          return containerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
           getContainerOrBuilderList() {
        if (containerBuilder_ != null) {
          return containerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(container_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder() {
        return getContainerFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder(
          int index) {
        return getContainerFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder> 
           getContainerBuilderList() {
        return getContainerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
          getContainerFieldBuilder() {
        if (containerBuilder_ == null) {
          containerBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder>(
                  container_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          container_ = null;
        }
        return containerBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionContractProto)
    }

    static {
      defaultInstance = new PreemptionContractProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContractProto)
  }

  public interface PreemptionContainerProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionContainerProto}
   */
  public static final class PreemptionContainerProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionContainerProtoOrBuilder {
    // Use PreemptionContainerProto.newBuilder() to construct.
    private PreemptionContainerProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionContainerProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionContainerProto defaultInstance;
    public static PreemptionContainerProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionContainerProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionContainerProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = id_.toBuilder();
              }
              id_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(id_);
                id_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionContainerProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionContainerProto>() {
      public PreemptionContainerProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionContainerProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionContainerProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto id = 1;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
      return id_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
      return id_;
    }

    private void initFields() {
      id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, id_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, id_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && getId()
            .equals(other.getId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionContainerProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (idBuilder_ == null) {
          result.id_ = id_;
        } else {
          result.id_ = idBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> idBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
        if (idBuilder_ == null) {
          return id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
          onChanged();
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
          onChanged();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder mergeId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              id_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            id_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(id_).mergeFrom(value).buildPartial();
          } else {
            id_ = value;
          }
          onChanged();
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder clearId() {
        if (idBuilder_ == null) {
          id_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  id_,
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionContainerProto)
    }

    static {
      defaultInstance = new PreemptionContainerProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContainerProto)
  }

  public interface PreemptionResourceRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ResourceRequestProto resource = 1;
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionResourceRequestProto}
   */
  public static final class PreemptionResourceRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements PreemptionResourceRequestProtoOrBuilder {
    // Use PreemptionResourceRequestProto.newBuilder() to construct.
    private PreemptionResourceRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private PreemptionResourceRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final PreemptionResourceRequestProto defaultInstance;
    public static PreemptionResourceRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public PreemptionResourceRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<PreemptionResourceRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<PreemptionResourceRequestProto>() {
      public PreemptionResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PreemptionResourceRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionResourceRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ResourceRequestProto resource = 1;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    private void initFields() {
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, resource_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ResourceRequestProto resource = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionResourceRequestProto)
    }

    static {
      defaultInstance = new PreemptionResourceRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionResourceRequestProto)
  }

  public interface ResourceBlacklistRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated string blacklist_additions = 1;
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    java.util.List<java.lang.String>
    getBlacklistAdditionsList();
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    int getBlacklistAdditionsCount();
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    java.lang.String getBlacklistAdditions(int index);
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    com.google.protobuf.ByteString
        getBlacklistAdditionsBytes(int index);

    // repeated string blacklist_removals = 2;
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    java.util.List<java.lang.String>
    getBlacklistRemovalsList();
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    int getBlacklistRemovalsCount();
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    java.lang.String getBlacklistRemovals(int index);
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    com.google.protobuf.ByteString
        getBlacklistRemovalsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceBlacklistRequestProto}
   */
  public static final class ResourceBlacklistRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ResourceBlacklistRequestProtoOrBuilder {
    // Use ResourceBlacklistRequestProto.newBuilder() to construct.
    private ResourceBlacklistRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ResourceBlacklistRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ResourceBlacklistRequestProto defaultInstance;
    public static ResourceBlacklistRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ResourceBlacklistRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceBlacklistRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                blacklistAdditions_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              blacklistAdditions_.add(input.readBytes());
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                blacklistRemovals_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              blacklistRemovals_.add(input.readBytes());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.UnmodifiableLazyStringList(blacklistAdditions_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.UnmodifiableLazyStringList(blacklistRemovals_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ResourceBlacklistRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ResourceBlacklistRequestProto>() {
      public ResourceBlacklistRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ResourceBlacklistRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceBlacklistRequestProto> getParserForType() {
      return PARSER;
    }

    // repeated string blacklist_additions = 1;
    public static final int BLACKLIST_ADDITIONS_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList blacklistAdditions_;
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public java.util.List<java.lang.String>
        getBlacklistAdditionsList() {
      return blacklistAdditions_;
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public int getBlacklistAdditionsCount() {
      return blacklistAdditions_.size();
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public java.lang.String getBlacklistAdditions(int index) {
      return blacklistAdditions_.get(index);
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public com.google.protobuf.ByteString
        getBlacklistAdditionsBytes(int index) {
      return blacklistAdditions_.getByteString(index);
    }

    // repeated string blacklist_removals = 2;
    public static final int BLACKLIST_REMOVALS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList blacklistRemovals_;
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public java.util.List<java.lang.String>
        getBlacklistRemovalsList() {
      return blacklistRemovals_;
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public int getBlacklistRemovalsCount() {
      return blacklistRemovals_.size();
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public java.lang.String getBlacklistRemovals(int index) {
      return blacklistRemovals_.get(index);
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public com.google.protobuf.ByteString
        getBlacklistRemovalsBytes(int index) {
      return blacklistRemovals_.getByteString(index);
    }

    private void initFields() {
      blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < blacklistAdditions_.size(); i++) {
        output.writeBytes(1, blacklistAdditions_.getByteString(i));
      }
      for (int i = 0; i < blacklistRemovals_.size(); i++) {
        output.writeBytes(2, blacklistRemovals_.getByteString(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < blacklistAdditions_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(blacklistAdditions_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getBlacklistAdditionsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < blacklistRemovals_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(blacklistRemovals_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getBlacklistRemovalsList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) obj;

      boolean result = true;
      result = result && getBlacklistAdditionsList()
          .equals(other.getBlacklistAdditionsList());
      result = result && getBlacklistRemovalsList()
          .equals(other.getBlacklistRemovalsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getBlacklistAdditionsCount() > 0) {
        hash = (37 * hash) + BLACKLIST_ADDITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistAdditionsList().hashCode();
      }
      if (getBlacklistRemovalsCount() > 0) {
        hash = (37 * hash) + BLACKLIST_REMOVALS_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistRemovalsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceBlacklistRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.UnmodifiableLazyStringList(
              blacklistAdditions_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.blacklistAdditions_ = blacklistAdditions_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.UnmodifiableLazyStringList(
              blacklistRemovals_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.blacklistRemovals_ = blacklistRemovals_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance()) return this;
        if (!other.blacklistAdditions_.isEmpty()) {
          if (blacklistAdditions_.isEmpty()) {
            blacklistAdditions_ = other.blacklistAdditions_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureBlacklistAdditionsIsMutable();
            blacklistAdditions_.addAll(other.blacklistAdditions_);
          }
          onChanged();
        }
        if (!other.blacklistRemovals_.isEmpty()) {
          if (blacklistRemovals_.isEmpty()) {
            blacklistRemovals_ = other.blacklistRemovals_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureBlacklistRemovalsIsMutable();
            blacklistRemovals_.addAll(other.blacklistRemovals_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated string blacklist_additions = 1;
      private com.google.protobuf.LazyStringList blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureBlacklistAdditionsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.LazyStringArrayList(blacklistAdditions_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public java.util.List<java.lang.String>
          getBlacklistAdditionsList() {
        return java.util.Collections.unmodifiableList(blacklistAdditions_);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public int getBlacklistAdditionsCount() {
        return blacklistAdditions_.size();
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public java.lang.String getBlacklistAdditions(int index) {
        return blacklistAdditions_.get(index);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public com.google.protobuf.ByteString
          getBlacklistAdditionsBytes(int index) {
        return blacklistAdditions_.getByteString(index);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder setBlacklistAdditions(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addBlacklistAdditions(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addAllBlacklistAdditions(
          java.lang.Iterable<java.lang.String> values) {
        ensureBlacklistAdditionsIsMutable();
        super.addAll(values, blacklistAdditions_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder clearBlacklistAdditions() {
        blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addBlacklistAdditionsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.add(value);
        onChanged();
        return this;
      }

      // repeated string blacklist_removals = 2;
      private com.google.protobuf.LazyStringList blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureBlacklistRemovalsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.LazyStringArrayList(blacklistRemovals_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public java.util.List<java.lang.String>
          getBlacklistRemovalsList() {
        return java.util.Collections.unmodifiableList(blacklistRemovals_);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public int getBlacklistRemovalsCount() {
        return blacklistRemovals_.size();
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public java.lang.String getBlacklistRemovals(int index) {
        return blacklistRemovals_.get(index);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public com.google.protobuf.ByteString
          getBlacklistRemovalsBytes(int index) {
        return blacklistRemovals_.getByteString(index);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder setBlacklistRemovals(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addBlacklistRemovals(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addAllBlacklistRemovals(
          java.lang.Iterable<java.lang.String> values) {
        ensureBlacklistRemovalsIsMutable();
        super.addAll(values, blacklistRemovals_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder clearBlacklistRemovals() {
        blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addBlacklistRemovalsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.add(value);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceBlacklistRequestProto)
    }

    static {
      defaultInstance = new ResourceBlacklistRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceBlacklistRequestProto)
  }

  public interface ApplicationSubmissionContextProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional string application_name = 2 [default = "N/A"];
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    boolean hasApplicationName();
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    java.lang.String getApplicationName();
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getApplicationNameBytes();

    // optional string queue = 3 [default = "default"];
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    // optional .hadoop.yarn.PriorityProto priority = 4;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    boolean hasAmContainerSpec();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder();

    // optional bool cancel_tokens_when_complete = 6 [default = true];
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    boolean hasCancelTokensWhenComplete();
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    boolean getCancelTokensWhenComplete();

    // optional bool unmanaged_am = 7 [default = false];
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    boolean hasUnmanagedAm();
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    boolean getUnmanagedAm();

    // optional int32 maxAppAttempts = 8 [default = 0];
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    boolean hasMaxAppAttempts();
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    int getMaxAppAttempts();

    // optional .hadoop.yarn.ResourceProto resource = 9;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional string applicationType = 10 [default = "YARN"];
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    boolean hasApplicationType();
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    java.lang.String getApplicationType();
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypeBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationSubmissionContextProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From client_RM_Protocol /////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class ApplicationSubmissionContextProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationSubmissionContextProtoOrBuilder {
    // Use ApplicationSubmissionContextProto.newBuilder() to construct.
    private ApplicationSubmissionContextProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationSubmissionContextProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationSubmissionContextProto defaultInstance;
    public static ApplicationSubmissionContextProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationSubmissionContextProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationSubmissionContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              applicationName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              queue_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = amContainerSpec_.toBuilder();
              }
              amContainerSpec_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amContainerSpec_);
                amContainerSpec_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              cancelTokensWhenComplete_ = input.readBool();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              unmanagedAm_ = input.readBool();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              maxAppAttempts_ = input.readInt32();
              break;
            }
            case 74: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000100) == 0x00000100)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000100;
              break;
            }
            case 82: {
              bitField0_ |= 0x00000200;
              applicationType_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationSubmissionContextProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationSubmissionContextProto>() {
      public ApplicationSubmissionContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationSubmissionContextProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationSubmissionContextProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional string application_name = 2 [default = "N/A"];
    public static final int APPLICATION_NAME_FIELD_NUMBER = 2;
    private java.lang.Object applicationName_;
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public boolean hasApplicationName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public java.lang.String getApplicationName() {
      java.lang.Object ref = applicationName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getApplicationNameBytes() {
      java.lang.Object ref = applicationName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string queue = 3 [default = "default"];
    public static final int QUEUE_FIELD_NUMBER = 3;
    private java.lang.Object queue_;
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.PriorityProto priority = 4;
    public static final int PRIORITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
    public static final int AM_CONTAINER_SPEC_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto amContainerSpec_;
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public boolean hasAmContainerSpec() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec() {
      return amContainerSpec_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder() {
      return amContainerSpec_;
    }

    // optional bool cancel_tokens_when_complete = 6 [default = true];
    public static final int CANCEL_TOKENS_WHEN_COMPLETE_FIELD_NUMBER = 6;
    private boolean cancelTokensWhenComplete_;
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    public boolean hasCancelTokensWhenComplete() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    public boolean getCancelTokensWhenComplete() {
      return cancelTokensWhenComplete_;
    }

    // optional bool unmanaged_am = 7 [default = false];
    public static final int UNMANAGED_AM_FIELD_NUMBER = 7;
    private boolean unmanagedAm_;
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    public boolean hasUnmanagedAm() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    public boolean getUnmanagedAm() {
      return unmanagedAm_;
    }

    // optional int32 maxAppAttempts = 8 [default = 0];
    public static final int MAXAPPATTEMPTS_FIELD_NUMBER = 8;
    private int maxAppAttempts_;
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    public boolean hasMaxAppAttempts() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    public int getMaxAppAttempts() {
      return maxAppAttempts_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 9;
    public static final int RESOURCE_FIELD_NUMBER = 9;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional string applicationType = 10 [default = "YARN"];
    public static final int APPLICATIONTYPE_FIELD_NUMBER = 10;
    private java.lang.Object applicationType_;
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public boolean hasApplicationType() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public java.lang.String getApplicationType() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationType_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypeBytes() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      applicationName_ = "N/A";
      queue_ = "default";
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      cancelTokensWhenComplete_ = true;
      unmanagedAm_ = false;
      maxAppAttempts_ = 0;
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      applicationType_ = "YARN";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getApplicationNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, amContainerSpec_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(6, cancelTokensWhenComplete_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBool(7, unmanagedAm_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeInt32(8, maxAppAttempts_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeMessage(9, resource_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeBytes(10, getApplicationTypeBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getApplicationNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getQueueBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, amContainerSpec_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, cancelTokensWhenComplete_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, unmanagedAm_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(8, maxAppAttempts_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, resource_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(10, getApplicationTypeBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasApplicationName() == other.hasApplicationName());
      if (hasApplicationName()) {
        result = result && getApplicationName()
            .equals(other.getApplicationName());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasAmContainerSpec() == other.hasAmContainerSpec());
      if (hasAmContainerSpec()) {
        result = result && getAmContainerSpec()
            .equals(other.getAmContainerSpec());
      }
      result = result && (hasCancelTokensWhenComplete() == other.hasCancelTokensWhenComplete());
      if (hasCancelTokensWhenComplete()) {
        result = result && (getCancelTokensWhenComplete()
            == other.getCancelTokensWhenComplete());
      }
      result = result && (hasUnmanagedAm() == other.hasUnmanagedAm());
      if (hasUnmanagedAm()) {
        result = result && (getUnmanagedAm()
            == other.getUnmanagedAm());
      }
      result = result && (hasMaxAppAttempts() == other.hasMaxAppAttempts());
      if (hasMaxAppAttempts()) {
        result = result && (getMaxAppAttempts()
            == other.getMaxAppAttempts());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasApplicationType() == other.hasApplicationType());
      if (hasApplicationType()) {
        result = result && getApplicationType()
            .equals(other.getApplicationType());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasApplicationName()) {
        hash = (37 * hash) + APPLICATION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationName().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasAmContainerSpec()) {
        hash = (37 * hash) + AM_CONTAINER_SPEC_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerSpec().hashCode();
      }
      if (hasCancelTokensWhenComplete()) {
        hash = (37 * hash) + CANCEL_TOKENS_WHEN_COMPLETE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCancelTokensWhenComplete());
      }
      if (hasUnmanagedAm()) {
        hash = (37 * hash) + UNMANAGED_AM_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getUnmanagedAm());
      }
      if (hasMaxAppAttempts()) {
        hash = (37 * hash) + MAXAPPATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxAppAttempts();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasApplicationType()) {
        hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationType().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationSubmissionContextProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From client_RM_Protocol /////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getPriorityFieldBuilder();
          getAmContainerSpecFieldBuilder();
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationName_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000002);
        queue_ = "default";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
        } else {
          amContainerSpecBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        cancelTokensWhenComplete_ = true;
        bitField0_ = (bitField0_ & ~0x00000020);
        unmanagedAm_ = false;
        bitField0_ = (bitField0_ & ~0x00000040);
        maxAppAttempts_ = 0;
        bitField0_ = (bitField0_ & ~0x00000080);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        applicationType_ = "YARN";
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.applicationName_ = applicationName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (amContainerSpecBuilder_ == null) {
          result.amContainerSpec_ = amContainerSpec_;
        } else {
          result.amContainerSpec_ = amContainerSpecBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.cancelTokensWhenComplete_ = cancelTokensWhenComplete_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.unmanagedAm_ = unmanagedAm_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.maxAppAttempts_ = maxAppAttempts_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.applicationType_ = applicationType_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasApplicationName()) {
          bitField0_ |= 0x00000002;
          applicationName_ = other.applicationName_;
          onChanged();
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000004;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasAmContainerSpec()) {
          mergeAmContainerSpec(other.getAmContainerSpec());
        }
        if (other.hasCancelTokensWhenComplete()) {
          setCancelTokensWhenComplete(other.getCancelTokensWhenComplete());
        }
        if (other.hasUnmanagedAm()) {
          setUnmanagedAm(other.getUnmanagedAm());
        }
        if (other.hasMaxAppAttempts()) {
          setMaxAppAttempts(other.getMaxAppAttempts());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasApplicationType()) {
          bitField0_ |= 0x00000200;
          applicationType_ = other.applicationType_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional string application_name = 2 [default = "N/A"];
      private java.lang.Object applicationName_ = "N/A";
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public boolean hasApplicationName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public java.lang.String getApplicationName() {
        java.lang.Object ref = applicationName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getApplicationNameBytes() {
        java.lang.Object ref = applicationName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder setApplicationName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        applicationName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder clearApplicationName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        applicationName_ = getDefaultInstance().getApplicationName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder setApplicationNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        applicationName_ = value;
        onChanged();
        return this;
      }

      // optional string queue = 3 [default = "default"];
      private java.lang.Object queue_ = "default";
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queue_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000004);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.PriorityProto priority = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> amContainerSpecBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public boolean hasAmContainerSpec() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec() {
        if (amContainerSpecBuilder_ == null) {
          return amContainerSpec_;
        } else {
          return amContainerSpecBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder setAmContainerSpec(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (amContainerSpecBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amContainerSpec_ = value;
          onChanged();
        } else {
          amContainerSpecBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder setAmContainerSpec(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder builderForValue) {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = builderForValue.build();
          onChanged();
        } else {
          amContainerSpecBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder mergeAmContainerSpec(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (amContainerSpecBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              amContainerSpec_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) {
            amContainerSpec_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder(amContainerSpec_).mergeFrom(value).buildPartial();
          } else {
            amContainerSpec_ = value;
          }
          onChanged();
        } else {
          amContainerSpecBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder clearAmContainerSpec() {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
          onChanged();
        } else {
          amContainerSpecBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder getAmContainerSpecBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getAmContainerSpecFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder() {
        if (amContainerSpecBuilder_ != null) {
          return amContainerSpecBuilder_.getMessageOrBuilder();
        } else {
          return amContainerSpec_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> 
          getAmContainerSpecFieldBuilder() {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpecBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder>(
                  amContainerSpec_,
                  getParentForChildren(),
                  isClean());
          amContainerSpec_ = null;
        }
        return amContainerSpecBuilder_;
      }

      // optional bool cancel_tokens_when_complete = 6 [default = true];
      private boolean cancelTokensWhenComplete_ = true;
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public boolean hasCancelTokensWhenComplete() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public boolean getCancelTokensWhenComplete() {
        return cancelTokensWhenComplete_;
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public Builder setCancelTokensWhenComplete(boolean value) {
        bitField0_ |= 0x00000020;
        cancelTokensWhenComplete_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public Builder clearCancelTokensWhenComplete() {
        bitField0_ = (bitField0_ & ~0x00000020);
        cancelTokensWhenComplete_ = true;
        onChanged();
        return this;
      }

      // optional bool unmanaged_am = 7 [default = false];
      private boolean unmanagedAm_ ;
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public boolean hasUnmanagedAm() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public boolean getUnmanagedAm() {
        return unmanagedAm_;
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public Builder setUnmanagedAm(boolean value) {
        bitField0_ |= 0x00000040;
        unmanagedAm_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public Builder clearUnmanagedAm() {
        bitField0_ = (bitField0_ & ~0x00000040);
        unmanagedAm_ = false;
        onChanged();
        return this;
      }

      // optional int32 maxAppAttempts = 8 [default = 0];
      private int maxAppAttempts_ ;
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public boolean hasMaxAppAttempts() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public int getMaxAppAttempts() {
        return maxAppAttempts_;
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public Builder setMaxAppAttempts(int value) {
        bitField0_ |= 0x00000080;
        maxAppAttempts_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public Builder clearMaxAppAttempts() {
        bitField0_ = (bitField0_ & ~0x00000080);
        maxAppAttempts_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 9;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000100) == 0x00000100) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000100;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional string applicationType = 10 [default = "YARN"];
      private java.lang.Object applicationType_ = "YARN";
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public boolean hasApplicationType() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public java.lang.String getApplicationType() {
        java.lang.Object ref = applicationType_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationType_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypeBytes() {
        java.lang.Object ref = applicationType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder setApplicationType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        applicationType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder clearApplicationType() {
        bitField0_ = (bitField0_ & ~0x00000200);
        applicationType_ = getDefaultInstance().getApplicationType();
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder setApplicationTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        applicationType_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationSubmissionContextProto)
    }

    static {
      defaultInstance = new ApplicationSubmissionContextProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationSubmissionContextProto)
  }

  public interface ApplicationACLMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    boolean hasAccessType();
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType();

    // optional string acl = 2 [default = " "];
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    boolean hasAcl();
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    java.lang.String getAcl();
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    com.google.protobuf.ByteString
        getAclBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationACLMapProto}
   */
  public static final class ApplicationACLMapProto extends
      com.google.protobuf.GeneratedMessage
      implements ApplicationACLMapProtoOrBuilder {
    // Use ApplicationACLMapProto.newBuilder() to construct.
    private ApplicationACLMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ApplicationACLMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ApplicationACLMapProto defaultInstance;
    public static ApplicationACLMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public ApplicationACLMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationACLMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                accessType_ = value;
              }
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              acl_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ApplicationACLMapProto> PARSER =
        new com.google.protobuf.AbstractParser<ApplicationACLMapProto>() {
      public ApplicationACLMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationACLMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationACLMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
    public static final int ACCESSTYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto accessType_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    public boolean hasAccessType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType() {
      return accessType_;
    }

    // optional string acl = 2 [default = " "];
    public static final int ACL_FIELD_NUMBER = 2;
    private java.lang.Object acl_;
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public boolean hasAcl() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public java.lang.String getAcl() {
      java.lang.Object ref = acl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          acl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public com.google.protobuf.ByteString
        getAclBytes() {
      java.lang.Object ref = acl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        acl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
      acl_ = " ";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, accessType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getAclBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, accessType_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getAclBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) obj;

      boolean result = true;
      result = result && (hasAccessType() == other.hasAccessType());
      if (hasAccessType()) {
        result = result &&
            (getAccessType() == other.getAccessType());
      }
      result = result && (hasAcl() == other.hasAcl());
      if (hasAcl()) {
        result = result && getAcl()
            .equals(other.getAcl());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAccessType()) {
        hash = (37 * hash) + ACCESSTYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getAccessType());
      }
      if (hasAcl()) {
        hash = (37 * hash) + ACL_FIELD_NUMBER;
        hash = (53 * hash) + getAcl().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationACLMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
        bitField0_ = (bitField0_ & ~0x00000001);
        acl_ = " ";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.accessType_ = accessType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.acl_ = acl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance()) return this;
        if (other.hasAccessType()) {
          setAccessType(other.getAccessType());
        }
        if (other.hasAcl()) {
          bitField0_ |= 0x00000002;
          acl_ = other.acl_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public boolean hasAccessType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType() {
        return accessType_;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public Builder setAccessType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        accessType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public Builder clearAccessType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        accessType_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP;
        onChanged();
        return this;
      }

      // optional string acl = 2 [default = " "];
      private java.lang.Object acl_ = " ";
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public boolean hasAcl() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public java.lang.String getAcl() {
        java.lang.Object ref = acl_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          acl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public com.google.protobuf.ByteString
          getAclBytes() {
        java.lang.Object ref = acl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          acl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder setAcl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        acl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder clearAcl() {
        bitField0_ = (bitField0_ & ~0x00000002);
        acl_ = getDefaultInstance().getAcl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder setAclBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        acl_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationACLMapProto)
    }

    static {
      defaultInstance = new ApplicationACLMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationACLMapProto)
  }

  public interface YarnClusterMetricsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 num_node_managers = 1;
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    boolean hasNumNodeManagers();
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    int getNumNodeManagers();
  }
  /**
   * Protobuf type {@code hadoop.yarn.YarnClusterMetricsProto}
   */
  public static final class YarnClusterMetricsProto extends
      com.google.protobuf.GeneratedMessage
      implements YarnClusterMetricsProtoOrBuilder {
    // Use YarnClusterMetricsProto.newBuilder() to construct.
    private YarnClusterMetricsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private YarnClusterMetricsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final YarnClusterMetricsProto defaultInstance;
    public static YarnClusterMetricsProto getDefaultInstance() {
      return defaultInstance;
    }

    public YarnClusterMetricsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private YarnClusterMetricsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numNodeManagers_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<YarnClusterMetricsProto> PARSER =
        new com.google.protobuf.AbstractParser<YarnClusterMetricsProto>() {
      public YarnClusterMetricsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new YarnClusterMetricsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<YarnClusterMetricsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 num_node_managers = 1;
    public static final int NUM_NODE_MANAGERS_FIELD_NUMBER = 1;
    private int numNodeManagers_;
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    public boolean hasNumNodeManagers() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    public int getNumNodeManagers() {
      return numNodeManagers_;
    }

    private void initFields() {
      numNodeManagers_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, numNodeManagers_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, numNodeManagers_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) obj;

      boolean result = true;
      result = result && (hasNumNodeManagers() == other.hasNumNodeManagers());
      if (hasNumNodeManagers()) {
        result = result && (getNumNodeManagers()
            == other.getNumNodeManagers());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumNodeManagers()) {
        hash = (37 * hash) + NUM_NODE_MANAGERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumNodeManagers();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.YarnClusterMetricsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        numNodeManagers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numNodeManagers_ = numNodeManagers_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance()) return this;
        if (other.hasNumNodeManagers()) {
          setNumNodeManagers(other.getNumNodeManagers());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 num_node_managers = 1;
      private int numNodeManagers_ ;
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public boolean hasNumNodeManagers() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public int getNumNodeManagers() {
        return numNodeManagers_;
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public Builder setNumNodeManagers(int value) {
        bitField0_ |= 0x00000001;
        numNodeManagers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public Builder clearNumNodeManagers() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numNodeManagers_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.YarnClusterMetricsProto)
    }

    static {
      defaultInstance = new YarnClusterMetricsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.YarnClusterMetricsProto)
  }

  public interface QueueInfoProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string queueName = 1;
    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    // optional float capacity = 2;
    /**
     * <code>optional float capacity = 2;</code>
     */
    boolean hasCapacity();
    /**
     * <code>optional float capacity = 2;</code>
     */
    float getCapacity();

    // optional float maximumCapacity = 3;
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    boolean hasMaximumCapacity();
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    float getMaximumCapacity();

    // optional float currentCapacity = 4;
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    boolean hasCurrentCapacity();
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    float getCurrentCapacity();

    // optional .hadoop.yarn.QueueStateProto state = 5;
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    boolean hasState();
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState();

    // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> 
        getChildQueuesList();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index);
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    int getChildQueuesCount();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
        getChildQueuesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
        int index);

    // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> 
        getApplicationsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    int getApplicationsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueInfoProto}
   */
  public static final class QueueInfoProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueInfoProtoOrBuilder {
    // Use QueueInfoProto.newBuilder() to construct.
    private QueueInfoProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueInfoProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueInfoProto defaultInstance;
    public static QueueInfoProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueInfoProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              queueName_ = input.readBytes();
              break;
            }
            case 21: {
              bitField0_ |= 0x00000002;
              capacity_ = input.readFloat();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              maximumCapacity_ = input.readFloat();
              break;
            }
            case 37: {
              bitField0_ |= 0x00000008;
              currentCapacity_ = input.readFloat();
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                state_ = value;
              }
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                childQueues_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              childQueues_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>();
                mutable_bitField0_ |= 0x00000040;
              }
              applications_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          childQueues_ = java.util.Collections.unmodifiableList(childQueues_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          applications_ = java.util.Collections.unmodifiableList(applications_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueInfoProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueInfoProto>() {
      public QueueInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueInfoProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueInfoProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string queueName = 1;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional float capacity = 2;
    public static final int CAPACITY_FIELD_NUMBER = 2;
    private float capacity_;
    /**
     * <code>optional float capacity = 2;</code>
     */
    public boolean hasCapacity() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional float capacity = 2;</code>
     */
    public float getCapacity() {
      return capacity_;
    }

    // optional float maximumCapacity = 3;
    public static final int MAXIMUMCAPACITY_FIELD_NUMBER = 3;
    private float maximumCapacity_;
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    public boolean hasMaximumCapacity() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    public float getMaximumCapacity() {
      return maximumCapacity_;
    }

    // optional float currentCapacity = 4;
    public static final int CURRENTCAPACITY_FIELD_NUMBER = 4;
    private float currentCapacity_;
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    public boolean hasCurrentCapacity() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    public float getCurrentCapacity() {
      return currentCapacity_;
    }

    // optional .hadoop.yarn.QueueStateProto state = 5;
    public static final int STATE_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto state_;
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState() {
      return state_;
    }

    // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
    public static final int CHILDQUEUES_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> childQueues_;
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> getChildQueuesList() {
      return childQueues_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
        getChildQueuesOrBuilderList() {
      return childQueues_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public int getChildQueuesCount() {
      return childQueues_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index) {
      return childQueues_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
        int index) {
      return childQueues_.get(index);
    }

    // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
    public static final int APPLICATIONS_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public int getApplicationsCount() {
      return applications_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
      return applications_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index) {
      return applications_.get(index);
    }

    private void initFields() {
      queueName_ = "";
      capacity_ = 0F;
      maximumCapacity_ = 0F;
      currentCapacity_ = 0F;
      state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
      childQueues_ = java.util.Collections.emptyList();
      applications_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getChildQueuesCount(); i++) {
        if (!getChildQueues(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getApplicationsCount(); i++) {
        if (!getApplications(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getQueueNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeFloat(2, capacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(3, maximumCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeFloat(4, currentCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, state_.getNumber());
      }
      for (int i = 0; i < childQueues_.size(); i++) {
        output.writeMessage(6, childQueues_.get(i));
      }
      for (int i = 0; i < applications_.size(); i++) {
        output.writeMessage(7, applications_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getQueueNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, capacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, maximumCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(4, currentCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, state_.getNumber());
      }
      for (int i = 0; i < childQueues_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, childQueues_.get(i));
      }
      for (int i = 0; i < applications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, applications_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && (hasCapacity() == other.hasCapacity());
      if (hasCapacity()) {
        result = result && (Float.floatToIntBits(getCapacity())    == Float.floatToIntBits(other.getCapacity()));
      }
      result = result && (hasMaximumCapacity() == other.hasMaximumCapacity());
      if (hasMaximumCapacity()) {
        result = result && (Float.floatToIntBits(getMaximumCapacity())    == Float.floatToIntBits(other.getMaximumCapacity()));
      }
      result = result && (hasCurrentCapacity() == other.hasCurrentCapacity());
      if (hasCurrentCapacity()) {
        result = result && (Float.floatToIntBits(getCurrentCapacity())    == Float.floatToIntBits(other.getCurrentCapacity()));
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result &&
            (getState() == other.getState());
      }
      result = result && getChildQueuesList()
          .equals(other.getChildQueuesList());
      result = result && getApplicationsList()
          .equals(other.getApplicationsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (hasCapacity()) {
        hash = (37 * hash) + CAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getCapacity());
      }
      if (hasMaximumCapacity()) {
        hash = (37 * hash) + MAXIMUMCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getMaximumCapacity());
      }
      if (hasCurrentCapacity()) {
        hash = (37 * hash) + CURRENTCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getCurrentCapacity());
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getState());
      }
      if (getChildQueuesCount() > 0) {
        hash = (37 * hash) + CHILDQUEUES_FIELD_NUMBER;
        hash = (53 * hash) + getChildQueuesList().hashCode();
      }
      if (getApplicationsCount() > 0) {
        hash = (37 * hash) + APPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getChildQueuesFieldBuilder();
          getApplicationsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        capacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000002);
        maximumCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        currentCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000008);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (childQueuesBuilder_ == null) {
          childQueues_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          childQueuesBuilder_.clear();
        }
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.capacity_ = capacity_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.maximumCapacity_ = maximumCapacity_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.currentCapacity_ = currentCapacity_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.state_ = state_;
        if (childQueuesBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            childQueues_ = java.util.Collections.unmodifiableList(childQueues_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.childQueues_ = childQueues_;
        } else {
          result.childQueues_ = childQueuesBuilder_.build();
        }
        if (applicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            applications_ = java.util.Collections.unmodifiableList(applications_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.applications_ = applications_;
        } else {
          result.applications_ = applicationsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (other.hasCapacity()) {
          setCapacity(other.getCapacity());
        }
        if (other.hasMaximumCapacity()) {
          setMaximumCapacity(other.getMaximumCapacity());
        }
        if (other.hasCurrentCapacity()) {
          setCurrentCapacity(other.getCurrentCapacity());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (childQueuesBuilder_ == null) {
          if (!other.childQueues_.isEmpty()) {
            if (childQueues_.isEmpty()) {
              childQueues_ = other.childQueues_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureChildQueuesIsMutable();
              childQueues_.addAll(other.childQueues_);
            }
            onChanged();
          }
        } else {
          if (!other.childQueues_.isEmpty()) {
            if (childQueuesBuilder_.isEmpty()) {
              childQueuesBuilder_.dispose();
              childQueuesBuilder_ = null;
              childQueues_ = other.childQueues_;
              bitField0_ = (bitField0_ & ~0x00000020);
              childQueuesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getChildQueuesFieldBuilder() : null;
            } else {
              childQueuesBuilder_.addAllMessages(other.childQueues_);
            }
          }
        }
        if (applicationsBuilder_ == null) {
          if (!other.applications_.isEmpty()) {
            if (applications_.isEmpty()) {
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureApplicationsIsMutable();
              applications_.addAll(other.applications_);
            }
            onChanged();
          }
        } else {
          if (!other.applications_.isEmpty()) {
            if (applicationsBuilder_.isEmpty()) {
              applicationsBuilder_.dispose();
              applicationsBuilder_ = null;
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000040);
              applicationsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationsFieldBuilder() : null;
            } else {
              applicationsBuilder_.addAllMessages(other.applications_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getChildQueuesCount(); i++) {
          if (!getChildQueues(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getApplicationsCount(); i++) {
          if (!getApplications(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string queueName = 1;
      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queueName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      // optional float capacity = 2;
      private float capacity_ ;
      /**
       * <code>optional float capacity = 2;</code>
       */
      public boolean hasCapacity() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public float getCapacity() {
        return capacity_;
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public Builder setCapacity(float value) {
        bitField0_ |= 0x00000002;
        capacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public Builder clearCapacity() {
        bitField0_ = (bitField0_ & ~0x00000002);
        capacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float maximumCapacity = 3;
      private float maximumCapacity_ ;
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public boolean hasMaximumCapacity() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public float getMaximumCapacity() {
        return maximumCapacity_;
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public Builder setMaximumCapacity(float value) {
        bitField0_ |= 0x00000004;
        maximumCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public Builder clearMaximumCapacity() {
        bitField0_ = (bitField0_ & ~0x00000004);
        maximumCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional float currentCapacity = 4;
      private float currentCapacity_ ;
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public boolean hasCurrentCapacity() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public float getCurrentCapacity() {
        return currentCapacity_;
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public Builder setCurrentCapacity(float value) {
        bitField0_ |= 0x00000008;
        currentCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public Builder clearCurrentCapacity() {
        bitField0_ = (bitField0_ & ~0x00000008);
        currentCapacity_ = 0F;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.QueueStateProto state = 5;
      private org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState() {
        return state_;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public Builder setState(org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        state_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000010);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.QueueInfoProto childQueues = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> childQueues_ =
        java.util.Collections.emptyList();
      private void ensureChildQueuesIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          childQueues_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto>(childQueues_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> childQueuesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> getChildQueuesList() {
        if (childQueuesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(childQueues_);
        } else {
          return childQueuesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public int getChildQueuesCount() {
        if (childQueuesBuilder_ == null) {
          return childQueues_.size();
        } else {
          return childQueuesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index) {
        if (childQueuesBuilder_ == null) {
          return childQueues_.get(index);
        } else {
          return childQueuesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder setChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.set(index, value);
          onChanged();
        } else {
          childQueuesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder setChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.set(index, builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.add(value);
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.add(index, value);
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.add(builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.add(index, builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addAllChildQueues(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> values) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          super.addAll(values, childQueues_);
          onChanged();
        } else {
          childQueuesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder clearChildQueues() {
        if (childQueuesBuilder_ == null) {
          childQueues_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          childQueuesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder removeChildQueues(int index) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.remove(index);
          onChanged();
        } else {
          childQueuesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder getChildQueuesBuilder(
          int index) {
        return getChildQueuesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
          int index) {
        if (childQueuesBuilder_ == null) {
          return childQueues_.get(index);  } else {
          return childQueuesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
           getChildQueuesOrBuilderList() {
        if (childQueuesBuilder_ != null) {
          return childQueuesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(childQueues_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder addChildQueuesBuilder() {
        return getChildQueuesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder addChildQueuesBuilder(
          int index) {
        return getChildQueuesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder> 
           getChildQueuesBuilderList() {
        return getChildQueuesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
          getChildQueuesFieldBuilder() {
        if (childQueuesBuilder_ == null) {
          childQueuesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder>(
                  childQueues_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          childQueues_ = null;
        }
        return childQueuesBuilder_;
      }

      // repeated .hadoop.yarn.ApplicationReportProto applications = 7;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_ =
        java.util.Collections.emptyList();
      private void ensureApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>(applications_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
        if (applicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applications_);
        } else {
          return applicationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public int getApplicationsCount() {
        if (applicationsBuilder_ == null) {
          return applications_.size();
        } else {
          return applicationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);
        } else {
          return applicationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.set(index, value);
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(index, value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addAllApplications(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> values) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          super.addAll(values, applications_);
          onChanged();
        } else {
          applicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder clearApplications() {
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder removeApplications(int index) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.remove(index);
          onChanged();
        } else {
          applicationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
          int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);  } else {
          return applicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
           getApplicationsOrBuilderList() {
        if (applicationsBuilder_ != null) {
          return applicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applications_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder() {
        return getApplicationsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder> 
           getApplicationsBuilderList() {
        return getApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationsFieldBuilder() {
        if (applicationsBuilder_ == null) {
          applicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  applications_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          applications_ = null;
        }
        return applicationsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueInfoProto)
    }

    static {
      defaultInstance = new QueueInfoProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueInfoProto)
  }

  public interface QueueUserACLInfoProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string queueName = 1;
    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList();
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    int getUserAclsCount();
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueUserACLInfoProto}
   */
  public static final class QueueUserACLInfoProto extends
      com.google.protobuf.GeneratedMessage
      implements QueueUserACLInfoProtoOrBuilder {
    // Use QueueUserACLInfoProto.newBuilder() to construct.
    private QueueUserACLInfoProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private QueueUserACLInfoProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final QueueUserACLInfoProto defaultInstance;
    public static QueueUserACLInfoProto getDefaultInstance() {
      return defaultInstance;
    }

    public QueueUserACLInfoProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private QueueUserACLInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              queueName_ = input.readBytes();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  userAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>();
                  mutable_bitField0_ |= 0x00000002;
                }
                userAcls_.add(value);
              }
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(2, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    userAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>();
                    mutable_bitField0_ |= 0x00000002;
                  }
                  userAcls_.add(value);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = java.util.Collections.unmodifiableList(userAcls_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder.class);
    }

    public static com.google.protobuf.Parser<QueueUserACLInfoProto> PARSER =
        new com.google.protobuf.AbstractParser<QueueUserACLInfoProto>() {
      public QueueUserACLInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QueueUserACLInfoProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<QueueUserACLInfoProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string queueName = 1;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
    public static final int USERACLS_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> userAcls_;
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList() {
      return userAcls_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public int getUserAclsCount() {
      return userAcls_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index) {
      return userAcls_.get(index);
    }

    private void initFields() {
      queueName_ = "";
      userAcls_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getQueueNameBytes());
      }
      for (int i = 0; i < userAcls_.size(); i++) {
        output.writeEnum(2, userAcls_.get(i).getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getQueueNameBytes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < userAcls_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(userAcls_.get(i).getNumber());
        }
        size += dataSize;
        size += 1 * userAcls_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && getUserAclsList()
          .equals(other.getUserAclsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (getUserAclsCount() > 0) {
        hash = (37 * hash) + USERACLS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnumList(getUserAclsList());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueUserACLInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        userAcls_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = java.util.Collections.unmodifiableList(userAcls_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.userAcls_ = userAcls_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (!other.userAcls_.isEmpty()) {
          if (userAcls_.isEmpty()) {
            userAcls_ = other.userAcls_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureUserAclsIsMutable();
            userAcls_.addAll(other.userAcls_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string queueName = 1;
      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          queueName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.QueueACLProto userAcls = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> userAcls_ =
        java.util.Collections.emptyList();
      private void ensureUserAclsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>(userAcls_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList() {
        return java.util.Collections.unmodifiableList(userAcls_);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public int getUserAclsCount() {
        return userAcls_.size();
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index) {
        return userAcls_.get(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder setUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureUserAclsIsMutable();
        userAcls_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder addUserAcls(org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureUserAclsIsMutable();
        userAcls_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder addAllUserAcls(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> values) {
        ensureUserAclsIsMutable();
        super.addAll(values, userAcls_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder clearUserAcls() {
        userAcls_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueUserACLInfoProto)
    }

    static {
      defaultInstance = new QueueUserACLInfoProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueUserACLInfoProto)
  }

  public interface ContainerLaunchContextProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> 
        getLocalResourcesList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index);
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    int getLocalResourcesCount();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index);

    // optional bytes tokens = 2;
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    boolean hasTokens();
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    com.google.protobuf.ByteString getTokens();

    // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> 
        getServiceDataList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index);
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    int getServiceDataCount();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceDataOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
        int index);

    // repeated .hadoop.yarn.StringStringMapProto environment = 4;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> 
        getEnvironmentList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index);
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    int getEnvironmentCount();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getEnvironmentOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
        int index);

    // repeated string command = 5;
    /**
     * <code>repeated string command = 5;</code>
     */
    java.util.List<java.lang.String>
    getCommandList();
    /**
     * <code>repeated string command = 5;</code>
     */
    int getCommandCount();
    /**
     * <code>repeated string command = 5;</code>
     */
    java.lang.String getCommand(int index);
    /**
     * <code>repeated string command = 5;</code>
     */
    com.google.protobuf.ByteString
        getCommandBytes(int index);

    // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> 
        getApplicationACLsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    int getApplicationACLsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerLaunchContextProto}
   */
  public static final class ContainerLaunchContextProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerLaunchContextProtoOrBuilder {
    // Use ContainerLaunchContextProto.newBuilder() to construct.
    private ContainerLaunchContextProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerLaunchContextProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerLaunchContextProto defaultInstance;
    public static ContainerLaunchContextProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerLaunchContextProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerLaunchContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                localResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              localResources_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              bitField0_ |= 0x00000001;
              tokens_ = input.readBytes();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                serviceData_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              serviceData_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                environment_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>();
                mutable_bitField0_ |= 0x00000008;
              }
              environment_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                command_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000010;
              }
              command_.add(input.readBytes());
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              applicationACLs_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          localResources_ = java.util.Collections.unmodifiableList(localResources_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          serviceData_ = java.util.Collections.unmodifiableList(serviceData_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          environment_ = java.util.Collections.unmodifiableList(environment_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.UnmodifiableLazyStringList(command_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerLaunchContextProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerLaunchContextProto>() {
      public ContainerLaunchContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerLaunchContextProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerLaunchContextProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
    public static final int LOCALRESOURCES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_;
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public int getLocalResourcesCount() {
      return localResources_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
      return localResources_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index) {
      return localResources_.get(index);
    }

    // optional bytes tokens = 2;
    public static final int TOKENS_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString tokens_;
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    public boolean hasTokens() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    public com.google.protobuf.ByteString getTokens() {
      return tokens_;
    }

    // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
    public static final int SERVICE_DATA_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceData_;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceDataList() {
      return serviceData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceDataOrBuilderList() {
      return serviceData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public int getServiceDataCount() {
      return serviceData_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index) {
      return serviceData_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
        int index) {
      return serviceData_.get(index);
    }

    // repeated .hadoop.yarn.StringStringMapProto environment = 4;
    public static final int ENVIRONMENT_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> environment_;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getEnvironmentList() {
      return environment_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getEnvironmentOrBuilderList() {
      return environment_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public int getEnvironmentCount() {
      return environment_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index) {
      return environment_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
        int index) {
      return environment_.get(index);
    }

    // repeated string command = 5;
    public static final int COMMAND_FIELD_NUMBER = 5;
    private com.google.protobuf.LazyStringList command_;
    /**
     * <code>repeated string command = 5;</code>
     */
    public java.util.List<java.lang.String>
        getCommandList() {
      return command_;
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public int getCommandCount() {
      return command_.size();
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public java.lang.String getCommand(int index) {
      return command_.get(index);
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public com.google.protobuf.ByteString
        getCommandBytes(int index) {
      return command_.getByteString(index);
    }

    // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
    public static final int APPLICATION_ACLS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public int getApplicationACLsCount() {
      return applicationACLs_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
      return applicationACLs_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index) {
      return applicationACLs_.get(index);
    }

    private void initFields() {
      localResources_ = java.util.Collections.emptyList();
      tokens_ = com.google.protobuf.ByteString.EMPTY;
      serviceData_ = java.util.Collections.emptyList();
      environment_ = java.util.Collections.emptyList();
      command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      applicationACLs_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < localResources_.size(); i++) {
        output.writeMessage(1, localResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(2, tokens_);
      }
      for (int i = 0; i < serviceData_.size(); i++) {
        output.writeMessage(3, serviceData_.get(i));
      }
      for (int i = 0; i < environment_.size(); i++) {
        output.writeMessage(4, environment_.get(i));
      }
      for (int i = 0; i < command_.size(); i++) {
        output.writeBytes(5, command_.getByteString(i));
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        output.writeMessage(6, applicationACLs_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < localResources_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, localResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tokens_);
      }
      for (int i = 0; i < serviceData_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, serviceData_.get(i));
      }
      for (int i = 0; i < environment_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, environment_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < command_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(command_.getByteString(i));
        }
        size += dataSize;
        size += 1 * getCommandList().size();
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, applicationACLs_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) obj;

      boolean result = true;
      result = result && getLocalResourcesList()
          .equals(other.getLocalResourcesList());
      result = result && (hasTokens() == other.hasTokens());
      if (hasTokens()) {
        result = result && getTokens()
            .equals(other.getTokens());
      }
      result = result && getServiceDataList()
          .equals(other.getServiceDataList());
      result = result && getEnvironmentList()
          .equals(other.getEnvironmentList());
      result = result && getCommandList()
          .equals(other.getCommandList());
      result = result && getApplicationACLsList()
          .equals(other.getApplicationACLsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getLocalResourcesCount() > 0) {
        hash = (37 * hash) + LOCALRESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getLocalResourcesList().hashCode();
      }
      if (hasTokens()) {
        hash = (37 * hash) + TOKENS_FIELD_NUMBER;
        hash = (53 * hash) + getTokens().hashCode();
      }
      if (getServiceDataCount() > 0) {
        hash = (37 * hash) + SERVICE_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getServiceDataList().hashCode();
      }
      if (getEnvironmentCount() > 0) {
        hash = (37 * hash) + ENVIRONMENT_FIELD_NUMBER;
        hash = (53 * hash) + getEnvironmentList().hashCode();
      }
      if (getCommandCount() > 0) {
        hash = (37 * hash) + COMMAND_FIELD_NUMBER;
        hash = (53 * hash) + getCommandList().hashCode();
      }
      if (getApplicationACLsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ACLS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationACLsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerLaunchContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getLocalResourcesFieldBuilder();
          getServiceDataFieldBuilder();
          getEnvironmentFieldBuilder();
          getApplicationACLsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          localResourcesBuilder_.clear();
        }
        tokens_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (serviceDataBuilder_ == null) {
          serviceData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          serviceDataBuilder_.clear();
        }
        if (environmentBuilder_ == null) {
          environment_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          environmentBuilder_.clear();
        }
        command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (localResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            localResources_ = java.util.Collections.unmodifiableList(localResources_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.localResources_ = localResources_;
        } else {
          result.localResources_ = localResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.tokens_ = tokens_;
        if (serviceDataBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            serviceData_ = java.util.Collections.unmodifiableList(serviceData_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.serviceData_ = serviceData_;
        } else {
          result.serviceData_ = serviceDataBuilder_.build();
        }
        if (environmentBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            environment_ = java.util.Collections.unmodifiableList(environment_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.environment_ = environment_;
        } else {
          result.environment_ = environmentBuilder_.build();
        }
        if (((bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.UnmodifiableLazyStringList(
              command_);
          bitField0_ = (bitField0_ & ~0x00000010);
        }
        result.command_ = command_;
        if (applicationACLsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.applicationACLs_ = applicationACLs_;
        } else {
          result.applicationACLs_ = applicationACLsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) return this;
        if (localResourcesBuilder_ == null) {
          if (!other.localResources_.isEmpty()) {
            if (localResources_.isEmpty()) {
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureLocalResourcesIsMutable();
              localResources_.addAll(other.localResources_);
            }
            onChanged();
          }
        } else {
          if (!other.localResources_.isEmpty()) {
            if (localResourcesBuilder_.isEmpty()) {
              localResourcesBuilder_.dispose();
              localResourcesBuilder_ = null;
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
              localResourcesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getLocalResourcesFieldBuilder() : null;
            } else {
              localResourcesBuilder_.addAllMessages(other.localResources_);
            }
          }
        }
        if (other.hasTokens()) {
          setTokens(other.getTokens());
        }
        if (serviceDataBuilder_ == null) {
          if (!other.serviceData_.isEmpty()) {
            if (serviceData_.isEmpty()) {
              serviceData_ = other.serviceData_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureServiceDataIsMutable();
              serviceData_.addAll(other.serviceData_);
            }
            onChanged();
          }
        } else {
          if (!other.serviceData_.isEmpty()) {
            if (serviceDataBuilder_.isEmpty()) {
              serviceDataBuilder_.dispose();
              serviceDataBuilder_ = null;
              serviceData_ = other.serviceData_;
              bitField0_ = (bitField0_ & ~0x00000004);
              serviceDataBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getServiceDataFieldBuilder() : null;
            } else {
              serviceDataBuilder_.addAllMessages(other.serviceData_);
            }
          }
        }
        if (environmentBuilder_ == null) {
          if (!other.environment_.isEmpty()) {
            if (environment_.isEmpty()) {
              environment_ = other.environment_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureEnvironmentIsMutable();
              environment_.addAll(other.environment_);
            }
            onChanged();
          }
        } else {
          if (!other.environment_.isEmpty()) {
            if (environmentBuilder_.isEmpty()) {
              environmentBuilder_.dispose();
              environmentBuilder_ = null;
              environment_ = other.environment_;
              bitField0_ = (bitField0_ & ~0x00000008);
              environmentBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getEnvironmentFieldBuilder() : null;
            } else {
              environmentBuilder_.addAllMessages(other.environment_);
            }
          }
        }
        if (!other.command_.isEmpty()) {
          if (command_.isEmpty()) {
            command_ = other.command_;
            bitField0_ = (bitField0_ & ~0x00000010);
          } else {
            ensureCommandIsMutable();
            command_.addAll(other.command_);
          }
          onChanged();
        }
        if (applicationACLsBuilder_ == null) {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLs_.isEmpty()) {
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureApplicationACLsIsMutable();
              applicationACLs_.addAll(other.applicationACLs_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLsBuilder_.isEmpty()) {
              applicationACLsBuilder_.dispose();
              applicationACLsBuilder_ = null;
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000020);
              applicationACLsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationACLsFieldBuilder() : null;
            } else {
              applicationACLsBuilder_.addAllMessages(other.applicationACLs_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_ =
        java.util.Collections.emptyList();
      private void ensureLocalResourcesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          localResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>(localResources_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> localResourcesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
        if (localResourcesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(localResources_);
        } else {
          return localResourcesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public int getLocalResourcesCount() {
        if (localResourcesBuilder_ == null) {
          return localResources_.size();
        } else {
          return localResourcesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);
        } else {
          return localResourcesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder setLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.set(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder setLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.set(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addAllLocalResources(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> values) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          super.addAll(values, localResources_);
          onChanged();
        } else {
          localResourcesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder clearLocalResources() {
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          localResourcesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder removeLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.remove(index);
          onChanged();
        } else {
          localResourcesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder getLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
          int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);  } else {
          return localResourcesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
           getLocalResourcesOrBuilderList() {
        if (localResourcesBuilder_ != null) {
          return localResourcesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(localResources_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder() {
        return getLocalResourcesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder> 
           getLocalResourcesBuilderList() {
        return getLocalResourcesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
          getLocalResourcesFieldBuilder() {
        if (localResourcesBuilder_ == null) {
          localResourcesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder>(
                  localResources_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          localResources_ = null;
        }
        return localResourcesBuilder_;
      }

      // optional bytes tokens = 2;
      private com.google.protobuf.ByteString tokens_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public boolean hasTokens() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public com.google.protobuf.ByteString getTokens() {
        return tokens_;
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public Builder setTokens(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        tokens_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public Builder clearTokens() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tokens_ = getDefaultInstance().getTokens();
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.StringBytesMapProto service_data = 3;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceData_ =
        java.util.Collections.emptyList();
      private void ensureServiceDataIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          serviceData_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>(serviceData_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> serviceDataBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceDataList() {
        if (serviceDataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(serviceData_);
        } else {
          return serviceDataBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public int getServiceDataCount() {
        if (serviceDataBuilder_ == null) {
          return serviceData_.size();
        } else {
          return serviceDataBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index) {
        if (serviceDataBuilder_ == null) {
          return serviceData_.get(index);
        } else {
          return serviceDataBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder setServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.set(index, value);
          onChanged();
        } else {
          serviceDataBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder setServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.set(index, builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.add(value);
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.add(index, value);
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.add(builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.add(index, builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addAllServiceData(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> values) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          super.addAll(values, serviceData_);
          onChanged();
        } else {
          serviceDataBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder clearServiceData() {
        if (serviceDataBuilder_ == null) {
          serviceData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          serviceDataBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder removeServiceData(int index) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.remove(index);
          onChanged();
        } else {
          serviceDataBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder getServiceDataBuilder(
          int index) {
        return getServiceDataFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
          int index) {
        if (serviceDataBuilder_ == null) {
          return serviceData_.get(index);  } else {
          return serviceDataBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
           getServiceDataOrBuilderList() {
        if (serviceDataBuilder_ != null) {
          return serviceDataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(serviceData_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceDataBuilder() {
        return getServiceDataFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceDataBuilder(
          int index) {
        return getServiceDataFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder> 
           getServiceDataBuilderList() {
        return getServiceDataFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
          getServiceDataFieldBuilder() {
        if (serviceDataBuilder_ == null) {
          serviceDataBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder>(
                  serviceData_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          serviceData_ = null;
        }
        return serviceDataBuilder_;
      }

      // repeated .hadoop.yarn.StringStringMapProto environment = 4;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> environment_ =
        java.util.Collections.emptyList();
      private void ensureEnvironmentIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          environment_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>(environment_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> environmentBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getEnvironmentList() {
        if (environmentBuilder_ == null) {
          return java.util.Collections.unmodifiableList(environment_);
        } else {
          return environmentBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public int getEnvironmentCount() {
        if (environmentBuilder_ == null) {
          return environment_.size();
        } else {
          return environmentBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index) {
        if (environmentBuilder_ == null) {
          return environment_.get(index);
        } else {
          return environmentBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder setEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.set(index, value);
          onChanged();
        } else {
          environmentBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder setEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.set(index, builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.add(value);
          onChanged();
        } else {
          environmentBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.add(index, value);
          onChanged();
        } else {
          environmentBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.add(builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.add(index, builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addAllEnvironment(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> values) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          super.addAll(values, environment_);
          onChanged();
        } else {
          environmentBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder clearEnvironment() {
        if (environmentBuilder_ == null) {
          environment_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          environmentBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder removeEnvironment(int index) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.remove(index);
          onChanged();
        } else {
          environmentBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder getEnvironmentBuilder(
          int index) {
        return getEnvironmentFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
          int index) {
        if (environmentBuilder_ == null) {
          return environment_.get(index);  } else {
          return environmentBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
           getEnvironmentOrBuilderList() {
        if (environmentBuilder_ != null) {
          return environmentBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(environment_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addEnvironmentBuilder() {
        return getEnvironmentFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addEnvironmentBuilder(
          int index) {
        return getEnvironmentFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder> 
           getEnvironmentBuilderList() {
        return getEnvironmentFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
          getEnvironmentFieldBuilder() {
        if (environmentBuilder_ == null) {
          environmentBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder>(
                  environment_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          environment_ = null;
        }
        return environmentBuilder_;
      }

      // repeated string command = 5;
      private com.google.protobuf.LazyStringList command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureCommandIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.LazyStringArrayList(command_);
          bitField0_ |= 0x00000010;
         }
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public java.util.List<java.lang.String>
          getCommandList() {
        return java.util.Collections.unmodifiableList(command_);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public int getCommandCount() {
        return command_.size();
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public java.lang.String getCommand(int index) {
        return command_.get(index);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public com.google.protobuf.ByteString
          getCommandBytes(int index) {
        return command_.getByteString(index);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder setCommand(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addCommand(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addAllCommand(
          java.lang.Iterable<java.lang.String> values) {
        ensureCommandIsMutable();
        super.addAll(values, command_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder clearCommand() {
        command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addCommandBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.add(value);
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_ =
        java.util.Collections.emptyList();
      private void ensureApplicationACLsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>(applicationACLs_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> applicationACLsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
        if (applicationACLsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        } else {
          return applicationACLsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public int getApplicationACLsCount() {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.size();
        } else {
          return applicationACLsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);
        } else {
          return applicationACLsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addAllApplicationACLs(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> values) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          super.addAll(values, applicationACLs_);
          onChanged();
        } else {
          applicationACLsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder clearApplicationACLs() {
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder removeApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.remove(index);
          onChanged();
        } else {
          applicationACLsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder getApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
          int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);  } else {
          return applicationACLsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
           getApplicationACLsOrBuilderList() {
        if (applicationACLsBuilder_ != null) {
          return applicationACLsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder() {
        return getApplicationACLsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder> 
           getApplicationACLsBuilderList() {
        return getApplicationACLsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
          getApplicationACLsFieldBuilder() {
        if (applicationACLsBuilder_ == null) {
          applicationACLsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder>(
                  applicationACLs_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          applicationACLs_ = null;
        }
        return applicationACLsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerLaunchContextProto)
    }

    static {
      defaultInstance = new ContainerLaunchContextProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerLaunchContextProto)
  }

  public interface ContainerStatusProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ContainerStateProto state = 2;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    boolean hasState();
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState();

    // optional string diagnostics = 3 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    // optional int32 exit_status = 4 [default = -1000];
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    boolean hasExitStatus();
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    int getExitStatus();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerStatusProto}
   */
  public static final class ContainerStatusProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerStatusProtoOrBuilder {
    // Use ContainerStatusProto.newBuilder() to construct.
    private ContainerStatusProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerStatusProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerStatusProto defaultInstance;
    public static ContainerStatusProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerStatusProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerStatusProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                state_ = value;
              }
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              diagnostics_ = input.readBytes();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              exitStatus_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerStatusProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerStatusProto>() {
      public ContainerStatusProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerStatusProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerStatusProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ContainerStateProto state = 2;
    public static final int STATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto state_;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState() {
      return state_;
    }

    // optional string diagnostics = 3 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 3;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 exit_status = 4 [default = -1000];
    public static final int EXIT_STATUS_FIELD_NUMBER = 4;
    private int exitStatus_;
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    public boolean hasExitStatus() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    public int getExitStatus() {
      return exitStatus_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      diagnostics_ = "N/A";
      exitStatus_ = -1000;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, state_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, exitStatus_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, state_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, exitStatus_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result &&
            (getState() == other.getState());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasExitStatus() == other.hasExitStatus());
      if (hasExitStatus()) {
        result = result && (getExitStatus()
            == other.getExitStatus());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getState());
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasExitStatus()) {
        hash = (37 * hash) + EXIT_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getExitStatus();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerStatusProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        bitField0_ = (bitField0_ & ~0x00000002);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000004);
        exitStatus_ = -1000;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.state_ = state_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.exitStatus_ = exitStatus_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000004;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasExitStatus()) {
          setExitStatus(other.getExitStatus());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ContainerStateProto state = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState() {
        return state_;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public Builder setState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        state_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        state_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        onChanged();
        return this;
      }

      // optional string diagnostics = 3 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000004);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // optional int32 exit_status = 4 [default = -1000];
      private int exitStatus_ = -1000;
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public boolean hasExitStatus() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public int getExitStatus() {
        return exitStatus_;
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public Builder setExitStatus(int value) {
        bitField0_ |= 0x00000008;
        exitStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public Builder clearExitStatus() {
        bitField0_ = (bitField0_ & ~0x00000008);
        exitStatus_ = -1000;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerStatusProto)
    }

    static {
      defaultInstance = new ContainerStatusProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerStatusProto)
  }

  public interface ContainerResourceIncreaseRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseRequestProto}
   */
  public static final class ContainerResourceIncreaseRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerResourceIncreaseRequestProtoOrBuilder {
    // Use ContainerResourceIncreaseRequestProto.newBuilder() to construct.
    private ContainerResourceIncreaseRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerResourceIncreaseRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerResourceIncreaseRequestProto defaultInstance;
    public static ContainerResourceIncreaseRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerResourceIncreaseRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceIncreaseRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerResourceIncreaseRequestProto>() {
      public ContainerResourceIncreaseRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerResourceIncreaseRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 2;
    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, capability_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, capability_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
    }

    static {
      defaultInstance = new ContainerResourceIncreaseRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
  }

  public interface ContainerResourceIncreaseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    // optional .hadoop.common.TokenProto container_token = 3;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseProto}
   */
  public static final class ContainerResourceIncreaseProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerResourceIncreaseProtoOrBuilder {
    // Use ContainerResourceIncreaseProto.newBuilder() to construct.
    private ContainerResourceIncreaseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerResourceIncreaseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerResourceIncreaseProto defaultInstance;
    public static ContainerResourceIncreaseProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerResourceIncreaseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceIncreaseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerResourceIncreaseProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerResourceIncreaseProto>() {
      public ContainerResourceIncreaseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerResourceIncreaseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceIncreaseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 2;
    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    // optional .hadoop.common.TokenProto container_token = 3;
    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 3;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, capability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, containerToken_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, capability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, containerToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // optional .hadoop.common.TokenProto container_token = 3;
      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder setContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder setContainerToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder mergeContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              containerToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance();
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  containerToken_,
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceIncreaseProto)
    }

    static {
      defaultInstance = new ContainerResourceIncreaseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseProto)
  }

  public interface ContainerResourceDecreaseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ResourceProto capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceDecreaseProto}
   */
  public static final class ContainerResourceDecreaseProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerResourceDecreaseProtoOrBuilder {
    // Use ContainerResourceDecreaseProto.newBuilder() to construct.
    private ContainerResourceDecreaseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerResourceDecreaseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerResourceDecreaseProto defaultInstance;
    public static ContainerResourceDecreaseProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerResourceDecreaseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceDecreaseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerResourceDecreaseProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerResourceDecreaseProto>() {
      public ContainerResourceDecreaseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerResourceDecreaseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceDecreaseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ResourceProto capability = 2;
    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_;
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, capability_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, capability_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceDecreaseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  capability_,
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceDecreaseProto)
    }

    static {
      defaultInstance = new ContainerResourceDecreaseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceDecreaseProto)
  }

  public interface StringLocalResourceMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string key = 1;
    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    // optional .hadoop.yarn.LocalResourceProto value = 2;
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue();
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringLocalResourceMapProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From common//////////////////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class StringLocalResourceMapProto extends
      com.google.protobuf.GeneratedMessage
      implements StringLocalResourceMapProtoOrBuilder {
    // Use StringLocalResourceMapProto.newBuilder() to construct.
    private StringLocalResourceMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StringLocalResourceMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StringLocalResourceMapProto defaultInstance;
    public static StringLocalResourceMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public StringLocalResourceMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StringLocalResourceMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              key_ = input.readBytes();
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = value_.toBuilder();
              }
              value_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(value_);
                value_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StringLocalResourceMapProto> PARSER =
        new com.google.protobuf.AbstractParser<StringLocalResourceMapProto>() {
      public StringLocalResourceMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StringLocalResourceMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StringLocalResourceMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string key = 1;
    public static final int KEY_FIELD_NUMBER = 1;
    private java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hadoop.yarn.LocalResourceProto value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue() {
      return value_;
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder() {
      return value_;
    }

    private void initFields() {
      key_ = "";
      value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringLocalResourceMapProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From common//////////////////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getValueFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string key = 1;
      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          key_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.LocalResourceProto value = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder> valueBuilder_;
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder setValue(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder setValue(
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder mergeValue(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              value_ != org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringLocalResourceMapProto)
    }

    static {
      defaultInstance = new StringLocalResourceMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringLocalResourceMapProto)
  }

  public interface StringStringMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string key = 1;
    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    // optional string value = 2;
    /**
     * <code>optional string value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional string value = 2;</code>
     */
    java.lang.String getValue();
    /**
     * <code>optional string value = 2;</code>
     */
    com.google.protobuf.ByteString
        getValueBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringStringMapProto}
   */
  public static final class StringStringMapProto extends
      com.google.protobuf.GeneratedMessage
      implements StringStringMapProtoOrBuilder {
    // Use StringStringMapProto.newBuilder() to construct.
    private StringStringMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StringStringMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StringStringMapProto defaultInstance;
    public static StringStringMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public StringStringMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StringStringMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              key_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StringStringMapProto> PARSER =
        new com.google.protobuf.AbstractParser<StringStringMapProto>() {
      public StringStringMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StringStringMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StringStringMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string key = 1;
    public static final int KEY_FIELD_NUMBER = 1;
    private java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private java.lang.Object value_;
    /**
     * <code>optional string value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string value = 2;</code>
     */
    public java.lang.String getValue() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          value_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string value = 2;</code>
     */
    public com.google.protobuf.ByteString
        getValueBytes() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        value_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      key_ = "";
      value_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getValueBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getValueBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringStringMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          bitField0_ |= 0x00000002;
          value_ = other.value_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string key = 1;
      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          key_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      // optional string value = 2;
      private java.lang.Object value_ = "";
      /**
       * <code>optional string value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public java.lang.String getValue() {
        java.lang.Object ref = value_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          value_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public com.google.protobuf.ByteString
          getValueBytes() {
        java.lang.Object ref = value_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          value_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder setValue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder setValueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringStringMapProto)
    }

    static {
      defaultInstance = new StringStringMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringStringMapProto)
  }

  public interface StringBytesMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string key = 1;
    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    // optional bytes value = 2;
    /**
     * <code>optional bytes value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional bytes value = 2;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringBytesMapProto}
   */
  public static final class StringBytesMapProto extends
      com.google.protobuf.GeneratedMessage
      implements StringBytesMapProtoOrBuilder {
    // Use StringBytesMapProto.newBuilder() to construct.
    private StringBytesMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private StringBytesMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final StringBytesMapProto defaultInstance;
    public static StringBytesMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public StringBytesMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private StringBytesMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              key_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<StringBytesMapProto> PARSER =
        new com.google.protobuf.AbstractParser<StringBytesMapProto>() {
      public StringBytesMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StringBytesMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<StringBytesMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string key = 1;
    public static final int KEY_FIELD_NUMBER = 1;
    private java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bytes value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>optional bytes value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes value = 2;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private void initFields() {
      key_ = "";
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringBytesMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string key = 1;
      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          key_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      // optional bytes value = 2;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringBytesMapProto)
    }

    static {
      defaultInstance = new StringBytesMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringBytesMapProto)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PriorityProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_URLProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_URLProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LocalResourceProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeIdProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueInfoProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringStringMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\021yarn_protos.proto\022\013hadoop.yarn\032\016Securi" +
      "ty.proto\"\204\001\n\030SerializedExceptionProto\022\017\n" +
      "\007message\030\001 \001(\t\022\r\n\005trace\030\002 \001(\t\022\022\n\nclass_n" +
      "ame\030\003 \001(\t\0224\n\005cause\030\004 \001(\0132%.hadoop.yarn.S" +
      "erializedExceptionProto\";\n\022ApplicationId" +
      "Proto\022\n\n\002id\030\001 \001(\005\022\031\n\021cluster_timestamp\030\002" +
      " \001(\003\"g\n\031ApplicationAttemptIdProto\0227\n\016app" +
      "lication_id\030\001 \001(\0132\037.hadoop.yarn.Applicat" +
      "ionIdProto\022\021\n\tattemptId\030\002 \001(\005\"\217\001\n\020Contai" +
      "nerIdProto\022/\n\006app_id\030\001 \001(\0132\037.hadoop.yarn",
      ".ApplicationIdProto\022>\n\016app_attempt_id\030\002 " +
      "\001(\0132&.hadoop.yarn.ApplicationAttemptIdPr" +
      "oto\022\n\n\002id\030\003 \001(\005\"6\n\rResourceProto\022\016\n\006memo" +
      "ry\030\001 \001(\005\022\025\n\rvirtual_cores\030\002 \001(\005\"`\n\023Resou" +
      "rceOptionProto\022,\n\010resource\030\001 \001(\0132\032.hadoo" +
      "p.yarn.ResourceProto\022\033\n\023over_commit_time" +
      "out\030\002 \001(\005\"|\n\024NodeResourceMapProto\022)\n\007nod" +
      "e_id\030\001 \001(\0132\030.hadoop.yarn.NodeIdProto\0229\n\017" +
      "resource_option\030\002 \001(\0132 .hadoop.yarn.Reso" +
      "urceOptionProto\"!\n\rPriorityProto\022\020\n\010prio",
      "rity\030\001 \001(\005\"\220\002\n\016ContainerProto\022)\n\002id\030\001 \001(" +
      "\0132\035.hadoop.yarn.ContainerIdProto\022(\n\006node" +
      "Id\030\002 \001(\0132\030.hadoop.yarn.NodeIdProto\022\031\n\021no" +
      "de_http_address\030\003 \001(\t\022,\n\010resource\030\004 \001(\0132" +
      "\032.hadoop.yarn.ResourceProto\022,\n\010priority\030" +
      "\005 \001(\0132\032.hadoop.yarn.PriorityProto\0222\n\017con" +
      "tainer_token\030\006 \001(\0132\031.hadoop.common.Token" +
      "Proto\"V\n\010URLProto\022\016\n\006scheme\030\001 \001(\t\022\014\n\004hos" +
      "t\030\002 \001(\t\022\014\n\004port\030\003 \001(\005\022\014\n\004file\030\004 \001(\t\022\020\n\010u" +
      "serInfo\030\005 \001(\t\"\341\001\n\022LocalResourceProto\022\'\n\010",
      "resource\030\001 \001(\0132\025.hadoop.yarn.URLProto\022\014\n" +
      "\004size\030\002 \001(\003\022\021\n\ttimestamp\030\003 \001(\003\0221\n\004type\030\004" +
      " \001(\0162#.hadoop.yarn.LocalResourceTypeProt" +
      "o\022=\n\nvisibility\030\005 \001(\0162).hadoop.yarn.Loca" +
      "lResourceVisibilityProto\022\017\n\007pattern\030\006 \001(" +
      "\t\"\205\002\n#ApplicationResourceUsageReportProt" +
      "o\022\033\n\023num_used_containers\030\001 \001(\005\022\037\n\027num_re" +
      "served_containers\030\002 \001(\005\0222\n\016used_resource" +
      "s\030\003 \001(\0132\032.hadoop.yarn.ResourceProto\0226\n\022r" +
      "eserved_resources\030\004 \001(\0132\032.hadoop.yarn.Re",
      "sourceProto\0224\n\020needed_resources\030\005 \001(\0132\032." +
      "hadoop.yarn.ResourceProto\"\317\005\n\026Applicatio" +
      "nReportProto\0226\n\rapplicationId\030\001 \001(\0132\037.ha" +
      "doop.yarn.ApplicationIdProto\022\014\n\004user\030\002 \001" +
      "(\t\022\r\n\005queue\030\003 \001(\t\022\014\n\004name\030\004 \001(\t\022\014\n\004host\030" +
      "\005 \001(\t\022\020\n\010rpc_port\030\006 \001(\005\0225\n\022client_to_am_" +
      "token\030\007 \001(\0132\031.hadoop.common.TokenProto\022F" +
      "\n\026yarn_application_state\030\010 \001(\0162&.hadoop." +
      "yarn.YarnApplicationStateProto\022\023\n\013tracki" +
      "ngUrl\030\t \001(\t\022\030\n\013diagnostics\030\n \001(\t:\003N/A\022\021\n",
      "\tstartTime\030\013 \001(\003\022\022\n\nfinishTime\030\014 \001(\003\022J\n\030" +
      "final_application_status\030\r \001(\0162(.hadoop." +
      "yarn.FinalApplicationStatusProto\022L\n\022app_" +
      "resource_Usage\030\016 \001(\01320.hadoop.yarn.Appli" +
      "cationResourceUsageReportProto\022\033\n\023origin" +
      "alTrackingUrl\030\017 \001(\t\022K\n\033currentApplicatio" +
      "nAttemptId\030\020 \001(\0132&.hadoop.yarn.Applicati" +
      "onAttemptIdProto\022\020\n\010progress\030\021 \001(\002\022\027\n\017ap" +
      "plicationType\030\022 \001(\t\022.\n\013am_rm_token\030\023 \001(\013" +
      "2\031.hadoop.common.TokenProto\")\n\013NodeIdPro",
      "to\022\014\n\004host\030\001 \001(\t\022\014\n\004port\030\002 \001(\005\"\274\002\n\017NodeR" +
      "eportProto\022(\n\006nodeId\030\001 \001(\0132\030.hadoop.yarn" +
      ".NodeIdProto\022\023\n\013httpAddress\030\002 \001(\t\022\020\n\010rac" +
      "kName\030\003 \001(\t\022(\n\004used\030\004 \001(\0132\032.hadoop.yarn." +
      "ResourceProto\022.\n\ncapability\030\005 \001(\0132\032.hado" +
      "op.yarn.ResourceProto\022\025\n\rnumContainers\030\006" +
      " \001(\005\022/\n\nnode_state\030\007 \001(\0162\033.hadoop.yarn.N" +
      "odeStateProto\022\025\n\rhealth_report\030\010 \001(\t\022\037\n\027" +
      "last_health_report_time\030\t \001(\003\"\301\001\n\024Resour" +
      "ceRequestProto\022,\n\010priority\030\001 \001(\0132\032.hadoo",
      "p.yarn.PriorityProto\022\025\n\rresource_name\030\002 " +
      "\001(\t\022.\n\ncapability\030\003 \001(\0132\032.hadoop.yarn.Re" +
      "sourceProto\022\026\n\016num_containers\030\004 \001(\005\022\034\n\016r" +
      "elax_locality\030\005 \001(\010:\004true\"\224\001\n\026Preemption" +
      "MessageProto\022B\n\016strictContract\030\001 \001(\0132*.h" +
      "adoop.yarn.StrictPreemptionContractProto" +
      "\0226\n\010contract\030\002 \001(\0132$.hadoop.yarn.Preempt" +
      "ionContractProto\"Y\n\035StrictPreemptionCont" +
      "ractProto\0228\n\tcontainer\030\001 \003(\0132%.hadoop.ya" +
      "rn.PreemptionContainerProto\"\222\001\n\027Preempti",
      "onContractProto\022=\n\010resource\030\001 \003(\0132+.hado" +
      "op.yarn.PreemptionResourceRequestProto\0228" +
      "\n\tcontainer\030\002 \003(\0132%.hadoop.yarn.Preempti" +
      "onContainerProto\"E\n\030PreemptionContainerP" +
      "roto\022)\n\002id\030\001 \001(\0132\035.hadoop.yarn.Container" +
      "IdProto\"U\n\036PreemptionResourceRequestProt" +
      "o\0223\n\010resource\030\001 \001(\0132!.hadoop.yarn.Resour" +
      "ceRequestProto\"X\n\035ResourceBlacklistReque" +
      "stProto\022\033\n\023blacklist_additions\030\001 \003(\t\022\032\n\022" +
      "blacklist_removals\030\002 \003(\t\"\266\003\n!Application",
      "SubmissionContextProto\0227\n\016application_id" +
      "\030\001 \001(\0132\037.hadoop.yarn.ApplicationIdProto\022" +
      "\035\n\020application_name\030\002 \001(\t:\003N/A\022\026\n\005queue\030" +
      "\003 \001(\t:\007default\022,\n\010priority\030\004 \001(\0132\032.hadoo" +
      "p.yarn.PriorityProto\022C\n\021am_container_spe" +
      "c\030\005 \001(\0132(.hadoop.yarn.ContainerLaunchCon" +
      "textProto\022)\n\033cancel_tokens_when_complete" +
      "\030\006 \001(\010:\004true\022\033\n\014unmanaged_am\030\007 \001(\010:\005fals" +
      "e\022\031\n\016maxAppAttempts\030\010 \001(\005:\0010\022,\n\010resource" +
      "\030\t \001(\0132\032.hadoop.yarn.ResourceProto\022\035\n\017ap",
      "plicationType\030\n \001(\t:\004YARN\"e\n\026Application" +
      "ACLMapProto\022;\n\naccessType\030\001 \001(\0162\'.hadoop" +
      ".yarn.ApplicationAccessTypeProto\022\016\n\003acl\030" +
      "\002 \001(\t:\001 \"4\n\027YarnClusterMetricsProto\022\031\n\021n" +
      "um_node_managers\030\001 \001(\005\"\201\002\n\016QueueInfoProt" +
      "o\022\021\n\tqueueName\030\001 \001(\t\022\020\n\010capacity\030\002 \001(\002\022\027" +
      "\n\017maximumCapacity\030\003 \001(\002\022\027\n\017currentCapaci" +
      "ty\030\004 \001(\002\022+\n\005state\030\005 \001(\0162\034.hadoop.yarn.Qu" +
      "eueStateProto\0220\n\013childQueues\030\006 \003(\0132\033.had" +
      "oop.yarn.QueueInfoProto\0229\n\014applications\030",
      "\007 \003(\0132#.hadoop.yarn.ApplicationReportPro" +
      "to\"X\n\025QueueUserACLInfoProto\022\021\n\tqueueName" +
      "\030\001 \001(\t\022,\n\010userAcls\030\002 \003(\0162\032.hadoop.yarn.Q" +
      "ueueACLProto\"\257\002\n\033ContainerLaunchContextP" +
      "roto\022@\n\016localResources\030\001 \003(\0132(.hadoop.ya" +
      "rn.StringLocalResourceMapProto\022\016\n\006tokens" +
      "\030\002 \001(\014\0226\n\014service_data\030\003 \003(\0132 .hadoop.ya" +
      "rn.StringBytesMapProto\0226\n\013environment\030\004 " +
      "\003(\0132!.hadoop.yarn.StringStringMapProto\022\017" +
      "\n\007command\030\005 \003(\t\022=\n\020application_ACLs\030\006 \003(",
      "\0132#.hadoop.yarn.ApplicationACLMapProto\"\262" +
      "\001\n\024ContainerStatusProto\0223\n\014container_id\030" +
      "\001 \001(\0132\035.hadoop.yarn.ContainerIdProto\022/\n\005" +
      "state\030\002 \001(\0162 .hadoop.yarn.ContainerState" +
      "Proto\022\030\n\013diagnostics\030\003 \001(\t:\003N/A\022\032\n\013exit_" +
      "status\030\004 \001(\005:\005-1000\"\214\001\n%ContainerResourc" +
      "eIncreaseRequestProto\0223\n\014container_id\030\001 " +
      "\001(\0132\035.hadoop.yarn.ContainerIdProto\022.\n\nca" +
      "pability\030\002 \001(\0132\032.hadoop.yarn.ResourcePro" +
      "to\"\271\001\n\036ContainerResourceIncreaseProto\0223\n",
      "\014container_id\030\001 \001(\0132\035.hadoop.yarn.Contai" +
      "nerIdProto\022.\n\ncapability\030\002 \001(\0132\032.hadoop." +
      "yarn.ResourceProto\0222\n\017container_token\030\003 " +
      "\001(\0132\031.hadoop.common.TokenProto\"\205\001\n\036Conta" +
      "inerResourceDecreaseProto\0223\n\014container_i" +
      "d\030\001 \001(\0132\035.hadoop.yarn.ContainerIdProto\022." +
      "\n\ncapability\030\002 \001(\0132\032.hadoop.yarn.Resourc" +
      "eProto\"Z\n\033StringLocalResourceMapProto\022\013\n" +
      "\003key\030\001 \001(\t\022.\n\005value\030\002 \001(\0132\037.hadoop.yarn." +
      "LocalResourceProto\"2\n\024StringStringMapPro",
      "to\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t\"1\n\023String" +
      "BytesMapProto\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(" +
      "\014*?\n\023ContainerStateProto\022\t\n\005C_NEW\020\001\022\r\n\tC" +
      "_RUNNING\020\002\022\016\n\nC_COMPLETE\020\003*\204\001\n\031YarnAppli" +
      "cationStateProto\022\007\n\003NEW\020\001\022\016\n\nNEW_SAVING\020" +
      "\002\022\r\n\tSUBMITTED\020\003\022\014\n\010ACCEPTED\020\004\022\013\n\007RUNNIN" +
      "G\020\005\022\014\n\010FINISHED\020\006\022\n\n\006FAILED\020\007\022\n\n\006KILLED\020" +
      "\010*c\n\033FinalApplicationStatusProto\022\021\n\rAPP_" +
      "UNDEFINED\020\000\022\021\n\rAPP_SUCCEEDED\020\001\022\016\n\nAPP_FA" +
      "ILED\020\002\022\016\n\nAPP_KILLED\020\003*H\n\034LocalResourceV",
      "isibilityProto\022\n\n\006PUBLIC\020\001\022\013\n\007PRIVATE\020\002\022" +
      "\017\n\013APPLICATION\020\003*<\n\026LocalResourceTypePro" +
      "to\022\013\n\007ARCHIVE\020\001\022\010\n\004FILE\020\002\022\013\n\007PATTERN\020\003*s" +
      "\n\016NodeStateProto\022\n\n\006NS_NEW\020\001\022\016\n\nNS_RUNNI" +
      "NG\020\002\022\020\n\014NS_UNHEALTHY\020\003\022\025\n\021NS_DECOMMISSIO" +
      "NED\020\004\022\013\n\007NS_LOST\020\005\022\017\n\013NS_REBOOTED\020\006*0\n\016A" +
      "MCommandProto\022\r\n\tAM_RESYNC\020\001\022\017\n\013AM_SHUTD" +
      "OWN\020\002*N\n\032ApplicationAccessTypeProto\022\026\n\022A" +
      "PPACCESS_VIEW_APP\020\001\022\030\n\024APPACCESS_MODIFY_" +
      "APP\020\002*/\n\017QueueStateProto\022\r\n\tQ_STOPPED\020\001\022",
      "\r\n\tQ_RUNNING\020\002*H\n\rQueueACLProto\022\034\n\030QACL_" +
      "SUBMIT_APPLICATIONS\020\001\022\031\n\025QACL_ADMINISTER" +
      "_QUEUE\020\002*n\n\030ContainerExitStatusProto\022\013\n\007" +
      "SUCCESS\020\000\022\024\n\007INVALID\020\230\370\377\377\377\377\377\377\377\001\022\024\n\007ABORT" +
      "ED\020\234\377\377\377\377\377\377\377\377\001\022\031\n\014DISKS_FAILED\020\233\377\377\377\377\377\377\377\377\001" +
      "B0\n\034org.apache.hadoop.yarn.protoB\nYarnPr" +
      "otos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hadoop_yarn_SerializedExceptionProto_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SerializedExceptionProto_descriptor,
              new java.lang.String[] { "Message", "Trace", "ClassName", "Cause", });
          internal_static_hadoop_yarn_ApplicationIdProto_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationIdProto_descriptor,
              new java.lang.String[] { "Id", "ClusterTimestamp", });
          internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor,
              new java.lang.String[] { "ApplicationId", "AttemptId", });
          internal_static_hadoop_yarn_ContainerIdProto_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerIdProto_descriptor,
              new java.lang.String[] { "AppId", "AppAttemptId", "Id", });
          internal_static_hadoop_yarn_ResourceProto_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceProto_descriptor,
              new java.lang.String[] { "Memory", "VirtualCores", });
          internal_static_hadoop_yarn_ResourceOptionProto_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceOptionProto_descriptor,
              new java.lang.String[] { "Resource", "OverCommitTimeout", });
          internal_static_hadoop_yarn_NodeResourceMapProto_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeResourceMapProto_descriptor,
              new java.lang.String[] { "NodeId", "ResourceOption", });
          internal_static_hadoop_yarn_PriorityProto_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PriorityProto_descriptor,
              new java.lang.String[] { "Priority", });
          internal_static_hadoop_yarn_ContainerProto_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerProto_descriptor,
              new java.lang.String[] { "Id", "NodeId", "NodeHttpAddress", "Resource", "Priority", "ContainerToken", });
          internal_static_hadoop_yarn_URLProto_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_hadoop_yarn_URLProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_URLProto_descriptor,
              new java.lang.String[] { "Scheme", "Host", "Port", "File", "UserInfo", });
          internal_static_hadoop_yarn_LocalResourceProto_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_LocalResourceProto_descriptor,
              new java.lang.String[] { "Resource", "Size", "Timestamp", "Type", "Visibility", "Pattern", });
          internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor,
              new java.lang.String[] { "NumUsedContainers", "NumReservedContainers", "UsedResources", "ReservedResources", "NeededResources", });
          internal_static_hadoop_yarn_ApplicationReportProto_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationReportProto_descriptor,
              new java.lang.String[] { "ApplicationId", "User", "Queue", "Name", "Host", "RpcPort", "ClientToAmToken", "YarnApplicationState", "TrackingUrl", "Diagnostics", "StartTime", "FinishTime", "FinalApplicationStatus", "AppResourceUsage", "OriginalTrackingUrl", "CurrentApplicationAttemptId", "Progress", "ApplicationType", "AmRmToken", });
          internal_static_hadoop_yarn_NodeIdProto_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeIdProto_descriptor,
              new java.lang.String[] { "Host", "Port", });
          internal_static_hadoop_yarn_NodeReportProto_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeReportProto_descriptor,
              new java.lang.String[] { "NodeId", "HttpAddress", "RackName", "Used", "Capability", "NumContainers", "NodeState", "HealthReport", "LastHealthReportTime", });
          internal_static_hadoop_yarn_ResourceRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceRequestProto_descriptor,
              new java.lang.String[] { "Priority", "ResourceName", "Capability", "NumContainers", "RelaxLocality", });
          internal_static_hadoop_yarn_PreemptionMessageProto_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionMessageProto_descriptor,
              new java.lang.String[] { "StrictContract", "Contract", });
          internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor,
              new java.lang.String[] { "Container", });
          internal_static_hadoop_yarn_PreemptionContractProto_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionContractProto_descriptor,
              new java.lang.String[] { "Resource", "Container", });
          internal_static_hadoop_yarn_PreemptionContainerProto_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionContainerProto_descriptor,
              new java.lang.String[] { "Id", });
          internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(20);
          internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor,
              new java.lang.String[] { "Resource", });
          internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(21);
          internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor,
              new java.lang.String[] { "BlacklistAdditions", "BlacklistRemovals", });
          internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor =
            getDescriptor().getMessageTypes().get(22);
          internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor,
              new java.lang.String[] { "ApplicationId", "ApplicationName", "Queue", "Priority", "AmContainerSpec", "CancelTokensWhenComplete", "UnmanagedAm", "MaxAppAttempts", "Resource", "ApplicationType", });
          internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor =
            getDescriptor().getMessageTypes().get(23);
          internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor,
              new java.lang.String[] { "AccessType", "Acl", });
          internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor =
            getDescriptor().getMessageTypes().get(24);
          internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor,
              new java.lang.String[] { "NumNodeManagers", });
          internal_static_hadoop_yarn_QueueInfoProto_descriptor =
            getDescriptor().getMessageTypes().get(25);
          internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueInfoProto_descriptor,
              new java.lang.String[] { "QueueName", "Capacity", "MaximumCapacity", "CurrentCapacity", "State", "ChildQueues", "Applications", });
          internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor =
            getDescriptor().getMessageTypes().get(26);
          internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor,
              new java.lang.String[] { "QueueName", "UserAcls", });
          internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor =
            getDescriptor().getMessageTypes().get(27);
          internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor,
              new java.lang.String[] { "LocalResources", "Tokens", "ServiceData", "Environment", "Command", "ApplicationACLs", });
          internal_static_hadoop_yarn_ContainerStatusProto_descriptor =
            getDescriptor().getMessageTypes().get(28);
          internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerStatusProto_descriptor,
              new java.lang.String[] { "ContainerId", "State", "Diagnostics", "ExitStatus", });
          internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(29);
          internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor,
              new java.lang.String[] { "ContainerId", "Capability", });
          internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor =
            getDescriptor().getMessageTypes().get(30);
          internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor,
              new java.lang.String[] { "ContainerId", "Capability", "ContainerToken", });
          internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor =
            getDescriptor().getMessageTypes().get(31);
          internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor,
              new java.lang.String[] { "ContainerId", "Capability", });
          internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor =
            getDescriptor().getMessageTypes().get(32);
          internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor,
              new java.lang.String[] { "Key", "Value", });
          internal_static_hadoop_yarn_StringStringMapProto_descriptor =
            getDescriptor().getMessageTypes().get(33);
          internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StringStringMapProto_descriptor,
              new java.lang.String[] { "Key", "Value", });
          internal_static_hadoop_yarn_StringBytesMapProto_descriptor =
            getDescriptor().getMessageTypes().get(34);
          internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_StringBytesMapProto_descriptor,
              new java.lang.String[] { "Key", "Value", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.security.proto.SecurityProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
